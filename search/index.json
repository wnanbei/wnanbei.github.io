[{"content":"防御性编程（Defensive programming）是防御式设计的一种具体体现，它是为了保证，对程序的不可预见的使用，不会造成程序功能上的损坏。\n它可以被看作是为了减少或消除墨菲定律效力的方法。\n 一个测试工程师走进一家酒吧，要了一杯啤酒；\n一个测试工程师走进一家酒吧，要了一杯咖啡；\n一个测试工程师走进一家酒吧，要了-1杯啤酒；\n一个测试工程师走进一家酒吧，要了一份asdfQwer@24dg!\u0026amp;*(@；\n一个测试工程师走进一家酒吧，什么也没要；\n一个测试工程师走进一家酒吧，又走出去又进来又出去又进来又出去，最后在外面把老板打了一顿；\n一个测试工程师走进一家酒吧，要了NaN杯Null；\n一个测试工程师冲进一家酒吧，要了500吨啤酒；\n一个测试工程师把酒吧拆了；\n一个测试工程师化装成老板走进一家酒吧，要了500杯啤酒并且不付钱；\n一万个测试工程师在酒吧门外呼啸而过；\n测试工程师们满意地离开了酒吧。\n然后一名顾客点了一份炒饭，酒吧炸了。\n 这就是今天的主题，如何避免酒吧爆炸 防御性编程。类似的概念有防御性驾驶、防御性专利。\n防御性编程的特点 不信任原则 软件开发的不信任原则，保持 overly pessimistic（过于悲观），把和程序有关的一切请求、服务、接口、返回值、机器、框架、中间件等等都当做不可信的，步步为营、处处设防。\n*边界和场景 边界：\n 用户端的输入和操作 网络环境 数据存储 文件 第三方包 同事写的代码 自己写的代码  场景：\n 非常规操作，如：高频点击、非流程操作  缺点  部分性能损失。 健壮性的损失。 代码可读性的损失。 开发时间的损耗（不一定）。  优点  尽早发现较小的问题，而不是等到它们发展成大的灾难的时候才发现。 节省大量调试时间。 避免异常逻辑的传导，明确异常原因与位置。 避免了大量安全性问题，防范部分恶意的滥用。  *健壮性与正确性的平衡 正确性（correctness）意味着永不返回不准确的结果，哪怕不返回结果也比返回不准确的结果好。\n健壮性（robustness）意味着要不断尝试采取某些措施，以保证软件可以持续地运转下去，哪怕有时得出一些不够准确的结果。\n实践场景 良好的编程风格和合理的设计 良好的编程风格、合理的结构设计可以使编码变得更加清晰明了，很轻松的将大部分可能发生的问题消弥在无形之中。\n所以，先思考，后编码会是一个非常良好的习惯，也是防御性编程的基础。\n参数验证 目前后端遇最需要防御性编程的情况，应该是 api 接口的请求参数需要验证。参数的上下限、数值类型、零值、类型、格式等等都需要进行验证。\n这些错误有可能来自于用户的错误使用，也可能来自于前端的异常调用，保护我们的程序远离外部的无效数据，可以大大提高程序的稳定性。\nGin 框架在使用 Bind 系列方法绑定 struct 时会自动根据 struct 的 tag 来验证参数是否正确，用来验证的库是：go-playground/validator/v10，这里有详细用法：validator。\ntype Test struct { Field `binding:\u0026#34;required\u0026#34;` //此字段值必须存在 \tField `binding:\u0026#34;min=2,max=10\u0026#34;` //限制数值类型大小、字符串类型长度、切片元素数量 \tField `binding:\u0026#34;boolean\u0026#34;` //限制为 bool 类型 \tField `binding:\u0026#34;number\u0026#34;` //限制为数字 \tField `binding:\u0026#34;email\u0026#34;` //限制为邮箱格式 \tField `binding:\u0026#34;omitempty,rgb|rgba\u0026#34;` //此字段值可以不存在，仅在存在时验证格式 } 如果对于绑定时自动验证的方式不满足，或者需要在其他地方使用，可以单独使用 validator 库。\n需要注意的是，单独使用 validator 库时，tag 需要使用 validate 而不是 binding：\ntype Test struct { Field string `validate:\u0026#34;number\u0026#34;` } func main() { validate := validator.New() t := \u0026amp;Test{Field: \u0026#34;abcd\u0026#34;} err := validate.Struct(t) if err != nil { fmt.Println(err) } } 也可以单独验证一个字段：\nvalidate := validator.New() s := \u0026#34;18\u0026#34; err := validate.Var(s, \u0026#34;min=5,max=10\u0026#34;) if err != nil { fmt.Println(err) } 使用 validator 验证 struct 时，返回的异常可以清晰的说明是哪个字段出了什么问题，根据不同的异常返回不同的提示信息，可以更好的提升接口的清晰性、正确性。\ndao 层参数验证 除了 api 接口的参数异常属于高危情况外，访问数据的 dao 层接受的参数同样需要严格的参数验证，这种情况不仅关系到代码正常运行，更影响到整个系统、业务的安全。\ndao 层接收到的参数可能来自于程序内部的错误处理、api 接口未过滤的异常参数等情况，但由于直面数据库，造成严重后果的可能性更大，所以更要谨慎验证参数的正确性。\n谨慎强制类型转换 一定要对于强制的类型转换保持警惕，如果转换方法会返回异常的，一定要处理异常，并预设转换失败的场景进行处理。\n以下是一些常见的类型转换高危场景：\n int64 转 int32，有可能造成精度的丢失； string 转 int，格式异常转换失败； string 转 time.Time，格式异常转换失败； 解析 json，格式异常转换失败。  异常处理 Go 语言处理所有异常的理念，是非常符合防御式编程的思想的。不要预设异常不会发生而忽略异常。\n而异常的处理方法则需要根据业务的具体情况具体分析，常见的处理方法有以下几类：\n 返回中立值 换用下一个正确数据 返回与前一次相同的值 换用最接近的有效值 在日志中记录告警信息 返回错误码 调用错误处理子程序或对象 关闭程序  除此之外，像 gin 的默认中间件 Recovery 中间件会自动恢复 api 中的 panic，并记录日志，这也是一种防御性编程的方式。\n*方法返回数据的验证 再次强调，不要信任任何方法的返回值。在异常处理的基础上，还需要验证返回的数据是否正确，某些重要的数据是否存在，数据是否正常。\n好的 API 设计 这个 API 不仅指的是我们的 Restful api 接口，也指的是我们内部代码的方法 API。\n 好的 API 易于使用：命名合理、可读性强，输入输出设置合理且扩展性好。 好的 API 难以误用：针对各种可能的误用情况进行必要校验并给出可读性强的报错信息提示。  当 API 的设计良好，同时保证了易于使用和难以误用时，自然会大大提高 API 的正确使用率，降低各种因为 API 误用造成的问题。\n*频率控制 特别是消耗过于大的方法场景\n同时保护被调用方的频率。令牌桶、漏桶\n  用户流控：限制每个用户在一定时间内对某个接口的调用数。\n  接口流控：限制一定时间内某个接口的总调用数。\n  单机流控：限制一定时间内单台服务器上的项目所有接口的总调用数。\n  分布式流控：限制一定时间内项目所有服务器的总请求数。\n  包变量私有化 不需要被外部使用的包变量，使用首字母小写的私有变量，如果外部需要访问，也尽量使用全局方法提供给外部访问。避免包变量在外部被错误修改，导致程序的异常。\nconst ( env = \u0026#34;prod\u0026#34; ) func Env() string { return env } 如果包变量需要被外部变更，特别是一些比较复杂的对象，更要使用包提供的方法去进行安全的变更。\nfunc ChangeEnv() error { if v, ok := checkConfig(); ok { env = v return nil } return errors.New(\u0026#34;change env failed.\u0026#34;) } 尽量使用常量替代全局变量 如果某些全局变量不需要修改，那么使用常量来声明这些变量，利用常量不可更改的属性来保护这些变量的值不被他人变更。\nconst ( StatusContinue = 100 // RFC 7231, 6.2.1 \tStatusSwitchingProtocols = 101 // RFC 7231, 6.2.2 ) var statusText = map[int]string{ StatusContinue: \u0026#34;Continue\u0026#34;, StatusSwitchingProtocols: \u0026#34;Switching Protocols\u0026#34;, } func StatusText(code int) string { return statusText[code] } 超时控制 调用接口或长耗时任务，需要限制最大超时时间，并审慎地判断超时时间的值。如果超时时间过长，短时间并发量增大的情况下，会造成大量协程被挂起，消耗大量资源，造成系统异常。\nGo 中可以使用 context 或 time.After 等机制对超时行为进行控制。\n*释放资源 在获取资源后，尽量使用 defer 释放资源。\n在代码较简单的情况下，可以使用在每一个代码分支结束时手动释放资源。但在代码复杂起来，时间跨度拉长，变更了开发人员等情况下，某些代码分支没有释放资源而直接结束方法后。就会造成资源永久挂起、内存泄漏等问题。\n简单的一个场景：一个 500 行的函数，需要你去检查一个 bug，你发现是少做了一层判断，你加上判断后，if err != nil { return }，看上去是不是很正常，那如果有资源需要手动释放的情况，这里就会造成内存泄漏。\n同样的，反过来想，作为一个后来的代码维护者，在修改代码时，同样要注意检查是否有需要手动释放的资源。\n隔离程序 隔离程序指的是对于防御性编程的灵活调整，毕竟防御性编程始终是有成本的。而绝对防御式编程将消耗大量的精力，造成非常臃肿的代码。\n所以我们可以将高危、容易出错的地方加上防御性编程代码，而在不容易出错的、内部的位置减少或去掉防御性编程代码。\n /images/go/隔离程序.png \n以下位置就是常见的高危场景：\n 外部输入 调用接口 文件访问 数据库查询  而在内部的函数调用等地方，可以适当的减少防御性代码，但某些关键数据和关键逻辑位置，防御性代码依然是必要的。\n","date":"2021-11-12T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E9%98%B2%E5%BE%A1%E6%80%A7%E7%BC%96%E7%A8%8B/","title":"防御性编程"},{"content":"","date":"2021-11-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/mongodb-%E7%B4%A2%E5%BC%95%E7%94%A8%E6%B3%95%E4%B8%8E%E5%8E%9F%E7%90%86/","title":"MongoDB 索引用法与原理"},{"content":"模板模式是指抽象类里定义好算法的执行步骤和具体算法，以及可能发生变化的算法定义为抽象方法。不同的子类继承该抽象类，并实现父类的抽象方法。\n优势：\n 不变的算法被继承复用：不变的部分高度封装、复用。 变化的算法子类继承并具体实现：变化的部分子类只需要具体实现抽象的部分即可，方便扩展，且可无限扩展。  适用场景 满足如下要求的所有场景:\n 算法执行的步骤是稳定不变的，但是具体的某些算法可能存在变化的场景。\n 比如说煮面，需要先烧水，水烧开之后再放面进去，这个流程被称为 煮面过程，而烧水方式可能有多种，比如柴火烧、电磁炉烧、天然气烧。所以可以得出以下结论：\n 煮面过程的步骤是稳定不变的 煮面过程的烧水方式是可变的  如果能满足这样的条件，就可以使用模板方法。\n使用方式 可以有四个步骤：\n 业务梳理 代码建模 代码 Demo  业务梳理","date":"2021-11-09T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%B3%BB%E5%88%97%E4%B8%80/","title":"模板模式 - 设计模式系列（一）"},{"content":"ElasticSearch 使用 HTTP 协议的 Restful 接口，来对接不同的程序系统。\n查询 Get 读取一条文档。\nGET index_name/_doc/id Mget 批量读取文档。\n在请求体中指定 index：\nGET _mget { \u0026#34;docs\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; }, { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } ] } URI 中指定 index：\nGET index_name/_mget { \u0026#34;docs\u0026#34; : [ { \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; }, { \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } ] } Msearch 批量搜索文档\nPOST index_name/_msearch {} {\u0026#34;query\u0026#34; : {\u0026#34;match_all\u0026#34; : {}},\u0026#34;size\u0026#34;:1} {\u0026#34;index\u0026#34; : \u0026#34;kibana_sample_data_flights\u0026#34;} {\u0026#34;query\u0026#34; : {\u0026#34;match_all\u0026#34; : {}},\u0026#34;size\u0026#34;:2} 创建 Create 创建一条文档，如果指定的 id 存在，则报错\nPOST index_name/_create PUT index_name/_create/id PUT index_name/_doc/id?op_type=create { \u0026#34;user\u0026#34; : \u0026#34;Mike\u0026#34;, \u0026#34;post_date\u0026#34; : \u0026#34;2019-04-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Kibana\u0026#34; }  不指定 id 时，系统会自动生成 id 如果指定 id，则在 URI 中显式指定，如果指定的 id 存在，则报错  Index 创建一条文档，如果指定的 id 存在，旧文档会被删除，插入新文档，文档版本信息 +1\nPUT index_name/_doc/id 更新 Update 不会删除原文档，真正的数据更新\nPOST index_name/_update/id { \u0026#34;doc\u0026#34;:{ \u0026#34;post_date\u0026#34; : \u0026#34;2019-05-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Elasticsearch\u0026#34; } }  Update 的内容必须放在 doc 字段中  删除 Delete 删除一条文档\nDELETE index_name/_doc/id 批量操作 Bulk 一次请求执行多条语句\nPOST _bulk { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;field1\u0026#34; : \u0026#34;value1\u0026#34; } { \u0026#34;delete\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } } { \u0026#34;create\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test2\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;3\u0026#34; } } { \u0026#34;field1\u0026#34; : \u0026#34;value3\u0026#34; } { \u0026#34;update\u0026#34; : {\u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;} } { \u0026#34;doc\u0026#34; : {\u0026#34;field2\u0026#34; : \u0026#34;value2\u0026#34;} } 工具 Analyze 分词接口\nGET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;2 running Quick brown-foxes leap over lazy dogs in the summer evening.\u0026#34; } GET index_name/_analyze // 根据某 index 某字段的分词方式分词 { \u0026#34;field\u0026#34;: \u0026#34;title\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;2 running Quick brown-foxes leap over lazy dogs in the summer evening.\u0026#34; } GET _analyze // 自定义分词 { \u0026#34;tokenizer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;lowercase\u0026#34;], \u0026#34;text\u0026#34;: \u0026#34;2 running Quick brown-foxes leap over lazy dogs in the summer evening.\u0026#34; } ","date":"2021-11-06T16:17:25Z","permalink":"https://wnanbei.github.io/post/elasticsearch-crud-%E6%8E%A5%E5%8F%A3/","title":"ElasticSearch CRUD 接口"},{"content":"Query 查询所有数据 db.inventory.find( {} ) 条件查询 db.inventory.find( { status: \u0026#34;D\u0026#34; } ) IN 查询：\ndb.inventory.find( { status: { $in: [ \u0026#34;A\u0026#34;, \u0026#34;D\u0026#34; ] } } ) AND 查询：\ndb.inventory.find( { status: \u0026#34;A\u0026#34;, qty: { $lt: 30 } } ) OR 查询：\ndb.inventory.find( { $or: [ { status: \u0026#34;A\u0026#34; }, { qty: { $lt: 30 } } ] } ) AND 和 IN 混用：\ndb.inventory.find( { status: \u0026#34;A\u0026#34;, $or: [ { qty: { $lt: 30 } }, { item: /^p/ } ] } ) 嵌套数据查询 查询数据中嵌套的内容：\ndb.inventory.find( { size: { h: 14, w: 21, uom: \u0026#34;cm\u0026#34; } } ) 注：条件字段顺序必须完全与数据相同，否则匹配不到。\n也可以使用 dot 方式指定嵌套字段：\ndb.inventory.find( { \u0026#34;size.h\u0026#34;: { $lt: 15 } } ) db.inventory.find( { \u0026#34;size.h\u0026#34;: { $lt: 15 }, \u0026#34;size.uom\u0026#34;: \u0026#34;in\u0026#34;, status: \u0026#34;D\u0026#34; } ) 数组查询 数组完全匹配，包括顺序：\ndb.inventory.find( { tags: [\u0026#34;red\u0026#34;, \u0026#34;blank\u0026#34;] } ) 查询所有数组内包含此条件的数据：\ndb.inventory.find( { tags: \u0026#34;red\u0026#34; } ) db.inventory.find( { tags: { $all: [\u0026#34;red\u0026#34;, \u0026#34;blank\u0026#34;] } } ) db.inventory.find( { dim_cm: { $gt: 25 } } ) 多条件查询：\ndb.inventory.find( { dim_cm: { $gt: 15, $lt: 20 } } ) 根据数组中特定索引的值查询：\ndb.inventory.find( { \u0026#34;dim_cm.1\u0026#34;: { $gt: 25 } } ) 根据数组长度查询：\ndb.inventory.find( { \u0026#34;tags\u0026#34;: { $size: 3 } } ) 限制查询返回字段 仅返回指定的字段：\ndb.inventory.find( { status: \u0026#34;A\u0026#34; }, { item: 1, status: 1, \u0026#34;size.uom\u0026#34;: 1 } ) 除了指定的字段，其他字段都返回：\ndb.inventory.find( { status: \u0026#34;A\u0026#34; }, { status: 0, instock: 0 } ) 不返回 _id:\ndb.inventory.find( { status: \u0026#34;A\u0026#34; }, { item: 1, status: 1, _id: 0 } ) 除了 _id 字段，其他字段不能进行组合。\nnull 值处理 查询所有无此字段或字段值为 null 的数据：\ndb.inventory.find( { item: null } ) 仅查询字段存在且值为 null 的数据：\ndb.inventory.find( { item : { $type: 10 } } ) 仅查询字段不存在的数据：\ndb.inventory.find( { item : { $exists: false } } ) Insert 特性：\n MongoDB 所有对单条数据的写操作都是原子操作； 不指定 _id 会自动生成； 插入数据会返回对应 _id  单条插入 db.inventory.insertOne( { item: \u0026#34;canvas\u0026#34;, qty: 100, tags: [\u0026#34;cotton\u0026#34;], size: { h: 28, w: 35.5, uom: \u0026#34;cm\u0026#34; } } ) 批量插入 db.inventory.insertMany([ { item: \u0026#34;journal\u0026#34;, qty: 25, tags: [\u0026#34;blank\u0026#34;, \u0026#34;red\u0026#34;], size: { h: 14, w: 21, uom: \u0026#34;cm\u0026#34; } }, { item: \u0026#34;mat\u0026#34;, qty: 85, tags: [\u0026#34;gray\u0026#34;], size: { h: 27.9, w: 35.5, uom: \u0026#34;cm\u0026#34; } }, { item: \u0026#34;mousepad\u0026#34;, qty: 25, tags: [\u0026#34;gel\u0026#34;, \u0026#34;blue\u0026#34;], size: { h: 19, w: 22.85, uom: \u0026#34;cm\u0026#34; } } ]) Update 特性：\n MongoDB 所有对单条数据的写操作都是原子操作； 一条数据插入之后，_id 字段将不能再更改和替换； 对于写操作，mongo 会保留字段的顺序，除非以下情况：  _id 字段始终排在第一位。 字段重命名可能会导致文档字段重新排序。    单条更新 db.inventory.updateOne( { item: \u0026#34;paper\u0026#34; }, { $set: { \u0026#34;size.uom\u0026#34;: \u0026#34;cm\u0026#34;, status: \u0026#34;P\u0026#34; }, $currentDate: { lastModified: true } } ) 批量更新 db.inventory.updateMany( { \u0026#34;qty\u0026#34;: { $lt: 50 } }, { $set: { \u0026#34;size.uom\u0026#34;: \u0026#34;in\u0026#34;, status: \u0026#34;P\u0026#34; }, $currentDate: { lastModified: true } } ) 替换数据 完全替换此条数据。\ndb.inventory.replaceOne( { item: \u0026#34;paper\u0026#34; }, { item: \u0026#34;paper\u0026#34;, instock: [ { warehouse: \u0026#34;A\u0026#34;, qty: 60 }, { warehouse: \u0026#34;B\u0026#34;, qty: 40 } ] } ) Delete 特性：\n MongoDB 所有对单条数据的写操作都是原子操作； 就算删除了全部数据，也不会删除索引。  单条删除 单条删除会删除匹配到的第一条数据：\ndb.inventory.deleteOne( { status: \u0026#34;D\u0026#34; } ) 批量删除 db.inventory.deleteMany({}) db.inventory.deleteMany({ status : \u0026#34;A\u0026#34; }) ","date":"2021-11-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/mongodb-crud-%E6%93%8D%E4%BD%9C/","title":"MongoDB CRUD 操作"},{"content":"golangci-lint 是一个代码检查工具的集合，聚集了多种 Go 代码检查工具，如 golint、go vet 等。\n优点：\n 运行速度快 可以集成到 vscode、goland 等开发工具中 包含了非常多种代码检查器 可以集成到 CI 中  这是包含的代码检查器列表：Linters\n安装 golangci-lint 官方不建议使用 go get 方式安装，推荐使用二进制安装。\nMacOS 直接使用 homebrew 安装：\nbrew install golangci-lint brew upgrade golangci-lint Linux 和 Windows # binary will be $(go env GOPATH)/bin/golangci-lint curl -sSfL https://raw.githubusercontent.com/Goci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v1.42.1 golangci-lint --version golangci-lint 将会被安装到 GOPATH/bin 目录中，如果此目录不在环境变量路径中需要加上。\n使用方式 命令行 在项目根目录下执行以下命令检查整个项目的代码：\ngolangci-lint run 其等价于：\ngolangci-lint run ./... 或者可以指定检查某个目录下的代码文件，指定目录时不会递归分析其子目录，要递归分析其子目录需要加上 /...：\ngolangci-lint run dir1 dir2/... dir3/file1.go 在没有配置文件时，golangci-lint 会使用默认的代码检查器进行检查。\n使用以下命令，可以查看默认启用和关闭了哪些检查器：\ngolangci-lint help linters 集成到 vscode 在 vscode 配置文件中新增以下内容：\n\u0026#34;go.lintTool\u0026#34;:\u0026#34;golangci-lint\u0026#34;, \u0026#34;go.lintFlags\u0026#34;: [ \u0026#34;--fast\u0026#34; ] golangci-lint 会自动查找项目中的 .golangci.yml 配置文件，不用额外配置。\n集成到 Goland  安装插件 Go Linter  可以在 Goland 内插件市场搜索 Go Linter 直接安装。   配置 File Watchers  在 Goland 配置页面的 工具 -\u0026gt; File Watchers 进行配置。 点 + 按钮，选择 golangci-lint 创建。    排除代码检查 有时候有部分代码因为各种原因不能通过代码检查，也不能修改，可以使用注释跳过代码检查。如下所示：\nvar bad_name int //nolint var bad_name int //nolint:golint,unused 可以排除一整块代码：\n//nolint func allIssuesInThisFunctionAreExcluded() *string { // ... } //nolint:govet var ( a int b int ) 或者一整个文件：\n//nolint:unparam package pkg 配置文件 golangci-lint 会自动在当前目录下查找以下名称的配置文件：\n .golangci.yml .golangci.yaml .golangci.toml .golangci.json  配置启用的代码选择器 linters: disable-all: true enable: - megacheck - govet enable-all: true disable: - maligned - prealloc presets: - bugs - unused fast: false 示例配置 以下是官方给出的配置文件示例，包含了可以设置的选项和选项的默认值：\n# This file contains all available configuration options # with their default values. # options for analysis running run: # default concurrency is a available CPU number concurrency: 4 # timeout for analysis, e.g. 30s, 5m, default is 1m timeout: 1m # exit code when at least one issue was found, default is 1 issues-exit-code: 1 # include test files or not, default is true tests: true # list of build tags, all linters use it. Default is empty list. build-tags: - mytag # which dirs to skip: issues from them won\u0026#39;t be reported; # can use regexp here: generated.*, regexp is applied on full path; # default value is empty list, but default dirs are skipped independently # from this option\u0026#39;s value (see skip-dirs-use-default). # \u0026#34;/\u0026#34; will be replaced by current OS file path separator to properly work # on Windows. skip-dirs: - src/external_libs - autogenerated_by_my_lib # default is true. Enables skipping of directories: # vendor$, third_party$, testdata$, examples$, Godeps$, builtin$ skip-dirs-use-default: true # which files to skip: they will be analyzed, but issues from them # won\u0026#39;t be reported. Default value is empty list, but there is # no need to include all autogenerated files, we confidently recognize # autogenerated files. If it\u0026#39;s not please let us know. # \u0026#34;/\u0026#34; will be replaced by current OS file path separator to properly work # on Windows. skip-files: - \u0026#34;.*\\\\.my\\\\.go$\u0026#34; - lib/bad.go # by default isn\u0026#39;t set. If set we pass it to \u0026#34;go list -mod={option}\u0026#34;. From \u0026#34;go help modules\u0026#34;: # If invoked with -mod=readonly, the go command is disallowed from the implicit # automatic updating of go.mod described above. Instead, it fails when any changes # to go.mod are needed. This setting is most useful to check that go.mod does # not need updates, such as in a continuous integration and testing system. # If invoked with -mod=vendor, the go command assumes that the vendor # directory holds the correct copies of dependencies and ignores # the dependency descriptions in go.mod. modules-download-mode: readonly|vendor|mod # Allow multiple parallel golangci-lint instances running. # If false (default) - golangci-lint acquires file lock on start. allow-parallel-runners: false # output configuration options output: # colored-line-number|line-number|json|tab|checkstyle|code-climate|junit-xml|github-actions # default is \u0026#34;colored-line-number\u0026#34; format: colored-line-number # print lines of code with issue, default is true print-issued-lines: true # print linter name in the end of issue text, default is true print-linter-name: true # make issues output unique by line, default is true uniq-by-line: true # add a prefix to the output file references; default is no prefix path-prefix: \u0026#34;\u0026#34; # sorts results by: filepath, line and column sort-results: false # all available settings of specific linters linters-settings: cyclop: # the maximal code complexity to report max-complexity: 10 # the maximal average package complexity. If it\u0026#39;s higher than 0.0 (float) the check is enabled (default 0.0) package-average: 0.0 # should ignore tests (default false) skip-tests: false dogsled: # checks assignments with too many blank identifiers; default is 2 max-blank-identifiers: 2 dupl: # tokens count to trigger issue, 150 by default threshold: 100 errcheck: # report about not checking of errors in type assertions: `a := b.(MyStruct)`; # default is false: such cases aren\u0026#39;t reported by default. check-type-assertions: false # report about assignment of errors to blank identifier: `num, _ := strconv.Atoi(numStr)`; # default is false: such cases aren\u0026#39;t reported by default. check-blank: false # [deprecated] comma-separated list of pairs of the form pkg:regex # the regex is used to ignore names within pkg. (default \u0026#34;fmt:.*\u0026#34;). # see https://github.com/kisielk/errcheck#the-deprecated-method for details ignore: fmt:.*,io/ioutil:^Read.* # [deprecated] use exclude-functions instead. # path to a file containing a list of functions to exclude from checking # see https://github.com/kisielk/errcheck#excluding-functions for details exclude: /path/to/file.txt # list of functions to exclude from checking, where each entry is a single function to exclude. # see https://github.com/kisielk/errcheck#excluding-functions for details exclude-functions: - io/ioutil.ReadFile - io.Copy(*bytes.Buffer) - io.Copy(os.Stdout) errorlint: # Check whether fmt.Errorf uses the %w verb for formatting errors. See the readme for caveats errorf: true # Check for plain type assertions and type switches asserts: true # Check for plain error comparisons comparison: true exhaustive: # check switch statements in generated files also check-generated: false # indicates that switch statements are to be considered exhaustive if a # \u0026#39;default\u0026#39; case is present, even if all enum members aren\u0026#39;t listed in the # switch default-signifies-exhaustive: false exhaustivestruct: # Struct Patterns is list of expressions to match struct packages and names # The struct packages have the form example.com/package.ExampleStruct # The matching patterns can use matching syntax from https://pkg.go.dev/path#Match # If this list is empty, all structs are tested. struct-patterns: - \u0026#39;*.Test\u0026#39; - \u0026#39;example.com/package.ExampleStruct\u0026#39; forbidigo: # Forbid the following identifiers (identifiers are written using regexp): forbid: - ^print.*$ - \u0026#39;fmt\\.Print.*\u0026#39; # Exclude godoc examples from forbidigo checks. Default is true. exclude_godoc_examples: false funlen: lines: 60 statements: 40 gci: # put imports beginning with prefix after 3rd-party packages; # only support one prefix # if not set, use goimports.local-prefixes local-prefixes: github.com/org/project gocognit: # minimal code complexity to report, 30 by default (but we recommend 10-20) min-complexity: 10 goconst: # minimal length of string constant, 3 by default min-len: 3 # minimum occurrences of constant string count to trigger issue, 3 by default min-occurrences: 3 # ignore test files, false by default ignore-tests: false # look for existing constants matching the values, true by default match-constant: true # search also for duplicated numbers, false by default numbers: false # minimum value, only works with goconst.numbers, 3 by default min: 3 # maximum value, only works with goconst.numbers, 3 by default max: 3 # ignore when constant is not used as function argument, true by default ignore-calls: true gocritic: # Which checks should be enabled; can\u0026#39;t be combined with \u0026#39;disabled-checks\u0026#39;; # See https://go-critic.github.io/overview#checks-overview # To check which checks are enabled run `GL_DEBUG=gocritic golangci-lint run` # By default list of stable checks is used. enabled-checks: - rangeValCopy # Which checks should be disabled; can\u0026#39;t be combined with \u0026#39;enabled-checks\u0026#39;; default is empty disabled-checks: - regexpMust # Enable multiple checks by tags, run `GL_DEBUG=gocritic golangci-lint run` to see all tags and checks. # Empty list by default. See https://github.com/go-critic/go-critic#usage -\u0026gt; section \u0026#34;Tags\u0026#34;. enabled-tags: - performance disabled-tags: - experimental # Settings passed to gocritic. # The settings key is the name of a supported gocritic checker. # The list of supported checkers can be find in https://go-critic.github.io/overview. settings: captLocal: # must be valid enabled check name # whether to restrict checker to params only (default true) paramsOnly: true elseif: # whether to skip balanced if-else pairs (default true) skipBalanced: true hugeParam: # size in bytes that makes the warning trigger (default 80) sizeThreshold: 80 nestingReduce: # min number of statements inside a branch to trigger a warning (default 5) bodyWidth: 5 rangeExprCopy: # size in bytes that makes the warning trigger (default 512) sizeThreshold: 512 # whether to check test functions (default true) skipTestFuncs: true rangeValCopy: # size in bytes that makes the warning trigger (default 128) sizeThreshold: 32 # whether to check test functions (default true) skipTestFuncs: true ruleguard: # path to a gorules file for the ruleguard checker rules: \u0026#39;\u0026#39; truncateCmp: # whether to skip int/uint/uintptr types (default true) skipArchDependent: true underef: # whether to skip (*x).method() calls where x is a pointer receiver (default true) skipRecvDeref: true unnamedResult: # whether to check exported functions checkExported: true gocyclo: # minimal code complexity to report, 30 by default (but we recommend 10-20) min-complexity: 10 godot: # comments to be checked: `declarations`, `toplevel`, or `all` scope: declarations # list of regexps for excluding particular comment lines from check exclude: # example: exclude comments which contain numbers # - \u0026#39;[0-9]+\u0026#39; # check that each sentence starts with a capital letter capital: false godox: # report any comments starting with keywords, this is useful for TODO or FIXME comments that # might be left in the code accidentally and should be resolved before merging keywords: # default keywords are TODO, BUG, and FIXME, these can be overwritten by this setting - NOTE - OPTIMIZE # marks code that should be optimized before merging - HACK # marks hack-arounds that should be removed before merging gofmt: # simplify code: gofmt with `-s` option, true by default simplify: true gofumpt: # Select the Go version to target. The default is `1.15`. lang-version: \u0026#34;1.15\u0026#34; # Choose whether or not to use the extra rules that are disabled # by default extra-rules: false goheader: values: const: # define here const type values in format k:v, for example: # COMPANY: MY COMPANY regexp: # define here regexp type values, for example # AUTHOR: .*@mycompany\\.com template: # |- # put here copyright header template for source code files, for example: # Note: {{ YEAR }} is a builtin value that returns the year relative to the current machine time. # # {{ AUTHOR }} {{ COMPANY }} {{ YEAR }} # SPDX-License-Identifier: Apache-2.0 # Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at: # http://www.apache.org/licenses/LICENSE-2.0 # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. template-path: # also as alternative of directive \u0026#39;template\u0026#39; you may put the path to file with the template source goimports: # put imports beginning with prefix after 3rd-party packages; # it\u0026#39;s a comma-separated list of prefixes local-prefixes: github.com/org/project golint: # minimal confidence for issues, default is 0.8 min-confidence: 0.8 gomnd: settings: mnd: # the list of enabled checks, see https://github.com/tommy-muehle/go-mnd/#checks for description. checks: argument,case,condition,operation,return,assign # ignored-numbers: 1000 # ignored-files: magic_.*.go # ignored-functions: math.* gomoddirectives: # Allow local `replace` directives. Default is false. replace-local: false # List of allowed `replace` directives. Default is empty. replace-allow-list: - launchpad.net/gocheck # Allow to not explain why the version has been retracted in the `retract` directives. Default is false. retract-allow-no-explanation: false # Forbid the use of the `exclude` directives. Default is false. exclude-forbidden: false gomodguard: allowed: modules: # List of allowed modules # - gopkg.in/yaml.v2 domains: # List of allowed module domains # - golang.org blocked: modules: # List of blocked modules # - github.com/uudashr/go-module: # Blocked module # recommendations: # Recommended modules that should be used instead (Optional) # - golang.org/x/mod # reason: \u0026#34;`mod` is the official go.mod parser library.\u0026#34; # Reason why the recommended module should be used (Optional) versions: # List of blocked module version constraints # - github.com/mitchellh/go-homedir: # Blocked module with version constraint # version: \u0026#34;\u0026lt; 1.1.0\u0026#34; # Version constraint, see https://github.com/Masterminds/semver#basic-comparisons # reason: \u0026#34;testing if blocked version constraint works.\u0026#34; # Reason why the version constraint exists. (Optional) local_replace_directives: false # Set to true to raise lint issues for packages that are loaded from a local path via replace directive gosec: # To select a subset of rules to run. # Available rules: https://github.com/securego/gosec#available-rules includes: - G401 - G306 - G101 # To specify a set of rules to explicitly exclude. # Available rules: https://github.com/securego/gosec#available-rules excludes: - G204 # Exclude generated files exclude-generated: true # To specify the configuration of rules. # The configuration of rules is not fully documented by gosec: # https://github.com/securego/gosec#configuration # https://github.com/securego/gosec/blob/569328eade2ccbad4ce2d0f21ee158ab5356a5cf/rules/rulelist.go#L60-L102 config: G306: \u0026#34;0600\u0026#34; G101: pattern: \u0026#34;(?i)example\u0026#34; ignore_entropy: false entropy_threshold: \u0026#34;80.0\u0026#34; per_char_threshold: \u0026#34;3.0\u0026#34; truncate: \u0026#34;32\u0026#34; gosimple: # Select the Go version to target. The default is \u0026#39;1.13\u0026#39;. go: \u0026#34;1.15\u0026#34; # https://staticcheck.io/docs/options#checks checks: [ \u0026#34;all\u0026#34; ] govet: # report about shadowed variables check-shadowing: true # settings per analyzer settings: printf: # analyzer name, run `go tool vet help` to see all analyzers funcs: # run `go tool vet help printf` to see available settings for `printf` analyzer - (github.com/golangci/golangci-lint/pkg/logutils.Log).Infof - (github.com/golangci/golangci-lint/pkg/logutils.Log).Warnf - (github.com/golangci/golangci-lint/pkg/logutils.Log).Errorf - (github.com/golangci/golangci-lint/pkg/logutils.Log).Fatalf # enable or disable analyzers by name # run `go tool vet help` to see all analyzers enable: - atomicalign enable-all: false disable: - shadow disable-all: false depguard: list-type: blacklist include-go-root: false packages: - github.com/sirupsen/logrus packages-with-error-message: # specify an error message to output when a blacklisted package is used - github.com/sirupsen/logrus: \u0026#34;logging is allowed only by logutils.Log\u0026#34; ifshort: # Maximum length of variable declaration measured in number of lines, after which linter won\u0026#39;t suggest using short syntax. # Has higher priority than max-decl-chars. max-decl-lines: 1 # Maximum length of variable declaration measured in number of characters, after which linter won\u0026#39;t suggest using short syntax. max-decl-chars: 30 importas: # if set to `true`, force to use alias. no-unaliased: true # List of aliases alias: # using `servingv1` alias for `knative.dev/serving/pkg/apis/serving/v1` package - pkg: knative.dev/serving/pkg/apis/serving/v1 alias: servingv1 # using `autoscalingv1alpha1` alias for `knative.dev/serving/pkg/apis/autoscaling/v1alpha1` package - pkg: knative.dev/serving/pkg/apis/autoscaling/v1alpha1 alias: autoscalingv1alpha1 # You can specify the package path by regular expression, # and alias by regular expression expansion syntax like below. # see https://github.com/julz/importas#use-regular-expression for details - pkg: knative.dev/serving/pkg/apis/(\\w+)/(v[\\w\\d]+) alias: $1$2 ireturn: # ireturn allows using `allow` and `reject` settings at the same time. # Both settings are lists of the keywords and regular expressions matched to interface or package names. # keywords: # - `empty` for `interface{}` # - `error` for errors # - `stdlib` for standard library # - `anon` for anonymous interfaces # By default, it allows using errors, empty interfaces, anonymous interfaces, # and interfaces provided by the standard library. allow: - anon - error - empty - stdlib # You can specify idiomatic endings for interface - (or|er)$ # Reject patterns reject: - github.com\\/user\\/package\\/v4\\.Type lll: # max line length, lines longer will be reported. Default is 120. # \u0026#39;\\t\u0026#39; is counted as 1 character by default, and can be changed with the tab-width option line-length: 120 # tab width in spaces. Default to 1. tab-width: 1 makezero: # Allow only slices initialized with a length of zero. Default is false. always: false maligned: # print struct with more effective memory layout or not, false by default suggest-new: true misspell: # Correct spellings using locale preferences for US or UK. # Default is to use a neutral variety of English. # Setting locale to US will correct the British spelling of \u0026#39;colour\u0026#39; to \u0026#39;color\u0026#39;. locale: US ignore-words: - someword nakedret: # make an issue if func has more lines of code than this setting and it has naked returns; default is 30 max-func-lines: 30 nestif: # minimal complexity of if statements to report, 5 by default min-complexity: 4 nilnil: # By default, nilnil checks all returned types below. checked-types: - ptr - func - iface - map - chan nlreturn: # size of the block (including return statement that is still \u0026#34;OK\u0026#34;) # so no return split required. block-size: 1 nolintlint: # Enable to ensure that nolint directives are all used. Default is true. allow-unused: false # Disable to ensure that nolint directives don\u0026#39;t have a leading space. Default is true. allow-leading-space: true # Exclude following linters from requiring an explanation. Default is []. allow-no-explanation: [ ] # Enable to require an explanation of nonzero length after each nolint directive. Default is false. require-explanation: true # Enable to require nolint directives to mention the specific linter being suppressed. Default is false. require-specific: true prealloc: # XXX: we don\u0026#39;t recommend using this linter before doing performance profiling. # For most programs usage of prealloc will be a premature optimization. # Report preallocation suggestions only on simple loops that have no returns/breaks/continues/gotos in them. # True by default. simple: true range-loops: true # Report preallocation suggestions on range loops, true by default for-loops: false # Report preallocation suggestions on for loops, false by default promlinter: # Promlinter cannot infer all metrics name in static analysis. # Enable strict mode will also include the errors caused by failing to parse the args. strict: false # Please refer to https://github.com/yeya24/promlinter#usage for detailed usage. disabled-linters: # - \u0026#34;Help\u0026#34; # - \u0026#34;MetricUnits\u0026#34; # - \u0026#34;Counter\u0026#34; # - \u0026#34;HistogramSummaryReserved\u0026#34; # - \u0026#34;MetricTypeInName\u0026#34; # - \u0026#34;ReservedChars\u0026#34; # - \u0026#34;CamelCase\u0026#34; # - \u0026#34;lintUnitAbbreviations\u0026#34; predeclared: # comma-separated list of predeclared identifiers to not report on ignore: \u0026#34;\u0026#34; # include method names and field names (i.e., qualified names) in checks q: false rowserrcheck: packages: - github.com/jmoiron/sqlx revive: # see https://github.com/mgechev/revive#available-rules for details. ignore-generated-header: true severity: warning rules: - name: indent-error-flow severity: warning - name: add-constant severity: warning arguments: - maxLitCount: \u0026#34;3\u0026#34; allowStrs: \u0026#39;\u0026#34;\u0026#34;\u0026#39; allowInts: \u0026#34;0,1,2\u0026#34; allowFloats: \u0026#34;0.0,0.,1.0,1.,2.0,2.\u0026#34; staticcheck: # Select the Go version to target. The default is \u0026#39;1.13\u0026#39;. go: \u0026#34;1.15\u0026#34; # https://staticcheck.io/docs/options#checks checks: [ \u0026#34;all\u0026#34; ] stylecheck: # Select the Go version to target. The default is \u0026#39;1.13\u0026#39;. go: \u0026#34;1.15\u0026#34; # https://staticcheck.io/docs/options#checks checks: [ \u0026#34;all\u0026#34;, \u0026#34;-ST1000\u0026#34;, \u0026#34;-ST1003\u0026#34;, \u0026#34;-ST1016\u0026#34;, \u0026#34;-ST1020\u0026#34;, \u0026#34;-ST1021\u0026#34;, \u0026#34;-ST1022\u0026#34; ] # https://staticcheck.io/docs/options#dot_import_whitelist dot-import-whitelist: - fmt # https://staticcheck.io/docs/options#initialisms initialisms: [ \u0026#34;ACL\u0026#34;, \u0026#34;API\u0026#34;, \u0026#34;ASCII\u0026#34;, \u0026#34;CPU\u0026#34;, \u0026#34;CSS\u0026#34;, \u0026#34;DNS\u0026#34;, \u0026#34;EOF\u0026#34;, \u0026#34;GUID\u0026#34;, \u0026#34;HTML\u0026#34;, \u0026#34;HTTP\u0026#34;, \u0026#34;HTTPS\u0026#34;, \u0026#34;ID\u0026#34;, \u0026#34;IP\u0026#34;, \u0026#34;JSON\u0026#34;, \u0026#34;QPS\u0026#34;, \u0026#34;RAM\u0026#34;, \u0026#34;RPC\u0026#34;, \u0026#34;SLA\u0026#34;, \u0026#34;SMTP\u0026#34;, \u0026#34;SQL\u0026#34;, \u0026#34;SSH\u0026#34;, \u0026#34;TCP\u0026#34;, \u0026#34;TLS\u0026#34;, \u0026#34;TTL\u0026#34;, \u0026#34;UDP\u0026#34;, \u0026#34;UI\u0026#34;, \u0026#34;GID\u0026#34;, \u0026#34;UID\u0026#34;, \u0026#34;UUID\u0026#34;, \u0026#34;URI\u0026#34;, \u0026#34;URL\u0026#34;, \u0026#34;UTF8\u0026#34;, \u0026#34;VM\u0026#34;, \u0026#34;XML\u0026#34;, \u0026#34;XMPP\u0026#34;, \u0026#34;XSRF\u0026#34;, \u0026#34;XSS\u0026#34; ] # https://staticcheck.io/docs/options#http_status_code_whitelist http-status-code-whitelist: [ \u0026#34;200\u0026#34;, \u0026#34;400\u0026#34;, \u0026#34;404\u0026#34;, \u0026#34;500\u0026#34; ] tagliatelle: # check the struck tag name case case: # use the struct field name to check the name of the struct tag use-field-name: true rules: # any struct tag type can be used. # support string case: `camel`, `pascal`, `kebab`, `snake`, `goCamel`, `goPascal`, `goKebab`, `goSnake`, `upper`, `lower` json: camel yaml: camel xml: camel bson: camel avro: snake mapstructure: kebab testpackage: # regexp pattern to skip files skip-regexp: (export|internal)_test\\.go thelper: # The following configurations enable all checks. It can be omitted because all checks are enabled by default. # You can enable only required checks deleting unnecessary checks. test: first: true name: true begin: true benchmark: first: true name: true begin: true tb: first: true name: true begin: true tenv: # The option `all` will run against whole test files (`_test.go`) regardless of method/function signatures. # By default, only methods that take `*testing.T`, `*testing.B`, and `testing.TB` as arguments are checked. all: false unparam: # Inspect exported functions, default is false. Set to true if no external program/library imports your code. # XXX: if you enable this setting, unparam will report a lot of false-positives in text editors: # if it\u0026#39;s called for subdir of a project it can\u0026#39;t find external interfaces. All text editor integrations # with golangci-lint call it on a directory with the changed file. check-exported: false unused: # Select the Go version to target. The default is \u0026#39;1.13\u0026#39;. go: \u0026#34;1.15\u0026#34; whitespace: multi-if: false # Enforces newlines (or comments) after every multi-line if statement multi-func: false # Enforces newlines (or comments) after every multi-line function signature wrapcheck: # An array of strings that specify substrings of signatures to ignore. # If this set, it will override the default set of ignored signatures. # See https://github.com/tomarrell/wrapcheck#configuration for more information. ignoreSigs: - .Errorf( - errors.New( - errors.Unwrap( - .Wrap( - .Wrapf( - .WithMessage( - .WithMessagef( - .WithStack( ignorePackageGlobs: - encoding/* - github.com/pkg/* wsl: # See https://github.com/bombsimon/wsl/blob/master/doc/configuration.md for # documentation of available settings. These are the defaults for # `golangci-lint`. allow-assign-and-anything: false allow-assign-and-call: true allow-cuddle-declarations: false allow-multiline-assign: true allow-separated-leading-comment: false allow-trailing-comment: false force-case-trailing-whitespace: 0 force-err-cuddling: false force-short-decl-cuddling: false strict-append: true # The custom section can be used to define linter plugins to be loaded at runtime. # See README doc for more info. custom: # Each custom linter should have a unique name. example: # The path to the plugin *.so. Can be absolute or local. Required for each custom linter path: /path/to/example.so # The description of the linter. Optional, just for documentation purposes. description: This is an example usage of a plugin linter. # Intended to point to the repo location of the linter. Optional, just for documentation purposes. original-url: github.com/golangci/example-linter linters: disable-all: true enable: - megacheck - govet enable-all: true disable: - maligned - prealloc presets: - bugs - unused fast: false issues: # List of regexps of issue texts to exclude, empty list by default. # But independently from this option we use default exclude patterns, # it can be disabled by `exclude-use-default: false`. To list all # excluded by default patterns execute `golangci-lint run --help` exclude: - abcdef # Excluding configuration per-path, per-linter, per-text and per-source exclude-rules: # Exclude some linters from running on tests files. - path: _test\\.go linters: - gocyclo - errcheck - dupl - gosec # Exclude known linters from partially hard-vendored code, # which is impossible to exclude via \u0026#34;nolint\u0026#34; comments. - path: internal/hmac/ text: \u0026#34;weak cryptographic primitive\u0026#34; linters: - gosec # Exclude some staticcheck messages - linters: - staticcheck text: \u0026#34;SA9003:\u0026#34; # Exclude lll issues for long lines with go:generate - linters: - lll source: \u0026#34;^//go:generate \u0026#34; # Independently from option `exclude` we use default exclude patterns, # it can be disabled by this option. To list all # excluded by default patterns execute `golangci-lint run --help`. # Default value for this option is true. exclude-use-default: false # The default value is false. If set to true exclude and exclude-rules # regular expressions become case sensitive. exclude-case-sensitive: false # The list of ids of default excludes to include or disable. By default it\u0026#39;s empty. include: - EXC0002 # disable excluding of issues about comments from golint # Maximum issues count per one linter. Set to 0 to disable. Default is 50. max-issues-per-linter: 0 # Maximum count of issues with the same text. Set to 0 to disable. Default is 3. max-same-issues: 0 # Show only new issues: if there are unstaged changes or untracked files, # only those changes are analyzed, else only changes in HEAD~ are analyzed. # It\u0026#39;s a super-useful option for integration of golangci-lint into existing # large codebase. It\u0026#39;s not practical to fix all existing issues at the moment # of integration: much better don\u0026#39;t allow issues in new code. # Default is false. new: false # Show only new issues created after git revision `REV` new-from-rev: REV # Show only new issues created in git patch with set file path. new-from-patch: path/to/patch/file # Fix found issues (if it\u0026#39;s supported by the linter) fix: true severity: # Default value is empty string. # Set the default severity for issues. If severity rules are defined and the issues # do not match or no severity is provided to the rule this will be the default # severity applied. Severities should match the supported severity names of the # selected out format. # - Code climate: https://docs.codeclimate.com/docs/issues#issue-severity # - Checkstyle: https://checkstyle.sourceforge.io/property_types.html#severity # - Github: https://help.github.com/en/actions/reference/workflow-commands-for-github-actions#setting-an-error-message default-severity: error # The default value is false. # If set to true severity-rules regular expressions become case sensitive. case-sensitive: false # Default value is empty list. # When a list of severity rules are provided, severity information will be added to lint # issues. Severity rules have the same filtering capability as exclude rules except you # are allowed to specify one matcher per severity rule. # Only affects out formats that support setting severity information. rules: - linters: - dupl severity: info ","date":"2021-11-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E4%BB%A3%E7%A0%81%E6%A3%80%E6%9F%A5%E5%B7%A5%E5%85%B7-golangci-lint/","title":"Go 代码检查工具 golangci-lint"},{"content":"golang.org/x/time/rate 提供了一个使用令牌桶 Token Bucket 算法实现的限流器。\n用法 创建限流器 func NewLimiter(r Limit, b int) *Limiter  r - 每秒令牌桶中产生的 Token，为 0 则不产生 Token。 b - 令牌桶的最大容量。  r 的值类型为 float64，如果要设置超过秒以上的频率，可以使用 Every() 方法：\nlimit := Every(100 * time.Second) limiter := NewLimiter(limit, 1) 消费 Token golang.org/x/time/rate 提供了三种方式消费 Token，这三种方式在令牌桶内令牌不足时，有不同的处理方式。\nAllow/AllowN func (lim *Limiter) Allow() bool func (lim *Limiter) AllowN(now time.Time, n int) bool 在某一时刻，如果桶中 Token 数量大于等于 n，则消费 n 个 Token 并返回 true。\n如果不满足则不消费，返回 false。\nAllow 等价于 AllowN(time.Now(), 1)。\n在超出频率限制时，希望丢弃或跳过事件的时候使用此方法。\nWait/WaitN func (lim *Limiter) Wait(ctx context.Context) (err error) func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) 从令牌桶中消费 n 个 Token，如果令牌桶中 Token 数量不足，那么将会阻塞，直到 Token 数量满足。\n如果 Token 数量满足则直接返回。\nWait 方法可以使用 context 来控制超时时间。\nWait 等价于 WaitN(ctx, 1)。\n在超出频率时，如果希望有一个最长等待时间的，使用此方法。\nReserve/ReserveN func (lim *Limiter) Reserve() *Reservation func (lim *Limiter) ReserveN(now time.Time, n int) *Reservation 调用 Reserve 方法后，无论 Token 是否充足，都会消费 N 个令牌并返回一个 Reservation 对象。\n但是此时并不一定允许你执行相应逻辑，如果桶内 Token 不足，需要 Delay() 延迟一定时间执行。\n示例：\nr := lim.ReserveN(time.Now(), 1) if !r.OK() { // Not allowed to act! Did you remember to set lim.burst to be \u0026gt; 0 ?  return } time.Sleep(r.Delay()) Act() Reservation 对象拥有的方法：\nfunc (r *Reservation) Cancel() // 取消消费，并尝试返还 Token func (r *Reservation) CancelAt(now time.Time) func (r *Reservation) Delay() time.Duration // 返回需要延迟执行的时间 func (r *Reservation) DelayFrom(now time.Time) time.Duration func (r *Reservation) OK() bool // 判断令牌桶是否能提供请求的令牌数 在超出频率限制时，如果希望始终执行事件的，使用此方法。\n动态调整速率 获取限制频率和桶容量大小：\nfunc (lim *Limiter) Burst() int func (lim *Limiter) Limit() Limit 调整桶的容量大小：\nfunc (lim *Limiter) SetBurst(newBurst int) func (lim *Limiter) SetBurstAt(now time.Time, newBurst int) 调整限制频率：\nfunc (lim *Limiter) SetLimit(newLimit Limit) func (lim *Limiter) SetLimitAt(now time.Time, newLimit Limit) ","date":"2021-10-25T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E4%BB%A4%E7%89%8C%E6%A1%B6%E9%99%90%E6%B5%81%E5%99%A8-golang.org/x/time/rate/","title":"Go 令牌桶限流器 golang.org/x/time/rate"},{"content":"CSP - Communicating Sequential Process，通信顺序进程，是一种并发编程模型，用于描述两个独立的并发实体通过共享的通讯 channel 进行通信。\nCSP 中 channel 是第一类对象，它不关注发送消息的实体，而关注发送消息时使用的 channel。\n 并发编程。\n 并发程序经常出错的一个原因是人们认为自己所写代码的执行顺序是按书写的顺序来执行的，但在并发场景下，这显然是有问题的。 Atomicity，原子性。谈论原子性，必须要有一个 context。因为在一个 context 下是原子性的，但在另一个 context 下，就可能不是原子性的了。具体的 context 可能是：进程、操作系统、机器、集群……假想个例子，在一维空间中的 X 轴上，从坐标 1 到坐标 3 必须要经过坐标 2，这在一维空间中是绝对正确的。但作为活在三维空间里的人，我有很多种办法不经过 X 轴上的坐标 2 而到达坐标 3。仅管我的轨迹映射到 X 轴上还是会“经过”坐标 2，这也更像一个“降维打击”的例子。 形成死锁的四个条件：Mutual Exclusion（并发实体任意时刻独占资源）、Wait For Condition（并发实体同时持有资源并都在等待其他资源）、No Preemption（资源只能被持有它的实体释放）、Circular Wait（循环等待，a 等 b，b 等 c，c 等 a……）。 活锁是饥饿的一种，任何需要分享的资源都有可能发生饥饿，如 CPU、内存、文件句柄、数据库连接等。 并发（Concurrency）说的是代码，并行（Parallelism）说的是正在运行的程序。我们无法写出并行的代码，只能写并发的代码，并且期望它能并行执行。想象一下，我们写的代码在单核 CPU 上运行，还能并行地起来吗？ 考察并发的代码是否是在并行执行，我们得看在哪一个抽象的层级上看：并发原语、程序的运行时、操作系统、操作系统所在的平台（容器、虚拟机……）、CPUs、机器、集群…… 和前面说的 Atomicity 一样，谈论 Parallelism 时，也要有一个 context。它决定是否将能将两个操作看成并行。例如，我们运行 2 个操作，每个操作花费 1 秒。如果 context 是 5 秒钟，那可以说这两个操作是在并行执行；但如果 context 是 1 秒钟，那我们认为，这两个操作是串行地在执行。注意，context 并不等同于时间，线程、进程、操作系统等都可以看成 context。 给并发或者说并行定义什么样的 context 和并发程序是否正确运行有很大关系。例如，context 是两台电脑，我们分别在两台电脑上运行两个计算器程序，那理论上这两个计算器程序就是并行的，且不会相互影响。 在上面的例子里，context 是两台电脑，operations 是两个进程。很明显，我在我的电脑上运行任何程序，都不会影响你的电脑。但是在同一台机器上，一个进程还能保证不影响另一个进程吗？回答是不一定，比如读写同一个文件…… 大部分程序的并发抽象层级是线程。Go 在抽象层级上又增加了一个 goroutine。按理说，层级层次越高，并发安全性越难保证。但实际上 goroutine 让事情变得更容易，因为它并不是在线程的抽象层级之上又加了一层，而是取代了线程。 Go channel 的设计思想来源于 Hoare 于 1978 年发表在 ACM 上的一篇关于 CSP（Communicating Sequential Processes）的论文。Go 是第一门吸收了 CSP 精华并且将其发扬光大的语言。 大多数语言使用线程+并发同步访问控制作为并发模型，而 Go 的并发模型由 goroutine 和 channel 组成。线程类似于 goroutine，而并发同步访问控制则类似于 mutex。 Go 并发的理念是：简单，尽量使用 channel，尽情使用 goroutine。 在 linux 上，简单测试线程切换成本：  # 在 CPU0 上执行，在两个内核线程间发送、接收消息 taskset -c 0 perf bench sched pipe -T 因为是单核，所以在两个线程间发送、接收消息，需要进行上下文切换。在我的乞丐版阿里云主机上得到结果：\n# Running \u0026#39;sched/pipe\u0026#39; benchmark: # Executed 1000000 pipe operations between two threads Total time: 69.171 [sec] 69.171280 usecs/op 14456 ops/sec 计算出大致的线程切换成本：69.171280/2 = 34.58564 us。\n 使用 sync.WaitGroup 时要注意，sync.Add 要在新起 goroutine 语句的外层调用，否则执行到 sync.Wait 时，可能新起的 goroutine 还没调度到，sync.Add 自然没执行，最终导致逻辑出错。 mutex 是 mutual exclusion 的简写，翻译一下：互相排斥。 sync.cond 有两个比较有意思的方法：sync.Cond.Signal 和 sync.Cond.Broadcast。前者会唤醒等待时间最长的 goroutine，后者会唤醒所有等待的 goroutine。另外，要注意 sync.Cond.Wait 方法内部，隐藏了一些副作用，会先解锁：c.L.Unlock()，然后再加锁：c.L.Lock()。 查询 Go 源码使用了多少次 sync.Once：  grep -ir sync.Once $(go env GOROOT)/src | wc -l  channel 是粘合 goroutine 的胶水，select 则是粘合 channel 的胶水。 关于 runtime.GOMAXPROCS(n) 函数的一个可能的使用场景：代码中可能存在 data race 的情况，增加 n 值可以让 data race 更快地发生，从而可以更快地调试错误。 为了避免 goroutine 泄露，请注意：生成子 goroutine 的父 goroutine 需要负责停止子 gotoutine，即谁创建谁销毁。 可以将一个“无序、耗时长”的 stage 转成 fan-out。fan-in 是多转一，fan-out 则是一转多。 设计系统的时候，应该一开始就考虑 timeout 和 cancel。 分布式系统需要支持 timeout 的几个理由：   饱和 系统饱和时，最后到达的请求需要直接超时返回，否则可能引发雪崩； 数据过期 数据其实有一定的时间窗口，过了窗口，就是无效数据了。例如前端一个请求过来，假设用户可以容忍 2s，那这个窗口就是 2s，分布式系统需要支持 2s 的超时设置，超过 2s 后数据无效； 防止死锁 当然，触发 timeout，有可能使死锁变成活锁。系统设计的目标应该是在不触发 timeout 的情况下不发生死锁。   与上一条对应的，分布式系统应该支持 cancel 操作的几个理由：   超时 超时需要取消； 用户干预 当有用户驱动的并发操作时，用户可取消他发起的操作； 父节点取消 就像 context 一样，父 context 取消了，子 context 也要跟着取消； 重复的请求 为了得到更快的响应，同时向几个系统发起请求，当得到了最快的系统响应后，取消其他系统的请求。   可以将多个 ratelimiter 组合在一起，提供更有表达力的 ratelimiter。例如我可以限制每秒 1 个请求，同时每分钟限制 10 个请求。具体见第五章 Rate Limiting 小节。 Go 使用 fork-join 模型。fork 即 go func(){}(), 而 join 则一般是指 sync.WaitGroup 或 channels。 在一个函数里（位于某个 goroutine）不断地执行 go func(){}() 语句时，会不断地产生相应的 goroutine，并被添加到当前 goroutine 所在的 P 上的 LRQ 中，LRQ 可以看作是一个双端队列，越靠近队列尾的 goroutine 和当前 goroutine 的空间局部性越紧密，越需要优先执行。基于这点考虑，新产生的 goroutine 并不是直接放到 LRQ，而是会先放到 P 的 runnext 字段，执行完当前 goroutine 或当前 goroutine 被 park 后，首先执行的就是这个 runnext。如果之后又有新创建的 goroutine，它又会把当前挂在 runnext 上的 goroutine 顶到 LRQ 中。P 执行的时候从队列头的 goroutine 开始执行，而当 steal-working 发生时，也总是先从 LRQ 的头部偷，其实就是 FIFO。 ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/csp-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/","title":"CSP 并发编程模型"},{"content":"垃圾回收 - GC - garbage collection 是自动内存管理的一种形式。通常由垃圾收集器收集并适时回收或重用不再被对象占用的内存。\n垃圾回收作为内存管理的一部分，包含 3 个重要的功能：\n 如何分配和管理新对象。 如何识别正在使用中的对象。 如何清除不再使用的对象。  为什么需要垃圾回收 减少错误和复杂性  提供保证，不再被引用的对象将最终被收集。 避免悬空指针、多次释放等手动管理内存时出现的问题。 屏蔽了内存管理的复杂性，开发者可以更好的关注核心的业务逻辑。  解耦  避免了两个模块同时维护了同一内存时，释放内存将会变得困难的问题。业务模块将真正的实现解耦，从而有利于开发、调试并开发出更大规模、高并发项目。  缺陷 垃圾回收有额外的成本：\n 需要保存内存的状态信息（例如是否使用，是否包含指针）并扫描内存。 在很多时候，还需要中断整个程序来处理垃圾回收。  因此，在要求极致的速度和内存要求极小的场景（例如嵌入式、系统级程序）时并不适用。但是却是开发大规模、分布式、微服务应用程序的极佳选择。\n概念名词 根对象 根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：\n 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 执行栈：每个 Goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。  STW STW 是 Stop the world 或 Start the world 的缩写。指停止赋值器进一步操作对象图，从 stop 到 start 这两个动作之间的时间间隔，即万物静止。用于保证实现的正确性、防止无止境的内存增长等问题。\n此过程中整个用户代码被停止或者放缓执行，STW 越长，对用户代码造成的影响（例如延迟）就越大，对时间敏感的实时通信等应用程序会造成巨大的影响。\nGC 在需要进入 STW 时，需要通知并让所有的用户态代码停止，但是 for {} 所在的 Goroutine 永远都不会被中断，从而始终无法进入 STW 阶段。\n在自 Go 1.14 之后，这类 Goroutine 能够被异步地抢占，从而使得进入 STW 的时间不会超过抢占信号触发的周期，程序也不会因为仅仅等待一个 Goroutine 的停止而停顿在进入 STW 之前的操作上。\n经典策略 永远不可能有最好的垃圾回收算法，因为每一个应用程序所在的硬件条件、工作负载、性能要求都是不同的。\n每一种语言侧重的垃圾回收目标会不尽相同。垃圾回收的常见指标包括了程序暂停时间、空间开销、回收的及时性等，根据侧重于不同的设计目标会产生不同的垃圾回收策略。\n标记-清扫 标记-清扫（Mark-sweep）策略顾名思义分为 2 个主要的阶段：\n  第一阶段是扫描并标记当前活着的对象。\n  第二阶段是清扫没有被标记的垃圾对象。\n  因此，标记-清扫算法是一种间接的垃圾回收算法，其不是直接查找垃圾对象，而是通过活着的对象倒推出垃圾对象。\n扫描的过程一般是从栈上的根对象开始， 只要对象引用了其他的堆对象，就会一直往下扫描。因此搜索方式可以采取深度优先搜索或者广度优先搜索的方式。\n标记-清扫算法主要的缺点在于：\n 可能会产生内存碎片或空洞。这会导致由于没有连续的内存而使新对象分配失败。 一般需要在标记阶段，STW 暂停所有的程序运行。否则可能会破坏标记的结果。  标记-压缩 Mark-compact\n半空间复制 Semispace copy\n引用计数 reference counting\n分代 分代 GC 指的是将按照对象存活时间进行划分。\n这种策略的重要前提是：死去的一般都是新创建不久的对象。因此，没有必要反复的扫描旧对象。\n这大概率会加快垃圾回收的速度，提高处理能力和吞吐量，减少程序暂停的时间。\n但是分代 GC 有成本的：\n 这种策略没有办法及时回收老一代的对象。 需要额外开销引用和区分新老对象，特别是有多代的时候。  Go GC 三色标记法 Go 语言采用并发三色标记算法来进行垃圾回收。\n三色标记法是对标记-清扫法在标记阶段的改进。\n三色标记本身是最简单的一种垃圾回收策略，实现很简单。引用计数由于固有的缺陷，在并发时不可扩展的特性很少被使用，不适合 Go 这样高并发的语言。\n状态\n从垃圾回收器的视角来看，三色标记法规定了三种不同类型的对象，用不同的颜色相称：\n  白色 - 可能死亡\n在回收开始前，所有对象均为白色。当标记结束后，白色对象将被回收。\n  灰色 - 波面\n已被回收器标记，但回收器需要对其中的一个或多个指针进行扫描，因为他们可能还指向未被标记的白色对象。\n  黑色 - 确定存活\n已被回收器标记，其中所有字段都已被标记，黑色对象中任何一个指针都不可能直接指向白色对象。此对象将不会被回收。\n  算法流程\n 从 Root 对象出发扫描所有根对象，将他们引用的对象标记为灰色。 分析灰色对象是否引用了其他对象，如果没有引用其它对象则将该灰色对象标记为黑色，如果有引用则将它变为黑色的同时将它引用的对象也变为灰色。 重复步骤3，直到灰色对象队列为空，标记过程完成，等待回收白色对象。 将所有黑色对象变为白色，等待下一轮 GC。  优点：\n 最大的好处是可以异步执行标记，从而可以以中断时间极少的代价或者完全没有中断来进行整个 GC 三色标记法掌握了更多当前内存的信息，因此可以更加精确地按需调度，而不用像标记清扫法那样只能定时执行  缺点：\n 异步执行的代价是可能会造成一些遗漏，因为那些早先被标记为黑色的对象可能目前已经是不可达的了。所以三色标记法是一个 false negative 假阴性的算法。  并发三色标记法的问题 垃圾回收器的正确性体现在：不应出现对象的丢失，也不应错误的回收还不需要回收的对象。\n当以下两种情况同时发生时，会破坏并发垃圾回收器的正确性：\n  赋值器使一个黑色对象引用了白色对象。\n  赋值器断开了灰色对象与白色对象间未经垃圾回收器访问过的关系。\n  只要能够避免其中任何一个条件，都不会出现对象丢失的情况，因为：\n  如果 1 被避免，则所有白色对象均被灰色对象引用，没有白色对象会被遗漏。\n  如果 2 被避免，即便白色对象的指针被写入到黑色对象中，但从灰色对象出发，总存在一条没有访问过的路径，从而找到到达白色对象的路径，白色对象最终不会被遗漏。\n  写屏障、混合写屏障 写屏障是一个在并发垃圾回收器中才会出现的概念。\n强三色不变式 弱三色不变式 GC 流程  Mark Setup 标记准备阶段，STW 并打开 Write Barrier 开始标记 Mark Termination 标记结束，STW Sweeping 开始清理，并发执行  标记准备 Go GC 总结 历史演进  Go 1：串行三色标记清扫 Go 1.3：并行清扫，标记过程需要 STW，停顿时间在约几百毫秒 Go 1.5：并发标记清扫，停顿时间在一百毫秒以内 Go 1.6：使用 bitmap 来记录回收内存的位置，大幅优化垃圾回收器自身消耗的内存，停顿时间在十毫秒以内 Go 1.7：停顿时间控制在两毫秒以内 Go 1.8：混合写屏障，停顿时间在半个毫秒左右 Go 1.9：彻底移除了栈的重扫描过程 Go 1.12：整合了两个阶段的 Mark Termination，但引入了一个严重的 GC Bug 至今未修（见问题 20），尚无该 Bug 对 GC 性能影响的报告 Go 1.13：着手解决向操作系统归还内存的，提出了新的 Scavenger Go 1.14：替代了仅存活了一个版本的 scavenger，全新的页分配器，优化分配内存过程的速率与现有的扩展性问题，并引入了异步抢占，解决了由于密集循环导致的 STW 时间过长的问题  内存泄漏 在具有 GC 的语言中，内存泄漏用严谨的话来说应该是：\n 预期能很快被释放的内存由于附着在了长期存活的内存上、或生命期意外地被延长，导致预计能够立即回收的内存长时间得不到回收。\n Go 中内存泄漏的几种情况：\n  被根对象引用\n当有一个全局对象时，可能不经意间将某个变量附着在其上，且忽略的将其进行释放，则该内存永远不会得到释放。\n  Goroutine 泄漏\nGoroutine 作为一种逻辑上理解的轻量级线程，在运行过程中需要消耗一定的内存来保存用户代码的上下文信息。\n因此，如果一个程序持续不断地产生新的 Goroutine、且不结束已经创建的 Goroutine 并复用这部分内存，就会造成内存泄漏的现象。\n  Channel 泄漏\nChannel 作为一种同步原语，会连接两个不同的 Goroutine，如果一个 Goroutine 尝试向一个没有接收方的无缓冲 Channel 发送消息，则该 Goroutine 会被永久的休眠，整个 Goroutine 及其执行栈都得不到释放。\n ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-gc-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","title":"Go GC 垃圾回收"},{"content":"Gorm 常见 CRUD 操作 API。\n通用操作 批量操作 最简单的方法是使用 Table() 方法，指定要操作的表名，这时候进行 CRUD 操作就是批量的。\ndb.Table(\u0026#34;users\u0026#34;).Update(...) 或者使用 Model()，传入没有主键的模型实例，没有指定主键的话 Gorm 默认会使用批量操作，一般惯常用法是使用空的主键实例。\ndb.Model(User{}).Update(...) 根据主键操作 使用 Model() 方法，如果传入的模型实例有主键值，那么会默认只操作符合主键值的单条数据。\nuser := User{ID: 1} db.Model(\u0026amp;user).Update(...) where 除了使用主键选定操作数据，还可以使用 Where 设定条件。\n// Get first matched record // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39; limit 1; db.Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).First(\u0026amp;user) // Get all matched records // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39;; db.Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Find(\u0026amp;users) // \u0026lt;\u0026gt; // SELECT * FROM users WHERE name \u0026lt;\u0026gt; \u0026#39;jinzhu\u0026#39;; db.Where(\u0026#34;name \u0026lt;\u0026gt; ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Find(\u0026amp;users) // IN // SELECT * FROM users WHERE name in (\u0026#39;jinzhu\u0026#39;,\u0026#39;jinzhu 2\u0026#39;); db.Where(\u0026#34;name IN (?)\u0026#34;, []string{\u0026#34;jinzhu\u0026#34;, \u0026#34;jinzhu 2\u0026#34;}).Find(\u0026amp;users) // LIKE // SELECT * FROM users WHERE name LIKE \u0026#39;%jin%\u0026#39;; db.Where(\u0026#34;name LIKE ?\u0026#34;, \u0026#34;%jin%\u0026#34;).Find(\u0026amp;users) // AND // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39; AND age \u0026gt;= 22; db.Where(\u0026#34;name = ? AND age \u0026gt;= ?\u0026#34;, \u0026#34;jinzhu\u0026#34;, \u0026#34;22\u0026#34;).Find(\u0026amp;users) // Time // SELECT * FROM users WHERE updated_at \u0026gt; \u0026#39;2000-01-01 00:00:00\u0026#39;; db.Where(\u0026#34;updated_at \u0026gt; ?\u0026#34;, lastWeek).Find(\u0026amp;users) // BETWEEN // SELECT * FROM users WHERE created_at BETWEEN \u0026#39;2000-01-01 00:00:00\u0026#39; AND \u0026#39;2000-01-08 00:00:00\u0026#39;; db.Where(\u0026#34;created_at BETWEEN ? AND ?\u0026#34;, lastWeek, today).Find(\u0026amp;users) // Struct // SELECT * FROM users WHERE name = \u0026#34;jinzhu\u0026#34; AND age = 20 LIMIT 1; db.Where(\u0026amp;User{Name: \u0026#34;jinzhu\u0026#34;, Age: 20}).First(\u0026amp;user) // Map // SELECT * FROM users WHERE name = \u0026#34;jinzhu\u0026#34; AND age = 20; db.Where(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;jinzhu\u0026#34;, \u0026#34;age\u0026#34;: 20}).Find(\u0026amp;users) // 主键的切片 // SELECT * FROM users WHERE id IN (20, 21, 22); db.Where([]int64{20, 21, 22}).Find(\u0026amp;users) not 与 Where 相反。\n// SELECT * FROM users WHERE name \u0026lt;\u0026gt; \u0026#34;jinzhu\u0026#34; LIMIT 1; db.Not(\u0026#34;name\u0026#34;, \u0026#34;jinzhu\u0026#34;).First(\u0026amp;user) // Not In // SELECT * FROM users WHERE name NOT IN (\u0026#34;jinzhu\u0026#34;, \u0026#34;jinzhu 2\u0026#34;); db.Not(\u0026#34;name\u0026#34;, []string{\u0026#34;jinzhu\u0026#34;, \u0026#34;jinzhu 2\u0026#34;}).Find(\u0026amp;users) // Not In slice of primary keys // SELECT * FROM users WHERE id NOT IN (1,2,3); db.Not([]int64{1,2,3}).First(\u0026amp;user) // SELECT * FROM users; db.Not([]int64{}).First(\u0026amp;user) // Plain SQL // SELECT * FROM users WHERE NOT(name = \u0026#34;jinzhu\u0026#34;); db.Not(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).First(\u0026amp;user) // Struct // SELECT * FROM users WHERE name \u0026lt;\u0026gt; \u0026#34;jinzhu\u0026#34;; db.Not(User{Name: \u0026#34;jinzhu\u0026#34;}).First(\u0026amp;user) or // SELECT * FROM users WHERE role = \u0026#39;admin\u0026#39; OR role = \u0026#39;super_admin\u0026#39;; db.Where(\u0026#34;role = ?\u0026#34;, \u0026#34;admin\u0026#34;).Or(\u0026#34;role = ?\u0026#34;, \u0026#34;super_admin\u0026#34;).Find(\u0026amp;users) // Struct // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39; OR name = \u0026#39;jinzhu 2\u0026#39;; db.Where(\u0026#34;name = \u0026#39;jinzhu\u0026#39;\u0026#34;).Or(User{Name: \u0026#34;jinzhu 2\u0026#34;}).Find(\u0026amp;users) // Map // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39; OR name = \u0026#39;jinzhu 2\u0026#39;; db.Where(\u0026#34;name = \u0026#39;jinzhu\u0026#39;\u0026#34;).Or(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;jinzhu 2\u0026#34;}).Find(\u0026amp;users) order 排序，设置第二个参数 reorder 为 true ，可以覆盖前面定义的排序条件。\n// SELECT * FROM users ORDER BY age desc, name; db.Order(\u0026#34;age desc, name\u0026#34;).Find(\u0026amp;users) // 多字段排序 // SELECT * FROM users ORDER BY age desc, name; db.Order(\u0026#34;age desc\u0026#34;).Order(\u0026#34;name\u0026#34;).Find(\u0026amp;users) // 覆盖排序 // SELECT * FROM users ORDER BY age desc; (users1) // SELECT * FROM users ORDER BY age; (users2) db.Order(\u0026#34;age desc\u0026#34;).Find(\u0026amp;users1).Order(\u0026#34;age\u0026#34;, true).Find(\u0026amp;users2) limit // SELECT * FROM users LIMIT 3; db.Limit(3).Find(\u0026amp;users) // -1 取消 Limit 条件 // SELECT * FROM users LIMIT 10; (users1) // SELECT * FROM users; (users2) db.Limit(10).Find(\u0026amp;users1).Limit(-1).Find(\u0026amp;users2) offset // SELECT * FROM users OFFSET 3; db.Offset(3).Find(\u0026amp;users) // -1 取消 Offset 条件 // SELECT * FROM users OFFSET 10; (users1) // SELECT * FROM users; (users2) db.Offset(10).Find(\u0026amp;users1).Offset(-1).Find(\u0026amp;users2) count Count 必须是链式查询的最后一个操作 ，因为它会覆盖前面的 SELECT，但如果里面使用了 count 时不会覆盖。\n// SELECT * from USERS WHERE name = \u0026#39;jinzhu\u0026#39; OR name = \u0026#39;jinzhu 2\u0026#39;; (users) // SELECT count(*) FROM users WHERE name = \u0026#39;jinzhu\u0026#39; OR name = \u0026#39;jinzhu 2\u0026#39;; (count) db.Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Or(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu 2\u0026#34;).Find(\u0026amp;users).Count(\u0026amp;count) // SELECT count(*) FROM users WHERE name = \u0026#39;jinzhu\u0026#39;; (count) db.Model(\u0026amp;User{}).Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Count(\u0026amp;count) // SELECT count(*) FROM deleted_users; db.Table(\u0026#34;deleted_users\u0026#34;).Count(\u0026amp;count) // SELECT count( distinct(name) ) FROM deleted_users; db.Table(\u0026#34;deleted_users\u0026#34;).Select(\u0026#34;count(distinct(name))\u0026#34;).Count(\u0026amp;count()) 插入 判断数据是否存在于数据库中：\nuser := User{Name: \u0026#34;Jinzhu\u0026#34;, Age: 18, Birthday: time.Now()} db.NewRecord(user) 插入数据：\ndb.Create(\u0026amp;user) 插入前处理 如果想在插入数据前做一定的处理，可以为模型设置 BeforeCreate() 方法：\nfunc (user *User) BeforeCreate(scope *gorm.Scope) error { scope.SetColumn(\u0026#34;ID\u0026#34;, uuid.New()) return nil } 查询 查询单条数据时可以使用单个 user 接收数据，如果查询到的是多条数据，需要使用切片 users 进行接收。\n根据主键查询数据 // 根据主键查询第一条记录 // SELECT * FROM users ORDER BY id LIMIT 1; db.First(\u0026amp;user) // 随机获取一条记录 // SELECT * FROM users LIMIT 1; db.Take(\u0026amp;user) // 根据主键查询最后一条记录 // SELECT * FROM users ORDER BY id DESC LIMIT 1; db.Last(\u0026amp;user) // 查询所有的记录 // SELECT * FROM users; db.Find(\u0026amp;users) // 查询指定的某条记录(仅当主键为整型时可用) // SELECT * FROM users WHERE id = 10; db.First(\u0026amp;user, 10) 内联条件 当多个立即执行方法一起使用时，会默认共享前一个执行方法的条件。如果不希望共享，可以使用内联条件。\n// 根据主键获取记录 (只适用于整形主键) // SELECT * FROM users WHERE id = 23 LIMIT 1; db.First(\u0026amp;user, 23) // 根据主键获取记录, 如果它是一个非整形主键 // SELECT * FROM users WHERE id = \u0026#39;string_primary_key\u0026#39; LIMIT 1; db.First(\u0026amp;user, \u0026#34;id = ?\u0026#34;, \u0026#34;string_primary_key\u0026#34;) // Plain SQL // SELECT * FROM users WHERE name = \u0026#34;jinzhu\u0026#34;; db.Find(\u0026amp;user, \u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;) // SELECT * FROM users WHERE name \u0026lt;\u0026gt; \u0026#34;jinzhu\u0026#34; AND age \u0026gt; 20; db.Find(\u0026amp;users, \u0026#34;name \u0026lt;\u0026gt; ? AND age \u0026gt; ?\u0026#34;, \u0026#34;jinzhu\u0026#34;, 20) // Struct // SELECT * FROM users WHERE age = 20; db.Find(\u0026amp;users, User{Age: 20}) // Map // SELECT * FROM users WHERE age = 20; db.Find(\u0026amp;users, map[string]interface{}{\u0026#34;age\u0026#34;: 20}) 更新 db.First(\u0026amp;user) user.Name = \u0026#34;jinzhu 2\u0026#34; user.Age = 100 db.Save(\u0026amp;user) Save 会更新所有字段，即使你没有更改这个字段的值。\n更新指定字段 只更新指定的字段可以使用 Update 或 Updates。\n  更新单个字段\ndb.Model(\u0026amp;user).Update(\u0026#34;name\u0026#34;, \u0026#34;hello\u0026#34;) // UPDATE users SET name=\u0026#39;hello\u0026#39;, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111; db.Model(\u0026amp;user).Where(\u0026#34;active = ?\u0026#34;, true).Update(\u0026#34;name\u0026#34;, \u0026#34;hello\u0026#34;) // UPDATE users SET name=\u0026#39;hello\u0026#39;, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111 AND active=true;   使用 map 更新多个字段\ndb.Model(\u0026amp;user).Updates(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 18, \u0026#34;actived\u0026#34;: false}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18, actived=false, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111;   使用 struct 更新多个字段，只会更新其中有变化且为非零值的字段\ndb.Model(\u0026amp;user).Updates(User{Name: \u0026#34;hello\u0026#34;, Age: 18}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18, updated_at = \u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id = 111; 零值的字段不会发生任何更新，以下操作将没有任何更新\ndb.Model(\u0026amp;user).Updates(User{Name: \u0026#34;\u0026#34;, Age: 0, Actived: false})   更新时选定或者排除某些字段\n// Select 选定某些字段 // UPDATE users SET name=\u0026#39;hello\u0026#39;, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111; db.Model(\u0026amp;user).Select(\u0026#34;name\u0026#34;).Updates(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 18, \u0026#34;actived\u0026#34;: false}) // Omit 排除某些字段 //// UPDATE users SET age=18, actived=false, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111; db.Model(\u0026amp;user).Omit(\u0026#34;name\u0026#34;).Updates(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 18, \u0026#34;actived\u0026#34;: false})   忽略中间件 使用 Update 和 Updates 更新时会调用默认的 BeforeUpdate() 和 AfterUpdate 方法，这些默认方法会更新 UpdateAt 时间戳。\n如果想不调用这些方法，可以使用 UpdateColumn， UpdateColumns。\n// 更新单个属性，类似于 `Update` db.Model(\u0026amp;user).UpdateColumn(\u0026#34;name\u0026#34;, \u0026#34;hello\u0026#34;) //// UPDATE users SET name=\u0026#39;hello\u0026#39; WHERE id = 111;  // 更新多个属性，类似于 `Updates` db.Model(\u0026amp;user).UpdateColumns(User{Name: \u0026#34;hello\u0026#34;, Age: 18}) //// UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18 WHERE id = 111; 使用 SQL 表达式 DB.Model(\u0026amp;product).Update(\u0026#34;price\u0026#34;, gorm.Expr(\u0026#34;price * ? + ?\u0026#34;, 2, 100)) //// UPDATE \u0026#34;products\u0026#34; SET \u0026#34;price\u0026#34; = price * \u0026#39;2\u0026#39; + \u0026#39;100\u0026#39;, \u0026#34;updated_at\u0026#34; = \u0026#39;2013-11-17 21:34:10\u0026#39; WHERE \u0026#34;id\u0026#34; = \u0026#39;2\u0026#39;; 删除 删除时确保主键字段有值，GORM 会通过主键去删除记录，如果主键为空，GORM 会删除该 model 的所有记录。\ndb.Delete(\u0026amp;email) 批量删除\ndb.Where(\u0026#34;email LIKE ?\u0026#34;, \u0026#34;%jinzhu%\u0026#34;).Delete(Email{}) //// DELETE from emails where email LIKE \u0026#34;%jinzhu%\u0026#34;;  db.Delete(Email{}, \u0026#34;email LIKE ?\u0026#34;, \u0026#34;%jinzhu%\u0026#34;) //// DELETE from emails where email LIKE \u0026#34;%jinzhu%\u0026#34;; ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-gorm-crud/","title":"Go Gorm CRUD"},{"content":"对开发者友好的 Go ORM 库，v2 版本。\n安装：\ngo get -u gorm.io/gorm 导入：\nimport \u0026#34;gorm.io/gorm\u0026#34; 连接数据库 数据库驱动 Gorm 官方支持 MySQL、PostgreSQL、SQLite、SQL Server 四个数据库。\nimport \u0026#34;gorm.io/driver/mysql\u0026#34; import \u0026#34;gorm.io/driver/postgres\u0026#34; import \u0026#34;gorm.io/driver/sqlite\u0026#34; import \u0026#34;gorm.io/driver/sqlserver\u0026#34; 建立连接 使用 gorm.Open()方法建立连接。\nMySQL   要正确处理 time.Time，需要添加 parseTime 参数。\n  要完全支持 UTF-8 编码，需要修改charset=utf8 为 charset=utf8mb4。\n  例子：\nimport ( \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) func main() { dsn := \u0026#34;user:pass@tcp(127.0.0.1:3306)/dbname?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) } PostgreSQL import ( \u0026#34;gorm.io/driver/postgres\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) dsn := \u0026#34;user=gorm password=gorm dbname=gorm port=9920 sslmode=disable TimeZone=Asia/Shanghai\u0026#34; db, err := gorm.Open(postgres.Open(dsn), \u0026amp;gorm.Config{}) Gorm 使用 pgx 作为 postgres 的 database/sql 驱动，默认情况下，它会启用 prepared statement 缓存，可以这样禁用它：\ndb, err := gorm.Open(postgres.New(postgres.Config{ DSN: \u0026#34;user=gorm password=gorm dbname=gorm port=9920 sslmode=disable TimeZone=Asia/Shanghai\u0026#34;, PreferSimpleProtocol: true, // disables implicit prepared statement usage }), \u0026amp;gorm.Config{}) 连接池 GORM 使用 database/sql 维护连接池，db.DB() 方法可用于从当前 *gorm.DB 返回一个通用的数据库接口 *sql.DB。\n可以使用此接口设定连接池参数。\nsqlDB, err := db.DB() // SetMaxIdleConns 设置空闲连接池中连接的最大数量 sqlDB.SetMaxIdleConns(10) // SetMaxOpenConns 设置打开数据库连接的最大数量。 sqlDB.SetMaxOpenConns(100) // SetConnMaxLifetime 设置了连接可复用的最大时间。 sqlDB.SetConnMaxLifetime(time.Hour) 模型 模型使用 Struct 的 Tag 来对字段进行设置。字段支持基本的 Go 类型或它们的指针，以及 database/sql 库中的 sql.Scanner 和 driver.Valuer 接口。\n例子：\ntype User struct { ID uint Name string Email *string Age uint8 Birthday *time.Time MemberNumber sql.NullString ActivedAt sql.NullTime CreatedAt time.Time UpdatedAt time.Time } 约定 Gorm 使用了一系列的约定来定义默认的行为：\n 默认使用 ID 字段作为表的主键，可以通过标签 primaryKey 将其它字段设为主键 默认使用结构体名的 蛇形命名 的复数作为表名。对于结构体 User，根据约定，其表名为 users 数据表的列名使用的是 struct 字段名的 蛇形命名。CreatedAt 字段的列名是 created_at 对于有 CreatedAt 字段的模型，创建记录时，如果该字段值为零值，则将该字段的值设为当前时间 对于有 UpdatedAt 字段的模型，更新记录时，将该字段的值设为当前时间。  Gorm 提供了一个 gorm.Model 结构体，提供了这些字段：\ntype Model struct { ID uint `gorm:\u0026#34;primaryKey\u0026#34;` CreatedAt time.Time UpdatedAt time.Time DeletedAt gorm.DeletedAt `gorm:\u0026#34;index\u0026#34;` } 可以非常方便的将它嵌入到需要的结构体中：\ntype User struct { gorm.Model Name string } Tag 注意：\n Tag 不区分大小写     Tag 描述     column 指定列名   type 列数据类型，推荐使用兼容性好的通用类型，例如：所有数据库都支持 bool、int、uint、float、string、time、bytes 并且可以和其他标签一起使用，例如：not null、size, autoIncrement… 像 varbinary(8) 这样指定数据库数据类型也是支持的。在使用指定数据库数据类型时，它需要是完整的数据库数据类型，如：MEDIUMINT UNSINED not NULL AUTO_INSTREMENT   size 指定列大小, 默认值255   primaryKey 将列指定为主键   unique 将列指定为唯一   default 指定列默认值   precision 指定列精度   scale 指定列大小   not null 将列指定为非 NULL   autoIncrement 指定列为自增类型   embedded 将结构设置为嵌入   embeddedPrefix 设置嵌入结构的前缀   autoCreateTime 创建时追踪当前时间，对于 int 字段，它会追踪时间戳秒数，您可以使用 nano/milli 来追踪纳秒、毫秒时间戳，例如：autoCreateTime:nano   autoUpdateTime 创建/更新时追踪当前时间，对于 int 字段，它会追踪时间戳秒数，您可以使用 nano/milli 来追踪纳秒、毫秒时间戳，例如：autoUpdateTime:milli   index 根据参数创建索引，多个字段使用相同的名称则创建复合索引   uniqueIndex 与 index 相同，但创建的是唯一索引   check 创建检查约束，例如 check:age \u0026gt; 13   \u0026lt;- 设置字段写入的权限， \u0026lt;-:create 只创建、\u0026lt;-:update 只更新、\u0026lt;-:false 无写入权限、\u0026lt;- 创建和更新权限   -\u0026gt; 设置字段读的权限，-\u0026gt;:false 无读权限   - 忽略此字段    关联模型的 Tag    Tag 描述     Many2Many 指定连接表   ForeignKey 设置外键   Association_ForeignKey 设置关联外键   Polymorphic 指定多态类型   Polymorphic_Value 指定多态值   JoinTable_ForeignKey 指定连接表的外键   Association_JoinTable_ForeignKey 指定连接表的关联外键   Save_Associations 是否自动完成 save 的相关操作   Association_AutoUpdate 是否自动完成 update 的相关操作   Association_AutoCreate 是否自动完成 create 的相关操作   Association_Save_Reference 是否自动完成引用的 save 的相关操作    默认值 当通过结构体进行 CURD 操作时，GORM 将会只通过非零值字段操作，这意味着如果你的字段值为0，''， false 或者其他零值时，将不会被用于构建 sql 语句。\n存储时如果为零值，会使用 Tag 设定的默认值，没有设定默认值则使用数据库的默认值。\n所以 gorm 无法区分是故意设置的零值，还是没有设置值，如果需要区分，模型的字段类型可以使用指针或者 Scanner/Valuer 接口。\n指针：\ntype User struct { gorm.Model Name string Age *int `gorm:\u0026#34;default:18\u0026#34;` } Scanner/Valuer:\ntype User struct { gorm.Model Name string Age sql.NullInt64 `gorm:\u0026#34;default:18\u0026#34;` } 数据表 模型的表名可以使用 TableName() 方法设定：\nfunc (User) TableName() string { return \u0026#34;users\u0026#34; }   检查表是否存在\ndb.HasTable(\u0026amp;User{}) db.HasTable(\u0026#34;users\u0026#34;)   建表\ndb.CreateTable(\u0026amp;User{})   删除\n传入多个表名或多个模型可以删除多张表，如果表不存在会在 Error 中保存异常信息。\ndb.DropTable(\u0026amp;User{}) db.DropTable(\u0026#34;users\u0026#34;) db.DropTableIfExists(\u0026amp;User{}, \u0026#34;products\u0026#34;) // 当表存在时才删除表   更改模型   修改字段类型\n修改模型 User 的 description 列的数据类型为 text\ndb.Model(\u0026amp;User{}).ModifyColumn(\u0026#34;description\u0026#34;, \u0026#34;text\u0026#34;)   删除字段\n删除模型 User 的 description 列\ndb.Model(\u0026amp;User{}).DropColumn(\u0026#34;description\u0026#34;)  ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-gorm-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E4%B8%8E%E6%A8%A1%E5%9E%8B/","title":"Go Gorm 数据库连接与模型"},{"content":"作为一种基本数据结构，每种语言都有一些对于字符串的预定义处理函数。Go 中使用 strings 包来完成对字符串的主要操作。\n判断前后缀 // 判断字符串 s 是否以 prefix 开头 strings.HasPrefix(s, prefix string) bool // 判断字符串 s 是否以 prefix 结尾 strings.HasSuffix(s, suffix string) bool 判断包含关系 // 判断字符串 s 是否包含 substr strings.Contains(s, substr string) bool 判断位置 Index 返回字符串 str 在字符串 s 中的索引（str 的第一个字符的索引），-1 表示字符串 s 不包含字符串 str：\nstrings.Index(s, str string) int LastIndex 返回字符串 str 在字符串 s 中最后出现位置的索引（str 的第一个字符的索引），-1 表示字符串 s 不包含字符串 str：\nstrings.LastIndex(s, str string) int 如果 ch 是非 ASCII 编码的字符，建议使用以下函数来对字符进行定位：\nstrings.IndexRune(s string, r rune) int 替换 Replace 用于将字符串 str 中的前 n 个字符串 old 替换为字符串 new，并返回一个新的字符串，如果 n = -1 则替换所有字符串 old 为字符串 new：\nstrings.Replace(str, old, new, n) string 统计出现次数 // 计算字符串 str 在字符串 s 中出现的非重叠次数 strings.Count(s, str string) int 重复字符串 // 用于重复 count 次字符串 s 并返回一个新的字符串： strings.Repeat(s, count int) string 大小写 // 将字符串中的 Unicode 字符全部转换为相应的小写字符 strings.ToLower(s) string // 将字符串中的 Unicode 字符全部转换为相应的大写字符 strings.ToUpper(s) string 裁剪前后 修剪掉 s 字符串前后，由 unicode 指定的空格字符，包括 \\n\\t\\r\\n\nfunc TrimSpace(s string) string 修剪掉 s 字符串前后的 cutset 字符，可以直接指定多个字符\nfunc Trim(s string, cutset string) string func TrimLeft(s string, cutset string) string func TrimRight(s string, cutset string) string 传入一个函数来依次判断字符是否需要被剪裁\nfunc TrimFunc(s string, f func(rune) bool) string func TrimLeftFunc(s string, f func(rune) bool) string func TrimRightFunc(s string, f func(rune) bool) string 修剪掉 s 字符串前后特定的 prefix 字符串前后缀\nfunc TrimPrefix(s, prefix string) string func TrimSuffix(s, suffix string) string 分割字符串 strings.Fields(s) 将会利用 1 个或多个空白符号来作为动态长度的分隔符将字符串分割成若干小块，并返回一个 slice，如果字符串只包含空白符号，则返回一个长度为 0 的 slice。\nstrings.Split(s, sep) 用于自定义分割符号来对指定字符串进行分割，同样返回 slice。\n因为这 2 个函数都会返回 slice，所以习惯使用 for-range 循环来对其进行处理。\n拼接 strings.Join(sl []string, sep string) string 从字符串中读取内容 函数 strings.NewReader(str) 用于生成一个 Reader 并读取字符串中的内容，然后返回指向该 Reader的指针，从其它类型读取内容的函数还有：\n Read() 从 []byte 中读取内容。 ReadByte() 和 ReadRune() 从字符串中读取下一个 byte 或者 rune。 ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86-strings/","title":"Go 字符串处理 strings"},{"content":"Strconv 包含了一些变量用于获取程序运行的操作系统平台下 int 类型所占的位数，如：strconv.IntSize。\n任何类型 T 转换为字符串总是成功的。\nInt // int 转 string strconv.Itoa(i int) string // string 转 int strconv.Atoi(s string) (i int, err error) Float // float 转 string strconv.FormatFloat(f float64, fmt byte, prec int, bitSize int) string // string 转 float strconv.ParseFloat(s string, bitSize int) (f float64, err error)  fmt - 数据格式 prec - 数据精度 bitSize - 浮点型大小，32 表示 float32，64 表示 float64 ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2-strconv/","title":"Go 字符串类型转换 strconv"},{"content":"","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E6%A0%87%E5%87%86%E5%BA%93-io/","title":"Go 标准库 io"},{"content":"","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E6%A0%87%E5%87%86%E5%BA%93-ioutil/","title":"Go 标准库 ioutil"},{"content":"这是一个主要功能为从 Json 中提取值的包。\n安装：\ngo get -u github.com/tidwall/gjson 获取 Json 值 获取单个值 获取值最常用的是这两个方法，可以直接从 Json 数据中根据你提供的 path 提取结果。\nGetBytes 需要的是 []byte 数据。\n方法将返回一个类型为 Result 的结果。\nfunc Get(json, path string) Result func GetBytes(json []byte, path string) Result 获取多个值 如果要同时获取多个值，可以使用以下方法。\nfunc GetMany(json string, path ...string) []Result func GetManyBytes(json []byte, path ...string) []Result 这两个方法可以传入多个 path 路径，返回的是一个以 Result 组成的切片。\n解析 将 Json 数据直接解析成 Result。\nfunc Parse(json string) Result func ParseBytes(json []byte) Result 路径语法 Gjson 的路径主要由 . 分割的字段名构成，其中还包含一些特殊的符号。\n以下是一个示例 Json 数据：\n{ \u0026#34;name\u0026#34;: {\u0026#34;first\u0026#34;: \u0026#34;Tom\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Anderson\u0026#34;}, \u0026#34;age\u0026#34;:37, \u0026#34;children\u0026#34;: [\u0026#34;Sara\u0026#34;,\u0026#34;Alex\u0026#34;,\u0026#34;Jack\u0026#34;], \u0026#34;fav.movie\u0026#34;: \u0026#34;Deer Hunter\u0026#34;, \u0026#34;friends\u0026#34;: [ {\u0026#34;first\u0026#34;: \u0026#34;Dale\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Murphy\u0026#34;, \u0026#34;age\u0026#34;: 44, \u0026#34;nets\u0026#34;: [\u0026#34;ig\u0026#34;, \u0026#34;fb\u0026#34;, \u0026#34;tw\u0026#34;]}, {\u0026#34;first\u0026#34;: \u0026#34;Roger\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Craig\u0026#34;, \u0026#34;age\u0026#34;: 68, \u0026#34;nets\u0026#34;: [\u0026#34;fb\u0026#34;, \u0026#34;tw\u0026#34;]}, {\u0026#34;first\u0026#34;: \u0026#34;Jane\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Murphy\u0026#34;, \u0026#34;age\u0026#34;: 47, \u0026#34;nets\u0026#34;: [\u0026#34;ig\u0026#34;, \u0026#34;tw\u0026#34;]} ] } 基础语法 以下是通过 . 代表层级递进的语法：\nname.last \u0026#34;Anderson\u0026#34; name.first \u0026#34;Tom\u0026#34; age 37 children [\u0026#34;Sara\u0026#34;,\u0026#34;Alex\u0026#34;,\u0026#34;Jack\u0026#34;] Json 数组可以使用数字序号选取具体值：\nchildren.0 \u0026#34;Sara\u0026#34; children.1 \u0026#34;Alex\u0026#34; friends.1 {\u0026#34;first\u0026#34;: \u0026#34;Roger\u0026#34;, \u0026#34;last\u0026#34;: \u0026#34;Craig\u0026#34;, \u0026#34;age\u0026#34;: 68} friends.1.first \u0026#34;Roger\u0026#34; 注意：特殊符号 *, ?, . 等符号如果出现在 Json 字段名中，则路径需要使用 \\ 转义。\n通配符 路径中可以使用通配符 * 和 ?。\n * 代表任意多个任意字符 ? 代表一个任意字符  child*.2 \u0026#34;Jack\u0026#34; c?ildren.0 \u0026#34;Sara\u0026#34; 查询语法 Json 数组还可以使用 # 来进一步获取值：\nfriends.# 3 // friends 数组元素的数量 friends.#.age [44,68,47] // 单独获取 friends 数组元素的 age 字段 除此以外，Gjson 还支持类似数据库的查询语法：\n #(...) 代表根据括号里的条件查询单个结果 #(...)# 代表根据括号里的条件查询所有结果  例如：\nfriends.#(last==\u0026#34;Murphy\u0026#34;).first \u0026#34;Dale\u0026#34; friends.#(last==\u0026#34;Murphy\u0026#34;)#.first [\u0026#34;Dale\u0026#34;,\u0026#34;Jane\u0026#34;] friends.#(age\u0026gt;45)#.last [\u0026#34;Craig\u0026#34;,\u0026#34;Murphy\u0026#34;] friends.#(first%\u0026#34;D*\u0026#34;).last \u0026#34;Murphy\u0026#34; friends.#(first!%\u0026#34;D*\u0026#34;).last \u0026#34;Craig\u0026#34; 修饰符 使用修饰符可以实现一些特定的效果，目前有三个内置的修饰符：\n @reverse 反转一个数组内元素的顺序 @ugly 移除 Json 中所有的空格 @pretty 美化 Json 的显示  例子：\nchildren.@reverse [\u0026#34;Jack\u0026#34;,\u0026#34;Alex\u0026#34;,\u0026#34;Sara\u0026#34;] children.@reverse.0 \u0026#34;Jack\u0026#34; 其中 @pretty 还可以使用一些参数，例如：\n@pretty:{\u0026#34;sortKeys\u0026#34;:true} 其可以使用的参数有：sortKeys, indent, prefix, and width.\nResult Gjson 获取的内容都是 Result 类型的数据。\n获取值数据 确定值的类型的获取方法\nfunc (t Result) String() string func (t Result) Int() int64 func (t Result) Uint() uint64 func (t Result) Float() float64 func (t Result) Bool() bool func (t Result) Array() []Result func (t Result) Map() map[string]Result func (t Result) Time() time.Time 还有一个方法，返回不确定类型的值，需要进行类型断言\nfunc (t Result) Value() interface{} 值的类型为以下其中之一\nboolean \u0026gt;\u0026gt; bool number \u0026gt;\u0026gt; float64 string \u0026gt;\u0026gt; string null \u0026gt;\u0026gt; nil array \u0026gt;\u0026gt; []interface{} object \u0026gt;\u0026gt; map[string]interface{} 功能方法 // 用于链式调用获取值 func (t Result) Get(path string) Result // 判断值是否存在 func (t Result) Exists() bool // 判断值是否是一个 Json 对象 func (t Result) IsObject() bool // 用于遍历值，函数中返回 false 会停止遍历 func (t Result) ForEach(iterator func(key, value Result) bool) func (t Result) Less(token Result, caseSensitive bool) bool 字段 Result 还含有一些有用的字段。\nresult.Type // Reault 类型 Number, True, False, Null, JSON result.Str // 获取字符串值 result.Num // 获取数值 result.Raw // 获取原始的 Json 文本 result.Index // 在原始 Json 数据中的索引，0 表示 Gjson无法识别 检查 Json 在使用 Get 等方法获取值时，默认给予的 Json 数据为格式正确的，如果格式错误并不会报错，只会返回期望外的数据。\n所以，如果希望验证 Json 格式的正确性，可以在获取值前先行验证 Json 数据的格式：\nif !gjson.Valid(json) { return errors.New(\u0026#34;invalid json\u0026#34;) } value := gjson.Get(json, \u0026#34;name.last\u0026#34;) Bytes 数据 如果希望全程使用 []byte 处理数据，而避免将 result.Raw 从字符串转换为 []byte，可以使用以下方法：\nvar json []byte = ... result := gjson.GetBytes(json, path) var raw []byte if result.Index \u0026gt; 0 { raw = json[result.Index:result.Index+len(result.Raw)] } else { raw = []byte(result.Raw) } Jsoniter 将 Go 中数据转换成 Json 的方法，Gjson 中已经弃用了，建议使用滴滴开源的的 jsoniter。\n安装：\ngo get github.com/json-iterator/go 使用：\nimport \u0026#34;github.com/json-iterator/go\u0026#34; jsoniter.Marshal(\u0026amp;data) jsoniter.Unmarshal(input, \u0026amp;data) 兼容标准库 jsoniter 还提供了完全兼容标准库的使用方式。\nimport \u0026#34;github.com/json-iterator/go\u0026#34; var json = jsoniter.ConfigCompatibleWithStandardLibrary json.Marshal(\u0026amp;data) json.Unmarshal(input, \u0026amp;data) ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93-gjson/","title":"Go 第三方库 gjson"},{"content":"gRPC 是一个高性能、通用的开源 RPC 框架，由 Google 主要面向移动应用开发并基于 HTTP/2 协议标准而设计，基于 ProtoBuf(Protocol Buffers) 序列化协议开发，且支持众多开发语言。\n使用 gRPC， 可以在一个 .proto 文件中定义服务，并使用任何支持它的语言去实现客户端和服务端。使用 gRPC定义一个服务，指定一个可以远程调用的带有参数和返回类型的的方法，客户端可以像调用本地方法一样直接调用服务端的方法。gRPC 解决了不同语言及环境间通信的复杂性。\n使用 protocol buffers 还能获得其他好处：\n 包括高效的序列号 简单的 IDL 容易进行接口更新。  使用 gRPC 能更容易编写跨语言的分布式代码。\n安装 安装 grpc 包 $ go get google.golang.org/grpc 导入：\nimport \u0026#34;google.golang.org/grpc\u0026#34; 安装 protocol buffer 编译器   到此地址根据系统下载编译好的编译器：\nhttps://github.com/protocolbuffers/protobuf/releases\n  解压文件。\n  将编译器放到环境变量中。\n  安装 protoc 的 Go 插件\n$ go get -u github.com/golang/protobuf/protoc-gen-go   用法 gRPC 开发流程：\n 编写.proto文件，生成指定语言源代码。 编写服务端代码。 编写客户端代码。  .proto 文件 syntax = \u0026#34;proto3\u0026#34;; // 版本声明，使用Protocol Buffers v3版本 package pb; // 包名 // 定义一个打招呼服务 service Greeter { // SayHello 方法  rpc SayHello (HelloRequest) returns (HelloReply) {}}// 包含人名的一个请求消息 message HelloRequest { string name = 1;}// 包含问候语的响应消息 message HelloReply { string message = 1;}执行命令，生成 Go 语言源代码：\n$ protoc -I helloworld/ helloworld/pb/helloworld.proto --go_out=plugins=grpc:helloworld 在 gRPC_demo/helloworld/pb 目录下会生成 helloworld.pb.go 文件。\nserver package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; pb \u0026#34;gRPC_demo/helloworld/pb\u0026#34; \u0026#34;golang.org/x/net/context\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/reflection\u0026#34; ) type server struct{} func (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) { return \u0026amp;pb.HelloReply{Message: \u0026#34;Hello \u0026#34; + in.Name}, nil } func main() { // 监听本地的8972端口 \tlis, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8972\u0026#34;) if err != nil { fmt.Printf(\u0026#34;failed to listen: %v\u0026#34;, err) return } s := grpc.NewServer() // 创建gRPC服务器 \tpb.RegisterGreeterServer(s, \u0026amp;server{}) // 在gRPC服务端注册服务  reflection.Register(s) //在给定的gRPC服务器上注册服务器反射服务 \t// Serve方法在lis上接受传入连接，为每个连接创建一个ServerTransport和server的goroutine。 \t// 该goroutine读取gRPC请求，然后调用已注册的处理程序来响应它们。 \terr = s.Serve(lis) if err != nil { fmt.Printf(\u0026#34;failed to serve: %v\u0026#34;, err) return } } client package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; pb \u0026#34;gRPC_demo/helloworld/pb\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ) func main() { // 连接服务器 \tconn, err := grpc.Dial(\u0026#34;:8972\u0026#34;, grpc.WithInsecure()) if err != nil { fmt.Printf(\u0026#34;faild to connect: %v\u0026#34;, err) } defer conn.Close() c := pb.NewGreeterClient(conn) // 调用服务端的SayHello \tr, err := c.SayHello(context.Background(), \u0026amp;pb.HelloRequest{Name: \u0026#34;q1mi\u0026#34;}) if err != nil { fmt.Printf(\u0026#34;could not greet: %v\u0026#34;, err) } fmt.Printf(\u0026#34;Greeting: %s !\\n\u0026#34;, r.Message) } Protocol Buffers 示例：\nsyntax = \u0026#34;proto3\u0026#34;;package routeguide;service SearchService { rpc Search(SearchRequest) returns (SearchResponse);}message SearchRequest { required string query = 1; optional int32 page_number = 2; optional int32 result_per_page = 3;}message SearchResponse { ...} syntax = \u0026quot;proto3\u0026quot;; 是我们使用的协议版本。 message 的每个字段都有个 index，范围在 1~15 之间时编码只需要一个字节，所以性能要求更高的字段尽量使用这个范围内的 index。此 index 后续不要修改。  字段类型 这是 grpc 的类型与 Python、Go 类型的对应表。\n   .proto Type Notes Python Type Go Type     double  float float64   float  float float32   int32 Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint32 instead. int int32   int64 Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint64 instead. int/long int64   uint32 Uses variable-length encoding. int/long uint32   uint64 Uses variable-length encoding. int/long uint64   sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int int32   sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int/long int64   fixed32 Always four bytes. More efficient than uint32 if values are often greater than 228. int/long uint32   fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 256. int/long uint64   sfixed32 Always four bytes. int int32   sfixed64 Always eight bytes. int/long int64   bool  bool bool   string A string must always contain UTF-8 encoded or 7-bit ASCII text, and cannot be longer than 232. str/unicode string   bytes May contain any arbitrary sequence of bytes no longer than 232. str []byte    字段规则 在字段类型前可以定义字段的规则：\n repeated: 此字段可以出现多次，等同于一个数组  reserved 保留字段，用于声明某些 index 不能使用，也可以声明字段名。\nmessage Foo { reserved 2, 15, 9 to 11; reserved \u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;;}enum 枚举类型\nmessage SearchRequest { required string query = 1; optional int32 page_number = 2; optional int32 result_per_page = 3 [default = 10]; enum Corpus { UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; } optional Corpus corpus = 4 [default = UNIVERSAL];}import Protocol Buffers 支持从多个文件导入已经写好的代码。\nimport \u0026#34;myproject/other_protos.proto\u0026#34;;嵌套 Message message SearchResponse { message Result { required string url = 1; optional string title = 2; repeated string snippets = 3; } repeated Result result = 1;}如果需要在父 Message 之外复用这个子 Message：\nmessage SomeOtherMessage { optional SearchResponse.Result result = 1;}Package 用于声明当前文件的包名，这样在其他文件导入此文件时，可以使用包名来索引到具体 message：\npackage foo.bar;message Open { ... }导入文件:\nmessage Foo { ... required foo.bar.Open open = 1; ...}生成 Go 代码 生成使用 grpc 的代码。\nprotoc -I=$SRC_DIR --go_out=plugins=grpc:$DST_DIR $SRC_DIR/addressbook.proto ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93-grpc/","title":"Go 第三方库 grpc"},{"content":"此包用于读取各类配置文件。\n安装：\ngo get github.com/spf13/viper Viper 支持的配置文件后缀名如下：\njson, toml, yaml, yml, properties, props, prop, hcl, dotenv, env, ini\n初始化 读取配置 设置读取配置的文件，此方法需要显式的指定配置文件的路径、名称和扩展名，使用此方法设定后，Viper 将不会再去其他路径寻找配置文件。\nfunc SetConfigFile(in string) 设置读取配置的文件名和路径，如果没有设置 ConfigFile，那么 Viper 会去设置的路径中，寻找所有类型被支持的同名配置文件。\nfunc AddConfigPath(in string) // 添加路径，可以添加多个 func SetConfigName(in string) 配置好路径过后就可以读取配置信息了：\nfunc ReadInConfig() error 设置默认值 viper.SetDefault(\u0026#34;ContentDir\u0026#34;, \u0026#34;content\u0026#34;) viper.SetDefault(\u0026#34;LayoutDir\u0026#34;, \u0026#34;layouts\u0026#34;) viper.SetDefault(\u0026#34;Taxonomies\u0026#34;, map[string]string{\u0026#34;tag\u0026#34;: \u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;categories\u0026#34;}) 监听配置变化 调用此函数后，Viper 会自动监听配置文件的变化，如果配置文件有更改，Viper 会更新自己的配置信息。\nfunc WatchConfig() 如果希望在配置文件更新时，进行额外的处理，可以这样：\nviper.OnConfigChange(func(e fsnotify.Event) { fmt.Println(\u0026#34;配置发生变更：\u0026#34;, e.Name) }) 读取值 检查值是否设置 直接使用 Viper 去获取值时，如果这个 key 在配置文件中没有设置，那么会返回零值。所以如果需要判断值是否设置了这个 key，使用以下方法：\n// 判断是否有这个设置，包括文件和代码中设置的配置 func IsSet(key string) bool // 判断是否在配置文件中有这个配置 func InConfig(key string) bool 获取值 获取单个配置的值：\nfunc Get(key string) interface{} func GetBool(key string) bool func GetDuration(key string) time.Duration func GetFloat64(key string) float64 func GetInt(key string) int func GetInt32(key string) int32 func GetInt64(key string) int64 func GetIntSlice(key string) []int func GetSizeInBytes(key string) uint func GetString(key string) string func GetStringMap(key string) map[string]interface{} func GetStringMapString(key string) map[string]string func GetStringMapStringSlice(key string) map[string][]string func GetStringSlice(key string) []string func GetTime(key string) time.Time func GetUint(key string) uint func GetUint32(key string) uint32 func GetUint64(key string) uint64 调试 此方法可以打印注册的所有配置信息。\nviper.Debug() 写入配置文件 更改设置 在使用中可以更改既定的配置\nfunc Set(key string, value interface{}) 写入配置文件 更改配置之后，可以将当前配置写入配置文件\nfunc WriteConfig() error func WriteConfigAs(filename string) error func SafeWriteConfig() error func SafeWriteConfigAs(filename string) error ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93-viper/","title":"Go 第三方库 viper"},{"content":"此包用于结构化记录日志。\n安装：\ngo get -u go.uber.org/zap 导入：\nimport \u0026#34;go.uber.org/zap\u0026#34; 优点：\n 性能高，与 Zerolog 同一水平。  创建 Logger New 创建 Logger 最基础的方式是使用 New 方法：\nfunc New(core zapcore.Core, options ...Option) *Logger 此方法需要传入 zapcore 和 option 来进行构造。通常需要深度定制时使用此方法。\n例子：\nEncoderConfig := zapcore.EncoderConfig{ MessageKey: \u0026#34;msg\u0026#34;, LevelKey: \u0026#34;level\u0026#34;, TimeKey: \u0026#34;time\u0026#34;, NameKey: \u0026#34;zap\u0026#34;, CallerKey: \u0026#34;caller\u0026#34;, StacktraceKey: \u0026#34;stacktrace\u0026#34;, LineEnding: zapcore.DefaultLineEnding, EncodeLevel: zapcore.LowercaseLevelEncoder, EncodeTime: zapcore.ISO8601TimeEncoder, EncodeDuration: zapcore.StringDurationEncoder, EncodeCaller: zapcore.ShortCallerEncoder, EncodeName: zapcore.FullNameEncoder, } core := zapcore.NewCore( zapcore.NewJSONEncoder(EncoderConfig), zapcore.Lock(os.Stdout), zap.InfoLevel, ) logger := zap.New( core, zap.AddCaller(), zap.AddStacktrace(zap.ErrorLevel), ) defer logger.sync() Option 可以用于对 Logger 时进行一些配置，Zap 提供的 Option 如下：\nfunc AddCaller() Option // 添加调用信息 func AddCallerSkip(skip int) Option // 报告调用信息时，跳过指定调用层数 func WithCaller(enabled bool) Option // 是否添加调用信息 func AddStacktrace(lvl zapcore.LevelEnabler) Option // 异常时堆栈追踪 func Development() Option // 开发模式 func ErrorOutput(w zapcore.WriteSyncer) Option //异常输出位置 func Fields(fs ...Field) Option // 添加字段 func Hooks(hooks ...func(zapcore.Entry) error) Option // 添加回调 func IncreaseLevel(lvl zapcore.LevelEnabler) Option // 仅可以提高记录等级，不能降低 func WrapCore(f func(zapcore.Core) zapcore.Core) Option // 用于包裹或替换 Core 内置 Logger 由于 New 方法创建 Logger 过于复杂，zap 包中提供了几个内建的 Logger。\n  NewDevelopment\n此 Logger 以人性化的格式记录 Debug 级别以上的日志和标准的异常信息。\nWarn 和以上级别的日志会自动包含堆栈追踪。\n此方法等价于 NewDevelopmentConfig().Build(...Option)。\nfunc NewDevelopment(options ...Option) (*Logger, error)   NewProduction\n此 Logger 以 Json 格式记录 Info 级别以上的日志和标准的异常信息。\nError 和以上级别的日志会自动包含堆栈追踪。\n此方法等价于 NewProductionConfig().Build(...Option)。\nfunc NewProduction(options ...Option) (*Logger, error)   NewExample\n此 Logger 是一个常用于测试用例的 Logger。\n它以 Json 格式记录 Debug 级别以上的日志和标准的异常信息。但是删去了时间戳和调用函数，以简短日志输出。\nfunc NewExample(options ...Option) *Logger   使用 Config 创建 Logger 除了使用 New 自定义创建外，使用 Config 来创建 Logger 会更加方便。\nConfig Config 包含了绝大部分常见的设置。其中部分设置需要使用 zapcore.EncoderConfig 来进行配置。\ntype Config struct { // 输出的日志级别，使用 Config.Level.SetLevel 可以原子性的更改输出的日志级别  Level AtomicLevel `json:\u0026#34;level\u0026#34; yaml:\u0026#34;level\u0026#34;` // 是否开启开发模式，开启后会改变 DPanicLevel 的行为，栈追踪也会更自由  Development bool `json:\u0026#34;development\u0026#34; yaml:\u0026#34;development\u0026#34;` // 是否关闭调用信息，默认状况下，所有的日志都会带有文件名和文件行数  DisableCaller bool `json:\u0026#34;disableCaller\u0026#34; yaml:\u0026#34;disableCaller\u0026#34;` // 禁用自动堆栈追踪，默认情况下，堆栈追踪在开发模式抓取 WarnLevel 以上级别的日志，  // 在生产模式抓取 ErrorLevel 以上级别的日志  DisableStacktrace bool `json:\u0026#34;disableStacktrace\u0026#34; yaml:\u0026#34;disableStacktrace\u0026#34;` // 采样策略，作用是限制日志在每秒钟内的输出数量, 以防止CPU和IO被过度占用。  // 如果为 nil 则禁用采样  Sampling *SamplingConfig `json:\u0026#34;sampling\u0026#34; yaml:\u0026#34;sampling\u0026#34;` // Encoding 设置日志的编码格式，可选的有 json 和 console，也可以使用 RegisterEncoder  // 来注册第三方编码方式  Encoding string `json:\u0026#34;encoding\u0026#34; yaml:\u0026#34;encoding\u0026#34;` // 注册的 Encoder 的设置，详见 zapcore.EncoderConfig  EncoderConfig zapcore.EncoderConfig `json:\u0026#34;encoderConfig\u0026#34; yaml:\u0026#34;encoderConfig\u0026#34;` // 日志输出的位置，如果是控制台，则是 stdout，或者是日志文件路径  // 详见 Open  OutputPaths []string `json:\u0026#34;outputPaths\u0026#34; yaml:\u0026#34;outputPaths\u0026#34;` ErrorOutputPaths []string `json:\u0026#34;errorOutputPaths\u0026#34; yaml:\u0026#34;errorOutputPaths\u0026#34;` // 添加到根 logger 的字段  InitialFields map[string]interface{} `json:\u0026#34;initialFields\u0026#34; yaml:\u0026#34;initialFields\u0026#34;` } 在创建 Config 之后，使用 Build() 方法，即可根据 Config 创建相应的 Logger。\n例子：\ncfg := zap.Config{ Level: zap.NewAtomicLevelAt(zap.DebugLevel), Development: false, DisableCaller: false, DisableStacktrace: false, Sampling: nil, Encoding: \u0026#34;json\u0026#34;, EncoderConfig: zapcore.EncoderConfig{ MessageKey: \u0026#34;msg\u0026#34;, LevelKey: \u0026#34;level\u0026#34;, TimeKey: \u0026#34;time\u0026#34;, NameKey: \u0026#34;zap\u0026#34;, CallerKey: \u0026#34;caller\u0026#34;, StacktraceKey: \u0026#34;stacktrace\u0026#34;, LineEnding: zapcore.DefaultLineEnding, EncodeLevel: zapcore.LowercaseLevelEncoder, EncodeTime: zapcore.ISO8601TimeEncoder, EncodeDuration: zapcore.StringDurationEncoder, EncodeCaller: zapcore.ShortCallerEncoder, EncodeName: zapcore.FullNameEncoder, }, OutputPaths: []string{\u0026#34;stdout\u0026#34;}, ErrorOutputPaths: []string{\u0026#34;stderr\u0026#34;}, InitialFields: map[string]interface{}{\u0026#34;app\u0026#34;: \u0026#34;zapdex\u0026#34;}, } logger, err := cfg.Build() if err != nil { panic(err) } defer logger.Sync() logger.Info(\u0026#34;logger construction succeeded\u0026#34;) AtomicLevel 这是 Zap 中用来表示日志级别的对象，可以原子性的修改。\n创建 AtomicLevel：\nfunc NewAtomicLevel() AtomicLevel func NewAtomicLevelAt(l zapcore.Level) AtomicLevel 更改 AtomicLevel：\nfunc (lvl AtomicLevel) SetLevel(l zapcore.Level) 创建或更改特定的日志级别需要 zapcore.Level，以下是其定义：\nconst ( DebugLevel Level = iota - 1 // production 环境会被禁用  InfoLevel // 最常见的级别  WarnLevel ErrorLevel DPanicLevel // DpanicLevel 在 development 环境中会记录日志并 panic  PanicLevel // PanicLevel 会记录日志并 panic  FatalLevel // PanicLevel 会记录日志并调用 os.Exit(1) ) Logger 输出日志 func (log *Logger) Debug(msg string, fields ...Field) func (log *Logger) Info(msg string, fields ...Field) func (log *Logger) Warn(msg string, fields ...Field) func (log *Logger) Error(msg string, fields ...Field) func (log *Logger) DPanic(msg string, fields ...Field) func (log *Logger) Panic(msg string, fields ...Field) func (log *Logger) Fatal(msg string, fields ...Field) 全局 Logger 使用 ReplaceGlobals 方法可以将 logger 设置为全局的 logger：\nfunc ReplaceGlobals(logger *Logger) func() 设置为全局 logger 后，使用 L 方法就可以在任何位置获取这个全局的 logger：\nfunc L() *Logger SugaredLogger logger 在输出日志时，字段需要指定类型，较为麻烦，使用 SugaredLogger 则可以在输出日志时较为方便，但性能较低。获取 SugaredLogger：\nfunc (log *Logger) Sugar() *SugaredLogger ZapCore ZapCore 是 Zap 中的核心部分，在需要细致且底层的配置时使用。\n导入：\nimport \u0026#34;go.uber.org/zap/zapcore\u0026#34; Core 创建 Core 主要使用 NewCore 方法：\nfunc NewCore(enc Encoder, ws WriteSyncer, enab LevelEnabler) Core 参数：\n  enc Encoder - 使用 EncoderConfig 创建的 Encoder，Zap 提供了最常见的两种：\nfunc NewConsoleEncoder(cfg EncoderConfig) Encoder func NewJSONEncoder(cfg EncoderConfig) Encoder   ws WriteSyncer - 表示日志写入位置的接口，可以使用 AddSync 创建：\nfunc AddSync(w io.Writer) WriteSyncer 注：*os.File、os.Stderr、os.Stdout 已经实现了此接口。\n在并发情况下，需要给 WriteSyncer 加锁，可以使用 Lock 方法：\nfunc Lock(ws WriteSyncer) WriteSyncer   enab LevelEnabler - 用于决定记录什么级别的日志，[AtomicLevel](#2. AtomicLevel) 已实现这一接口。\n  创建多个 Core 有些时候我们需要同时将日志输出到多个位置，这样的情况下则需要我们创建多个 Core，并合并成一个：\nfunc NewTee(cores ...Core) Core EncoderConfig zapcore.EncoderConfig 用于配置 zap.Config 中的 Encoder。\ntype EncoderConfig struct { // 用于设置默认字段的字段名，如果值为空，则记录日志时忽略此字段  MessageKey string `json:\u0026#34;messageKey\u0026#34; yaml:\u0026#34;messageKey\u0026#34;` LevelKey string `json:\u0026#34;levelKey\u0026#34; yaml:\u0026#34;levelKey\u0026#34;` TimeKey string `json:\u0026#34;timeKey\u0026#34; yaml:\u0026#34;timeKey\u0026#34;` NameKey string `json:\u0026#34;nameKey\u0026#34; yaml:\u0026#34;nameKey\u0026#34;` CallerKey string `json:\u0026#34;callerKey\u0026#34; yaml:\u0026#34;callerKey\u0026#34;` StacktraceKey string `json:\u0026#34;stacktraceKey\u0026#34; yaml:\u0026#34;stacktraceKey\u0026#34;` // 每行日志的分隔符  LineEnding string `json:\u0026#34;lineEnding\u0026#34; yaml:\u0026#34;lineEnding\u0026#34;` // 日志级别的编码  EncodeLevel LevelEncoder `json:\u0026#34;levelEncoder\u0026#34; yaml:\u0026#34;levelEncoder\u0026#34;` // 时间格式的编码  EncodeTime TimeEncoder `json:\u0026#34;timeEncoder\u0026#34; yaml:\u0026#34;timeEncoder\u0026#34;` EncodeDuration DurationEncoder `json:\u0026#34;durationEncoder\u0026#34; yaml:\u0026#34;durationEncoder\u0026#34;` // 调用信息的编码  EncodeCaller CallerEncoder `json:\u0026#34;callerEncoder\u0026#34; yaml:\u0026#34;callerEncoder\u0026#34;` // 与上面几种编码器不同，此编码器是可选的，默认会使用 FullNameEncoder  EncodeName NameEncoder `json:\u0026#34;nameEncoder\u0026#34; yaml:\u0026#34;nameEncoder\u0026#34;` } 内置 Encoder Zap 中提供了几个编码器类型，可以用于自定义编码。分别是：\ntype LevelEncoder func(Level, PrimitiveArrayEncoder) type CallerEncoder func(EntryCaller, PrimitiveArrayEncoder) type DurationEncoder func(time.Duration, PrimitiveArrayEncoder) type NameEncoder func(string, PrimitiveArrayEncoder) type TimeEncoder func(time.Time, PrimitiveArrayEncoder) Zap 也提供了一部分常用的编码器实现，可以根据需要使用：\n  LevelEncoder\nfunc CapitalColorLevelEncoder(l Level, enc PrimitiveArrayEncoder) // 大写彩色 func CapitalLevelEncoder(l Level, enc PrimitiveArrayEncoder) // 大写 func LowercaseColorLevelEncoder(l Level, enc PrimitiveArrayEncoder) // 小写彩色 func LowercaseLevelEncoder(l Level, enc PrimitiveArrayEncoder) // 小写   TimeEncoder\nfunc EpochTimeEncoder(t time.Time, enc PrimitiveArrayEncoder) // 时间戳 func EpochMillisTimeEncoder(t time.Time, enc PrimitiveArrayEncoder) // 毫秒级时间戳 func EpochNanosTimeEncoder(t time.Time, enc PrimitiveArrayEncoder) // 纳秒级时间戳 func RFC3339TimeEncoder(t time.Time, enc PrimitiveArrayEncoder) // 秒级标准格式 func ISO8601TimeEncoder(t time.Time, enc PrimitiveArrayEncoder) // 毫秒级标准格式 func RFC3339NanoTimeEncoder(t time.Time, enc PrimitiveArrayEncoder) // 纳秒级标准格式   CallerEncoder\nfunc FullCallerEncoder(caller EntryCaller, enc PrimitiveArrayEncoder) // 长路径 func ShortCallerEncoder(caller EntryCaller, enc PrimitiveArrayEncoder) // 短路径   NameEncoder\nfunc FullNameEncoder(loggerName string, enc PrimitiveArrayEncoder)   DurationEncoder\nfunc MillisDurationEncoder(d time.Duration, enc PrimitiveArrayEncoder) func NanosDurationEncoder(d time.Duration, enc PrimitiveArrayEncoder) func SecondsDurationEncoder(d time.Duration, enc PrimitiveArrayEncoder) func StringDurationEncoder(d time.Duration, enc PrimitiveArrayEncoder)   日志文件切割归档 使用第三方库 Lumberjack 实现。安装：\n$ go get -u github.com/natefinch/lumberjack 接入 Zap func logWriter() zapcore.WriteSyncer { lumberJackLogger := \u0026amp;lumberjack.Logger{ Filename: \u0026#34;./test.log\u0026#34;, MaxSize: 10, MaxBackups: 5, MaxAge: 30, Compress: false, } return zapcore.AddSync(lumberJackLogger) } Lumberjack 参数：\n Filename: 日志文件的位置 MaxSize：在进行切割之前，日志文件的最大大小（以MB为单位） MaxBackups：保留旧文件的最大个数 MaxAges：保留旧文件的最大天数 Compress：是否压缩/归档旧文件 ","date":"2021-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93-zap/","title":"Go 第三方库 zap"},{"content":"GMP Scheduler 是 Runtime 中几乎最重要的组件，它的作用是：\n For scheduling goroutines onto kernel threads.\n GMP Scheduler 的核心思想是：\n 重用线程。 限制同时运行（不包含阻塞）的线程数为 N，N 为 CPU 逻辑核心数。  Go scheduler 的职责就是将所有处于 runnable 的 Goroutines 均匀分布到在 P 上运行的 M，利用多核并行，实现更强大的并发。\n \nGMP 数据结构 G Goroutine 用户级别的协程，我们在程序里用 go 关键字创建的协程。\n   状态 描述     _Gidle 空闲中，刚刚被分配并且还没有被初始化，值为 0，为创建 Goroutine 后的默认值   _Grunnable 待运行，G 在运行队列中, 等待 M 取出并运行，没有栈的所有权   _Grunning 运行中，正在执行代码的 Goroutine，拥有栈的所有权   _Gsyscall 系统调用中，正在执行系统调用，拥有栈的所有权，与 P 脱离，但是与某个 M 绑定，会在调用结束后被分配到运行队列   _Gwaiting 等待中，此时为被阻塞的 G，阻塞在某个 channel 的发送或者接收队列   _Gdead 已中止，当前 G 未被使用，没有执行代码，可能有分配的栈，分布在空闲列表 gFree，可能是一个刚初始化的 G，也可能是执行了 goexit 退出的 G   _Gcopystac 栈复制中，栈正在被拷贝，没有执行代码，不在运行队列上   _Gscan GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在    M Machine 指 Go 语言对一个关联的内核线程的封装。\nM 并没有像 G 和 P 一样的状态标记, 但可以认为一个 M 有以下的状态\n   状态 描述     spinning 自旋中 M 正在从运行队列获取 G, 这时候 M 拥有一个 P   执行 Go 代码中 M 正在执行 Go 代码, 这时候 M 拥有一个P   执行原生代码中 M 正在执行原生代码或者阻塞的 syscall, 这时 M 不拥有 P   休眠中 M 发现无待运行的 G 时会进入休眠, 并添加到空闲 M 链表中, 这时 M 不拥有 P    P Processor 包含了 Goroutine 运行的资源，M 必须和一个 P 关联才能运行 G。\nP 还包含自己的本地队列 local runqueue 来保存 G，这样可以避免竞争锁。\n   状态 描述     _Pidle 空闲中，当 M 发现无 runnable 的 G 时会进入休眠, 这时 M 拥有的 P 会变为空闲并放到空闲 P 链表中   _Prunning 运行中，当 M 拥有了一个 P 后, 这个 P 的状态就会变为运行中, M 会使用这个 P 中的资源运行 G   _Psyscall 系统调用中，当 Go 调用原生代码, 原生代码又反过来调用 Go 代码时, 使用的 P 会变为此状态   _Pgcstop GC 停止中，当 GC 停止了整个世界(STW)时, P 会变为此状态   _Pdead 已中止，当 P 的数量在运行时改变, 且数量减少时多余的 P 会变为此状态    P 和 M 的数量 P 的数量：\n  由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。\n这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个goroutine在同时运行。\n  M 的数量：\n GO 程序启动时，会设置 M 的最大数量，默认 10000。但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量。 一个 M 阻塞了，会创建新的 M。  M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。\nP 和 M 何时被创建   P：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。\n  M：没有足够的 M 来关联 P 并运行其中的可运行的 G。\n比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。\n  GRQ Global Runnable Queue 全局队列。存放等待运行的 G。\n  此队列优先度较低。\n  GRQ 入队和出队需要使用线程锁。\n  全局运行队列的数据结构是链表, 由两个指针 head, tail 组成。\n  LRQ Local Runnable Queue P 的本地队列。\n  同 GRQ 类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。\n  新建 G 时，G 优先加入到 P 的 LRQ，如果队列满了，则会把 LRQ 中随机一半的 G 移动到 GRQ。\n  LRQ 入队和出队不需要使用线程锁。\n  LRQ 的数据结构是环形队列, 由一个 256 长度的数组和两个序号 head, tail 组成。\n  概念 Goroutine 和 Thread 区别   内存占用\n 创建一个 Goroutine 的栈内存消耗为 2 KB，如果栈空间不够用，会自动进行扩容。 创建一个 Thread 需要消耗 1 MB 栈内存，还需要一个 a guard page 的区域用于和其他 Thread 的栈空间进行隔离。    创建和销毁\n Goroutine 由 Go runtime 负责管理，创建和销毁的消耗非常小，是用户级。 Thread 由于是内核级的，创建和销毀都会有巨大的消耗，通常解决的办法是线程池。    切换\n  Goroutines 切换只需保存三个寄存器：Program Counter, Stack Pointer and BP。\nGoroutine 的切换约为 200 ns，相当于 2400-3600 条指令。\n  Threads 切换时，需要保存各种寄存器，以便将来恢复：\n 16 general purpose registers, PC (Program Counter), SP (Stack Pointer), segment registers, 16 XMM registers, FP coprocessor state, 16 AVX registers, all MSRs etc.\n 一般而言，线程切换会消耗 1000-1500 纳秒，执行指令的条数会减少 12000-18000。\n    M:N 模型 Runtime 在程序启动的时候，会创建 M 个系统线程，之后创建的 N 个 Goroutine 都会在这 M 个线程上执行。这就是 M:N 模型。\n  同一时刻，一个线程上只能跑一个 Goroutine。\n  sysmon 会检测长时间（超过 10 ms）运行的 Goroutine，将其调度到 global runqueues，让其他 Goroutine 执行。\nglobal runqueues 是一个全局的 runqueue，优先级比较低，以示惩罚。\n  Work Stealing 当一个 G 执行结束，P 会去 LRQ 获取下一个 G 来执行。\n如果 LRQ 已经空了，这时，P 会随机选择一个 P 的 LRQ “偷”过来一半的 G。\n这样就有更多的 P 可以一起工作，加速执行完所有的 G。\n调度流程  Go调度器生命周期 \nM0 M0 是启动程序后的编号为 0 的主线程。\n 这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配 M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。  G0 G0 是每次启动一个 M 都会第一个创建的 gourtine。\n G0 是仅用于负责调度的 G，不指向任何可执行的函数。 每个 M 都会有一个自己的 G0。 在调度或系统调用时会使用 G0 的栈空间, 全局变量的 G0 是 M0 的 G0。  基于信号的抢占式调度","date":"2021-08-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-gmp-%E8%B0%83%E5%BA%A6%E5%99%A8/","title":"Go GMP 调度器"},{"content":"Redis 底层所采用的数据结构，分别有：SDS String、HashTable、ZipList、QuickList、IntSet、SkipList。\nSDS String SDS，全称 Simple Dynamic String。\n在 Redis 中，包含字符串值的键值对都是由 SDS 实现的，而不是 C 语言自带的字符串。SDS 字符串适合用来表示可以被修改的字符串。\n优点：\n 计算长度的时间复杂度为 O(1) 二进制安全 减少修改操作的内存重分配次数 杜绝缓冲区溢出  缺点：\n 占用更多内存，并且这些内存不会被主动释放  数据结构 sds 的完整结构分为两块部分，sdshdr 结构和字符数组。\n SDS 数据结构 \n  len - sds buffer 的已用长度。小于等于 alloc，len 根据类型可以分为无符号的 8 位、16 位、32 位、64 位的整数。\n  alloc - sds buffer 分配的内存空间的总长度。alloc 根据类型可以分为无符号的 8 位、16 位、32 位、64 位的整数。\n  flags - sds 的类型。取值范围为 0-4，用来表示 sds 的五种类型：5位、8 位、16 位、32 位、64 位，其中 0 表示的 5 位类型实际上并没有用到。\n类型根据 buffer 的总长度来决定，比如 8 位类型，buffer 的最大长度为 255。\n当表示 5 位的 sdshdr5 时，前三位用于表示类型，后五位用于存储字符串内容，此时没有 buf[] 部分。\n  buf[] - 字符数组，实际存储字符串的地方。buffer 由三部分组成：used buffer、avai buffer、end。\n  used buffer - 已经使用的 buffer。长度由 len 表示。\n  avai buffer - 剩余可用的 buffer。长度等于 alloc - len。\n  end - 表示 buffer 的结尾。占用 8 位空间，等同于 /0。\n    注：Redis 3.2 以前，SDS 使用 len 和 free 两个 4 字节的参数来表示字符串的大小。Redis 3.2 之后，SDS 字符串按长度划分成 5 种不同的类型，增加了一个 1 字节大小的 flags 字段表示类型，这样在存储短字符串时，len 和 alloc 可以被缩短到 1 字节。这是 Redis 节省内存的设计。\n扩容与释放 SDS 的空间预分配策略：\n 若 SDS 中剩余空闲长度 avail 大于或等于新增内容的长度 addlen，无需扩容。 若 SDS 中剩余空闲长度 avail 小于或等于 addlen，则分情况讨论：  新增后总长度 len+addlen \u0026lt; 1MB 的，按新长度的 2 倍扩容 新增后总长度 len+addlen \u0026gt;= 1MB 的，按新长度加上 1MB 扩容。    SDS 的惰性释放策略：\n 当 SDS 的长度缩短时，Redis 并不会立即回收不再使用的内存空间，而是更新 len 属性，需要时使用 alloc-len 即可获知未被使用的空间大小。 目的是避免频繁的内存分配，但会造成部分内存的浪费。 Redis 也提供了主动释放未使用内存的方法。  HashTable Redis 的 HashTable 使用 MurmurHash2 算法计算 Hash 值。\n优点：\n 访问数据的时间复杂度为 O(1)  缺点：\n 有哈希冲突问题   字典数据结构 \n链表法 Redis 中的 HashTable 使用链表法解决 Hash 冲突问题。也就是同一个桶里面的元素使用链表保存。\n但是当链表过长就会导致查找性能变差可能，所以 Redis 的字典都使用了两个 HashTable 用于 Rehash 操作，增加现有的哈希桶数量，减少哈希冲突。\n一般情况下，字典只使用 ht[0] HashTable, ht[1] HashTable 只在进行 Rehash 时使用。\n负载因子 负载因子用于衡量 HashTable 的“健康状况”。\n HashTable 的负载因子 = 填入 HashTable 中的元素个数 / HashTable 的长度\n 对于 HashTable 来说，负载因子过大或过小都不好，\n 负载因子过大，代表空闲位置越少，冲突也就越多，散列表的性能会下降 负载因子过小，则会造成内存不能合理利用，从而形成内存浪费  因此我们为了保证负载因子维持在一个合理的范围内，要对散列表的大小进行收缩或扩展，即 Rehash，类似于数组的收缩与扩容。\nRehash Rehash 执行条件\n在满足以下条件之一时，将进行 Rehash 操作：\n 负载因子大于等于 1 且 dict_can_resize 设置为 1，执行扩容操作 负载因子小于 0.1，执行收缩操作  当服务正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令进行持久化操作时，Redis 不会进行 Rehash 操作，除非满足以下条件：\n 负载因子大于等于安全阈值 dict_force_resize_ratio，默认为 5 时，将无视持久化操作，强制执行 Rehash 扩容操作  Rehash 过程\n扩展 HashTable 和收缩 HashTable 都是通过执行 Rehash 来完成，主要经过以下五步：\n  为 ht[1] 分配空间，其大小取决于 ht[0] 已使用节点数，即 ht[0].used\n  扩展操作，ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 $2^n$\n如：ht[0].used=3 则 ht[1] 的大小为 8，ht[0].used=5 则 ht[1] 的大小为 16\n  收缩操作， ht[1] 的大小为第一个大于等于 ht[0].used 的 $2^n$​\n    将字典的 rehashidx 设置为 0，表示正在执行 rehash 操作\n  将 ht[0] 中所有的键值对依次重新计算哈希值，并放到 ht[1] 数组对应位置，完成一个键值对的 Rehash 之后rehashidx 的值加 1\n  当 ht[0] 中所有的键值对都迁移到 ht[1] 之后，释放 ht[0]，将 ht[1] 修改为 ht[0]，然后再创建一个新的 ht[1] ，为下一次 Rehash 做准备。\n  将字典的 rehashidx 设置为 -1，表示 rehash 已经结束\n  渐进式 Rehash 由于 Rehash 过程需要完全重新计算整个 HashTable 的所有数据，需要的计算量非常庞大，所以 Redis 将 Rehash 过程分成多步进行，这被称为渐进式 Rehash。\n渐进式 Rehash 以 bucket 为单位进行数据迁移：\n Redis 执行每一个增删查改命令时都会检测是否处于 Rehash 过程中，如果是则帮助执行一次渐进式 Rehash 的数据迁移 同时，Redis 的周期函数如果发现有字典处于 Rehash 过程中，也会帮助执行一次渐进式 Rehash 的数据迁移，此行为需要配置 activerehashing，默认值为 1  在渐进式 Rehash 的过程中，会同时使用两个 HashTable\n Delete、Find、Update 操作会优先从 ht[0] 查找，如果找不到再从 ht[1] 查找 而插入操作则只会插入到 ht[1] 中  这就保证了随着 Rehash 过程的进行，ht[0] 的数据只减不增，最终变成一张空表。\nZipList 压缩数组 ziplist 是为了节省内存而开发的一种数据结构，由一系列特殊编码的连续内存块组成的顺序型数据结构。\nziplist 不存储指向上一个节点和下一个节点的指针，存储的是上一个节点的长度和当前节点的长度，牺牲了部分读写性能来换取高效的内存利用率，是一种时间换空间的思想。\n优点：\n 使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面比 HashTable 更加优秀  缺点：\n 每次增删数据都会引发一次内存的 realloc，存储数据量大时 realloc 可能会导致大量的数据拷贝。只适用于字段个数少和字段值少的场景 连锁更新问题  数据结构  ZapList 数据结构 \n  zlbytes - uint32_t 4 字节\n记录整个 zaplist 占用内存字节数，包括本身所占用的 4 个字节。在对 ziplist 进行内存重分配，或计算 zlend 位置时使用。\n  zltail - uint32_t 4 字节\n记录 zaplist 尾节点距离 zaplist 起始地址有多少个字节。通过这个值无需遍历整个 zaplist 就可以计算出尾节点的地址。\n  zllen - uint16_t 2 字节\n记录 zaplist 中包含的节点数量，当超过可以存储的最大值 65535 时，此值固定为 65535，此时需要遍历整个 zaplist 才能计算出真实节点数。\n  entry - 列表节点\n存储 zaplist 中的内容，长度由存储的实际数据决定。\n  zlend - uint8_t 1 字节\n用于标记 zaplist 的末端。\n  节点 zaplist 的节点可以存储两种数据，整数或者字节数组。\n ZapList 数据结构 \nzaplist 的每个节点分为三部分：\n  previous_entry_length - 前一个 entry 的长度，以便能够从后到前遍历列表\n  如果前一节点的长度小于 254 字节,那么 previous_entry_length 属性的长度为 1 字节，前一节点的长度就保存在这一个字节里面。\n  如果前一节点的长度大于等于 254 字节,那么 previous_entry_length 属性的长度为 5 字节。\n其中第一个字节会被设置为 0xFE(十进制值254)，标记后面跟了一个更大的值。\n之后的四个字节则用于保存前一节点的长度。\n    encoding - 当前 entry 所保存数据的类型以及长度\n 当存储的数据是 0-12 范围的小整数时，数据会直接存储到 encoding 中，此时节点将不再会有 content 部分。    content - 具体数据\n  连锁更新 ziplist 不会预留扩展空间，每次插入一个新的元素就需要调用 realloc 扩展内存, 并可能需要将原有内容拷贝到新地址。\n每个节点存在 prevlen 属性，用来记录前置节点的长度，根据前置节点长度还分为两种情况，当长度大于等于 254 时，占用空间会从 1 字节扩大到 5 字节。\n所谓连锁更新，就是多个长度处于 250 ~ 253 字节之间的连续节点，当一个节点更新后，导致下一个节点 prevlen 由 1 字节变为 5 字节，从而导致下下一个节点 prevlen 值增大，产生连锁反应。\n因为连锁更新在最坏情况下需要对压缩列表执行 N 次空间预分配，而每次空间预分配的最坏复杂度为 $O(n)$，所以连锁更新的最坏复杂度为 $O(n^2)$。\n不过，虽然连锁更新的复杂度高，但出现的几率较低。\n时间复杂度    操作 时间复杂度     创建一个新的 zaplist $O(1)$   获取给定节点所保存的值 $O(1)$   返回给定节点的下一个节点 $O(1)$   返回给定节点的前一个节点 $O(1)$   返回 zaplist 目前占用的内存字节数 $O(1)$   返回 zaplist 给定索引上的节点 $O(n)$   创建一个包含给定值的新节点,并将这个新节点添加到 zaplist 的表头或者表尾 平均 $O(n)$，最坏 $O(n^2)$(可能发生连锁更新)   将包含给定值的新节点插人到给定节点之后 平均 $O(n)$，最坏 $O(n^2)$(可能发生连锁更新)   从 zaplist 中删除给定的节点 平均 $O(n)$，最坏 $O(n^2)$(可能发生连锁更新)   删除 zaplist 在给定索引上的连续多个 平均 $O(n)$，最坏 $O(n^2)$(可能发生连锁更新)   返回 zaplist 目前包含的节点数量 数量小于 65535 时为 $O(1)$，大于 65535 时为 $O(n)$   在 zaplist 中査找并返回包含了给定值的节点 因为节点的值可能是一个字节数组，所以检查节点值和给定值是否相同的复杂度为 $O(n)$，而查找整个列表的复杂度则为 $O(n^2)$    QuickList quicklist 是 ziplist 和 linkedlist 的结合体，它使用跟 linkedlist 相似的双向链表，每一个链表节点使用 ziplist 来紧凑存储数据。\n优点：\n 节省内存，拥有跟 ziplist 几乎相同的空间利用率 在大数据量时性能好，插入与弹出性能与 linkedlist 相近  缺点：\n 实现较为复杂  数据结构  Redis QuickList \n head: 指向头节点的指针 tail: 指向尾节点的指针 count: 所有 ziplist entry 的总数量 len: quicklistNode 节点的数量 fill: 单个 quicklistNode 节点中 ziplist 存放 entry 最大总数设置，由 list-max-ziplist-size 参数设置，16 bit compress: 节点压缩深度设置，也就是 quicklist 首尾两端不被压缩的节点的个数，由list-compress-depth参数设置，16 bit  quicklistNode quicklistNode 是 quicklist 的节点结构。\n prev: 指向链表前一个节点的指针 next: 指向链表后一个节点的指针 zl: 数据指针。如果当前节点的数据没有压缩，那么它指向一个 ziplist，否则，它指向一个 quicklistLZF sz: 表示 zl 指向的 ziplist 的占用字节数总大小，即便 ziplist 被压缩了 sz 的值仍然是压缩前的 ziplist 大小 count: 表示 ziplist 里面包含的 entry 个数 encoding: 表示 ziplist 的编码，1 表示没有压缩，2 表示 LZF 压缩编码 container: 表示一个 quicklist 节点下面是直接存数据，还是使用 ziplist 存数据，或者用其它的结构来存数据。目前的实现中该值是固定为 2，表示使用 ziplist 作为数据容器 recompress: bool 值，为 true 表示数据暂时解压  quicklistLZF\nList 的设计目标是存放很长的列表数据，当列表很长时占用的内存空间必然会相应增多。但是当列表很长的时候，List 中访问频率最高的是两端的数据，中间的数据访问频率较低。\nRedis 会将中间的节点进行压缩，在需要使用时再进行解压缩，进一步减少数据存储的空间。\nquicklistLZF 是对 ziplist 利用 LZF 算法进行压缩后得到的数据结构：\n sz: 表示压缩后的 ziplist 大小 compressed: 是个数组，存放压缩后的 ziplist 字节数组  配置中 list-compress-depth 用来配置 quicklist 首尾两端不被压缩的 quicklistNode 节点个数：\n 0 特殊值，表示所有节点都不压缩 1 表示 quicklist 首尾各有 1 个节点不压缩，中间的节点压缩 2 表示 quicklist 首尾各有 2 个节点不压缩，中间的节点压缩  数据操作   头部和尾部插入\n头部插入和尾部插入比较简单，主要分为两种情况：\n 如果头节点（或尾节点）ziplist 没有超过限制大小，那么直接插入节点即可。 如果头节点（或尾节点）ziplist 超过了限制大小，那么新建一个 quicklistNode，将数据插入到新节点中。    任意位置插入\n任意位置插入比较复杂，分为四种情况：\n 插入位置 ziplist 没有超过限制大小，那么直接插入节点即可。 插入位置 ziplist 超过限制大小，但插入位置位于 ziplist 两端，如果相邻节点的 ziplist 没有超过限制大小，那么将数据插入到相邻节点的 ziplist 中。 插入位置 ziplist 超过限制大小，但插入位置位于 ziplist 两端，如果相邻节点的 ziplist 超过限制大小，此时新建一个 quicklistNode，将数据插入到新节点中。 插入位置 ziplist 超过限制大小，且插入位置位于 ziplist 中间，那么将当前节点分裂成两个新节点，将数据插入其中一个节点。    查找\nlist 的查找操作主要面向 index，每个节点的 ziplist 都有长度属性，根据每个节点的长度找到对应的节点，再根据 ziplist 的 index 找到数据。\n  删除\n在区间删除时，有以下几个步骤：\n 找到 start 所在的 quicklistNode 节点 计算删除的元素是否小于要删除的 count 如果不满足删除的个数，则会移动至下一个 quicklistNode 继续删除 依次循环直到删除完成为止    IntSet 当集合类型成员都是整数，且数量较少时，Redis 会使用整数集合这种数据结构。\n这种数据结构默认情况会使用最小的编码类型存储整数，分配内存。只有当存储了较大的整数时，才会采用更大的编码格式。\n优点：\n 节省内存  数据结构  Redis IntSet \n encoding: 编码方式，默认值是 INTSET_ENC_INT16。其值直接影响 contents 数组中元素的数据类型。 length: 整数集合的元素数量，也就是 contents 数组的长度。 contents: 数组，是整数集合的底层实现。数组中的元素按照从小到达的顺序排列，不包括重复项。类型由 encoding 值决定。  升级 intset 默认的 encoding 为 INTSET_ENC_INT16，只能存储 -32768 - 32767 范围内的整数。当存储超出此范围的整数时，则需要升级数据类型，才能添加元素。\n升级的步骤如下：\n 根据新元素的类型，扩展整数集合底层数组的空间大小（包括新元素的空间） 将底层数组中的所有元素都转换成新元素相同的类型，并将转换后的元素放置到正确的位置上，放置过程（从右至左）中，维持底层数组的有序性 将新元素添加到底层数组里边（最末尾）  Intset 让集合可以保存不同长度的整数，又可以确保升级操作只在有需要的时候进行，节省了内存。\n整数集合不支持降级操作，一旦对数组进行了升级，编码就一直处于升级后的状态。\n数据操作  查询  与第一个元素判断 与最后一个元素判断 二分查找   插入不需要升级的元素  查询新元素的角标位置 分配空间 将角标后的数据依次移动位置 新元素插入角标位置 修改 set 的 length 属性    时间复杂度    操作 时间复杂度     创建一个新的整数集合 $O(1)$   添加指定元素到集合 $O(N)$   移除指定元素 $O(N)$   判断指定元素是否在集合中 $O(logN)$   随机返回一个元素 $O(1)$   取出在指定索引上的元素 $O(1)$   返回集合包含的元素个数 $O(1)$   返回集合占用的内存字节数 $O(1)$    SkipList","date":"2021-06-07T00:00:00Z","permalink":"https://wnanbei.github.io/post/redis-%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"Redis 底层数据结构"},{"content":"常见的缓存类型以及现实中常遇到的缓存问题，Redis 所采用的过期淘汰策略 LRU、LFU 等。\n缓存类型 缓存的类型分为：本地缓存、分布式缓存和多级缓存。\n本地缓存 本地缓存就是在进程的内存中进行缓存。\n本地缓存是内存访问，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展。\n分布式缓存 分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。\n缺点就是需要进行远程请求，性能不如本地缓存。\n多级缓存 实际业务中一般采用多级缓存，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中。\n在目前的一线大厂中，这也是最常用的缓存方案，单考单一的缓存方案往往难以撑住很多高并发的场景。\n缓存问题 缓存穿透 缓存穿透 Cache Penetration，指数据库和缓存中都没有符合条件的数据，导致业务系统每次都绕过缓存服务器查询下游的数据库。\n如果黑客发起针对该 key 的大量访问攻击，会导致数据库压力过大，最终击垮数据库。\n解决方案：\n 首先需要在接口层做参数校验，拒绝逻辑上没有的数据，比如 id \u0026lt; 0； 查询数据库和缓存中没有的数据，在缓存中存储空值或默认值等（具体由产品决定）；  此缓存设置的过期时间要短，避免影响真实业务； 数据库更新时，需要及时更新对应缓存数据；   网关层对单个 IP 的访问量做出限制，避免异常用户的大量暴力访问； 布隆过滤器 Bloom Filter，此算法可以非常高效的判断数据数据一定不存在或可能存在，如果判定不存在，就可以直接不查数据库直接返回。  缓存击穿 缓存击穿 Cache Breakdown，是指某一个大量请求不断访问的热点 key 突然过期时，大量请求直接访问数据库，让数据库压力瞬间增大的情况。\n解决方案：\n 使用互斥锁，在发现某个缓存为空时，先加锁，从数据库加载数据完毕后解锁。其他线程获取锁失败时，则休眠一段时间后重试。这种方式保证同时只有一个请求去数据库读取数据更新缓存； 热点数据永不过期，只更新数据；  缓存雪崩 缓存雪崩 Cache Avalanche，是指大量缓存同时过期或缓存服务宕机，造成缓存逐级崩溃，最终压垮数据库的情况。\n解决方案：\n 缓存集群部署，Redis 高可用，主从+哨兵，Redis cluster，尽量避免缓存服务的全盘崩溃； 随机过期时间，让缓存的过期时间在一定范围内随机浮动，将同一时间点的过期分散到一个时间段内，降低峰值； 热点数据永不过期，只更新数据； 数据限流，在各层缓存和数据库之间进行限流，保证系统整体可用； 系统熔断和降级，返回一些默认的值，或者友情提示，或者空白的值。  缓存一致性 缓存一致性指的是，在高并发情况下，请求使用数据旧值覆盖了缓存的新值情况。常见的有两种情况：\n先更后更：\n指的是先更新数据库，后更新缓存。此方法在以下情况会出现缓存不一致：\n 线程 A 更新数据库; 线程 B 更新数据库; 线程 B 更新缓存； 线程 A 使用旧值更新缓存。  先删后更：\n指的是先删除缓存，后更新数据库。此方法在以下情况会出现缓存不一致：\n 请求 A 先删除缓存； 请求 B 查询发现缓存不存在； 请求 B 查询数据库，得旧值； 请求 B 将旧值写入缓存； 请求 A 将新值写入数据库；  此方法可以使用延时双删策略尽量保证数据一致性，也就是请求 A 将新值写入数据库后，延时一段时间，再次删除缓存。\n解决方案：先更后删\n目前业界主流的方式是使用先更后删策略更新缓存。此方案下依然可能会有缓存不一致的可能性：\n 缓存失效； 请求 A 查询数据库，得旧值； 请求 B 更新数据库； 请求 B 删除缓存； 请求 A 将查询到的旧值写入缓存；  在此情况下，依然会产生脏数据，但是前提是：步骤 3 比步骤 2 耗时更短，但通常来说更新数据耗时比查询数据长的，所以这一情况很难出现。\n还有一个问题是请求 B 删除缓存失败怎么办，解决方案是使用一个保障删除成功的重试机制即可，比如消息队列。\nRedis 淘汰策略 定期删除 redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，定期遍历这个字典来删除到期的 key。\nRedis 默认会每秒进行十次过期扫描（100ms一次），过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。\n 从过期字典中随机取 20 个 key 删除这 20 个 key 中已经过期的 key 如果过期的 key 比率超过 1/4，重复步骤 1  此策略主要避免了当 Redis 数据量太大时，每次过期检测需要遍历所有设置了过期时间的 key，造成 cpu 负载过大的问题。\n惰性删除 惰性策略就是在客户端访问这个 key 的时候，对 key 的过期时间进行检查，如果过期了就立即删除，不会返回任何东西。\n定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。\n内存淘汰策略 由于定期删除和惰性删除策略，并不是所有的过期 key 都会被删除，所以需要内存淘汰策略进行补充。\nRedis 4.0 以前有 6 种内存淘汰策略：\n  noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键\n  allkeys-lru：加入键的时候，如果过限，首先通过 LRU 算法驱逐最久没有使用的键\n  volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键\n  allkeys-random：加入键的时候如果过限，从所有 key 随机删除\n  volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐\n  volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键\n  Redis 4.0 后新增了两种 lfu 策略：\n volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键\n  allkeys-lfu：从所有键中驱逐使用频率最少的键\n  LRU 算法 LRU(Least Recently Used) 最近最少算法用于计算淘汰最久没有使用过的 key，但 Redis 没有使用标准 LRU 实现，而是使用了一种近似的 LRU 实现方式。\n标准 LRU 标准的 LRU 算法使用一个双向链表来记录数据的最近被访问顺序。\n 新增 key 时，在链表结尾添加 node，如果超出 LRU 阈值，淘汰链表队头的 node 修改 key 时，先修改对应 node 的值，然后把 node 移动到链表队尾 访问 key 时，将 node 移动到链表队尾  Redis LRU 实现 Redis 在每一个 key 对象内部维护了一个以秒为单位的 24 位时间戳，通过对少量 key 进行采样（默认 5 个），对比时间戳，然后回收其中最久未被访问的 key。\n需要注意的是此时间戳最大只能表示 194 天，不过这对于更新频繁的缓存数据来说是够用的。\nRedis 中有三个配置和 LRU 有关：\n maxmemory: Redis 存储数据时限制的内存大小，比如 100m。超过这个数值时触发数据淘汰。此配置为 0 时，不限制内存量。64 位的系统默认值为 0，32 位的系统默认内存限制为 3GB。 maxmemory_policy: 触发数据淘汰后的淘汰策略。 maxmemory_samples: 随机采样的精度，也就是随机取出 key 的数目。该数值配置越大, 越接近于真实的 LRU 算法，但是数值越大，相应消耗也变高，对性能有一定影响，样本值默认为 5。  Redis 3.0 LRU 优化：\n优化后算法会维护一个候选池，大小为 16，池中的数据根据访问时间进行排序，第一次采样选取的 key 都会放入池中。\n  随后每次随机选取的 key 只有在访问时间小于池中最小的时间才会放入池中，直到候选池被放满。\n  池放满后，如果有新的 key 需要放入，则将池中最近被访问的移出池。\n  需要淘汰数据的时候，直接从池中选取最久没被访问的 key 淘汰掉。\n  为什么不使用标准 LRU   原生 LRU 算法需要双向链表来管理数据，需要更多的内存\n  原生 LRU 需要对所有 key 进行排序，性能损耗更高\n  如果请求符合长尾法则，那么真实 LRU 与 Redis LRU 之间表现基本无差异，实际效果基本相等\n  需要改造现有 Redis 数据结构\n据 Redis 作者说，每个 Redis Object 可以挤出 24 bits 空间，但 24 bits 不够存储两个指针，但可以存储一个低位时间戳。\n   Redis LRU 算法性能 \nLFU 算法 使用 LRU 算法，有可能一个 key 很久没有被访问，只刚刚偶尔被访问了一次，那么它就被认为是热点数据，不会被淘汰，而有些 key 将来是很有可能被访问到但被淘汰了。\nRedis 在 4.0 中新增了一种 LFU 淘汰策略，用于根据 key 的访问频率进行淘汰。\nLFU 原理是为每个 key 维护一个计数器。每当 key 被访问时，计数器增大。计数器越大，可以约等于访问越频繁。每次采样时淘汰掉访问最不频繁的 key。\nRedis LFU 实现 Redis 中有三个配置项可以调整 LFU 算法的行为：\n lfu-log-factor: 默认为 10，访问频率增长速度，值越大，访问频率增长越慢。 lfu-decay-time: 默认为 1，访问频率降低速度，值越大，访问频率降低越慢。 LFU_INIT_VAL: 默认为 5，新增 key 的默认访问频率。  LFU 使用跟 LRU 同样的 24 bits 字段记录数据。\n 前 16 bits 用于记录以分钟为单位的时间，用于表示最近一次访问频率被降低的时间。 后 8 bits 记录访问频率 counter，最大为 255。  LFU 维护了一个与 LRU 相同的候选池，用于节省排序所有 key 访问频率所需要的时间。\n增加访问频率 由于只使用 8 bits 记录访问频率，最大为 255，所以访问频率不能无限增大。Redis 的解决方式是，访问频率越高，则访问频率增加的可能性越低。\n增加频率函数如下：\n/* Logarithmically increment a counter. The greater is the current counter value * the less likely is that it gets really implemented. Saturate it at 255. */ uint8_t LFULogIncr(uint8_t counter) { if (counter == 255) return 255; double r = (double)rand()/RAND_MAX; double baseval = counter - LFU_INIT_VAL; if (baseval \u0026lt; 0) baseval = 0; double p = 1.0/(baseval*server.lfu_log_factor+1); if (r \u0026lt; p) counter++; return counter; }  首先取一个 0-1 之间的随机数 r 由 counter 和 lfu_log_factor 决定一个 0-1 之间的值 p。counter 越大，p 值越小。 比较 r 与 p，如果 r \u0026lt; p，则 counter 增加 1。  可以看到当 counter 越大，则 p 值越小，则 r \u0026lt; p 的可能性越小，则 counter 增加的几率越小。\n当 counter 为 255 时，则不再增加。\n降低访问频率 如果只增加访问频率，则有可能一个 key 在某段时间被大量访问，之后不再被使用，这样的 key 将不会被淘汰，所以需要一种根据时间降低 key 访问频率的机制。\n降低频率函数如下：\n/* If the object decrement time is reached decrement the LFU counter but * do not update LFU fields of the object, we update the access time * and counter in an explicit way when the object is really accessed. * And we will times halve the counter according to the times of * elapsed time than server.lfu_decay_time. * Return the object frequency counter. * * This function is used in order to scan the dataset for the best object * to fit: as we check for the candidate, we incrementally decrement the * counter of the scanned objects if needed. */ unsigned long LFUDecrAndReturn(robj *o) { unsigned long ldt = o-\u0026gt;lru \u0026gt;\u0026gt; 8; unsigned long counter = o-\u0026gt;lru \u0026amp; 255; unsigned long num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : 0; if (num_periods) counter = (num_periods \u0026gt; counter) ? 0 : counter - num_periods; return counter; }  函数首先取得前 16 bits 的最近一次频率被降低时间。 计算最近一次频率被降低时间与当前时间的差值。 根据 lfu_decay_time 与差值的多少计算需要降低多少访问频率。  新增 key 默认访问频率 如果一个新增 key 的默认访问频率为 0，那么这个 key 很可能快速被删除掉，所以需要为新增 key 设定一个默认的访问频率值。\n可以通过 LFU_INIT_VAL 设置，默认值为 5。\n","date":"2021-06-07T00:00:00Z","permalink":"https://wnanbei.github.io/post/redis-%E7%BC%93%E5%AD%98%E4%B8%8E%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/","title":"Redis 缓存与淘汰策略"},{"content":"Redis 使用过程中的一些规范，包括 key 的名称、禁用的命令等。\n键值设计 Key 名称设计   可读性和可管理性\n以英文冒号分隔 key，前缀概念的范围的返回从大到小，从不变到可变，从变化幅度小到变化幅度大。\n例如：yoga:user:1，表示 yoga:user:{userID}，即瑜伽子系统 ID=1 的用户信息。\n  简洁性\n保证语义的前提下，控制 key 的长度，当 key 较长时，内存占用也不容忽视。\n例如：user:{uid}:friends:messages:{mid} 可简化为 u:{uid}:f:m:{mid}。\n  不包含特殊字符\n只使用字母数字。\n反例：包含空格、换行、单双引号以及其他转义字符\n  Value 设计  string 类型控制在 10KB 以内 hash、list、set、zset 元素个数不要超过 5000 选择合适的数据类型  命令 禁用命令 禁止线上使用 keys、flushall、flushdb 等，通过 redis 的 rename 机制禁用命令，或者使用 scan 的方式渐进式处理。\n关注 O(N) 命令 N 的数量 例如 hgetall、lrange、smembers、zrange、sinter 等并非不能使用，但是需要明确N的值。\n有遍历的需求可以使用 hscan、sscan、zscan 代替。\n客户端","date":"2021-06-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/redis-%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/","title":"Redis 使用规范"},{"content":"Redis 在 centos 系统下的安装配置流程。\n安装   首先我们需要安装基础的依赖包。\nsudo yum install -y gcc gcc-c++ make jemalloc-devel epel-release   然后使用wget从官网下载最新版本的Redis，目前的最新版是4.0.11。\nwget http://download.redis.io/releases/redis-4.0.11.tar.gz 如果想要下载其他版本的话，修改连接中的版本即可。\n  接下来解压压缩包\nsudo tar -zvxf redis-4.0.11.tar.gz   进入到解压出来的目录中，由于redis提供的是已经编译完成的版本，所以直接make install安装即可。\n当然也可以在安装时通过PREFIX参数指定安装的位置。\ncd redis-4.0.11 sudo make PREFIX=/usr/local/redis install   这些步骤完成之后，将会在指定的文件夹中出现redis的服务端和客户端文件。\n配置 redis安装完毕之后，我们还需要对其做一系列的配置。\n开机启动 在一开始解压的安装文件夹中，有一个redis.conf配置文件，首先我们先在/etc中新建一个文件夹：\nsudo mkdir /etc/redis 然后将redis.conf复制到这个文件夹中去。\n为了方便使用Redis，我们可以把Redis配置成系统服务，来支持开机启动。\n  首先，创建一个服务文件。\nsudo vim /usr/lib/systemd/system/redis-server.service   然后在这个文件中添加以下内容，里面的内容需要根据你安装的Redis版本和路径进行修改。\n[Unit] Description=Redis Server After=network.target [Service] ExecStart=/usr/local/redis/bin/redis-server /etc/redis/redis.conf --daemonize no ExecStop=/usr/local/redis/bin/redis-cli -p 6379 shutdown Restart=always [Install] WantedBy=multi-user.target   最后，我们把这个redis服务设置成开机启动。\nsudo systemctl enable redis-server   需要马上打开redis服务可以使用以下命令\nsudo systemctl start redis-server   远程连接 由于Redis在安装完成后是默认禁止远程连接的，所以如果需要的话，我们需要开启远程连接。\n首先打开Redis的配置文件：\nsudo vim /etc/redis/redis.conf 然后找到其中bind 127.0.0.1这一行，将其注释，或者修改为bind 0.0.0.0。\n密码 Redis提供了一个轻量级的认证方式，可以让我们在redis.conf中配置密码。\n同样的还是在redis.conf文件中，我们需要找到requirepass这一行，这个参数就是密码。将这一行取消注释，然后将你的密码写在这里，例如：\nrequirepass pwd123 保存退出后，我们需要重启Redis服务。\nsudo systemctl restart redis-server 之后，我们打开客户端的时候需要这样验证密码：\nredis-cli -a pwd123 或者在进入客户端之后再验证密码：\nredis-cli redis 127.0.0.1:6379\u0026gt; auth pwd123 启动测试 安装以及配置完毕之后，我们需要在安装目录下检测一下安装是否成功。\n  首先为redis-cli制作一个软连接放到/usr/bin目录中，方便使用。\nln -s /usr/local/redi/bin/redis-cli /usr/bin/redis-cli   启动redis-server服务。\nsudo systemctl start redis-server   然后我们需要新开一个终端来测试redis客户端是否能启动。\nsudo redis-cli   如果这几个步骤都能够正常使用的话，那么我们的redis就安装成功了。\n","date":"2021-06-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/redis-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Redis 安装配置"},{"content":"redis 提供了两种持久化的方式，分别是 RDB(Redis DataBase) 和 AOF(Append Only File)。\nRDB RDB，就是在不同的时间点，将 redis 存储的数据生成快照并存储到磁盘等介质上。\nRedis 在进行 RDB 数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程结束，才会用这个临时文件替换上次持久化好的文件。这种特性，让我们可以随时进行备份，因为快照文件总是完整可用的。\n优点：\n Redis 会单独 fork 一个子进程进行持久化，不影响主进程性能。 大规模数据恢复更高效。 备份文件总是完整可用。  缺点：\n RDB 耗时较长，不够实时，在停机的时候会导致大量丢失数据。数据完整性较差。  AOF AOF，则是将 redis 执行过的所有写指令记录下来，在下次 redis 重新启动时，把这些写指令从前到后再重复执行一遍，实现数据恢复。开启 AOF 后，如果有写操作，如 SET 等，redis 就会追加到 AOF 文件的末尾。\n默认的 AOF 持久化策略是每秒钟 fsync（指把缓存中的写指令记录到磁盘中）一次，因为在这种情况下，redis 仍然可以保持很好的处理性能，即使 redis 故障，也只会丢失最近 1 秒钟的数据。\n优点：\n 丢失数据的可能性小。 有 Rewrite 机制可以控制 AOF 文件大小。 断电、磁盘满等问题都不会影响 AOF 文件的可用性。  缺点：\n AOF 文件会越来越大，占用较多空间。 数据恢复效率较慢。  AOF Rewrite Redis 提供了 AOF 文件重写（rewrite）机制，当 AOF 文件的大小超过所设定的阈值时，redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。\n例如调用了 100 次 INCR 指令，在 AOF 文件中可以用 rewrite 把这 100 条指令合并成一条 SET 指令。\n流程：\n redis 会创建（fork）一个重写子进程，首先读取现有的 AOF 文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。 同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的 AOF 文件中，保证原有的 AOF 文件的可用性，避免在重写过程中出现意外。 当重写子进程完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新 AOF 文件中。 追加结束后，redis 就会用新 AOF 文件来代替旧 AOF 文件。  恢复数据 因为 RDB 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以通常需要 AOF 配合同时使用。\n在 Redis 实例重启时，使用 RDB 持久化文件重新构建内存，再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。\n","date":"2021-06-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/redis-%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E7%AD%96%E7%95%A5/","title":"Redis 数据持久化策略"},{"content":"在 Redis 中，常用的 5 种数据类型和应用场景如下：\n String：缓存、计数器、限速器、分布式锁等。 List：链表、队列、微博关注人时间轴列表等。 Hash： 用户信息、Hash 表等。 Set： 去重、赞、踩、共同好友等。 Sorted Set：访问量排行榜、点击量排行榜等。  redisObject Redis 有一个核心的对象 redisObject，用来表示所有的 key。此对象中有 type 和 encoding 两个字段，用来表示 key 的类型和底层数据结构。\nRedis 使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的健(键对象)，另一个对象用作键值对的值(值对象)。\nCopytypedef struct redisObiect{ //类型 \tunsigned type:4; //编码 \tunsigned encoding:4; //指向底层数据结构的指针 \tvoid *ptr; } 不同数据类型使用不同的数据结构以提升速度。每种数据类型都有一种或者多种数据结构来支撑。\n Redis 数据类型与数据结构关系 \n这样设计有两个好处：\n 可以自由改进内部编码，而对外的数据结构和命令没有影响。 多种内部编码实现可以在不同场景下发挥各自的优势，从而优化对象在不同场景下的使用效率。  使用以下命令可以查看 Key 具体的编码方式：\nobject encoding keyName Key Redis 存储的键值对中的 key，是二进制安全的，可以使用普通的字符串来做 key，也可以使用二进制的数据，例如图片，甚至空字符。\n需要遵守的原则：\n 同一个数据库中的 key 不可重名 key 的最大值为 512MB key 不应过长。当 key 过长时，查询等命令将会因为 key 过长而花费更多的时间在 key 的比较上 key 不应太短。命名需要考虑可读性，例如 \u0026quot;user:1000:followers\u0026quot;  命令    命令 作用     DEL key key存在时删除key   EXISTS key 检查key是否存在   TYPE key 查看key的类型   RENAME key newkey 将key重命名   RENAMENX key newkey 只有当newkey不存在时，才进行重命名   KEYS pattern 查找key   RANDOMKEY 从当前数据库随机获取一个key   MOVE key db 将这个key移动到指定的另一个数据库   DUMP key 序列化key，并返回被序列化的值   EXPIRE key second 以秒为单位给key设定过期时间   PEXPIRE key milliseconds 以豪秒为单位给key设定过期时间   EXPIREAT key timestamp 把一个时间戳设置为key的过期时间   PEXPIREAT key mill-timestamp 把一个毫秒级别的时间戳设置为key的过期时间   PERSIST key 移除key的过期时间   TTL key 以秒为单位返回key的过期时间   PTTL key 以豪秒为单位返回key的过期时间    String 字符串。字符串对象的值可以是字符串、数字、甚至是二进制，最大不能超过 512MB。\n主要底层数据结构为 sds string。\n编码 字符串对象的内部编码有 3 种：int、raw 和 embstr。\n 如果字符串对象保存的是可以用 long 类型表示的整数值，那么 Redis 会将整数值保存在字符串对象的 ptr 属性中，并将编码设置为 int。 如果字符串对象保存的是一个字符串值，并且长度大于 32 字节，那么 Redis 将使用一个简单动态字符串 SDS 来保存，并将编码设置为 raw。 如果字符串对象保存的是一个字符串值，并且长度小于等于 32 字节，那么 Redis 将使用一个简单动态字符串 SDS 来保存，并将编码设置为 embstr  embstr 编码是专门用于保存短字符串的一种优化编码方式，raw 编码会通过调用两次内存分配函数来分别分配两块空间来保存 redisObject 和 SDS，而 embstr 的不同之处在于会分配一块连续的内存空间来保存 redisObject 和 SDS。\nembstr 编码的优点有以下几点：\n embstr 编码创建字符串对象所需的内存分配次数为一次 embstr 编码的字符串对象释放内存也只需要调用一次内存释放函数 embstr 编码的字符串对象的所有数据都保存在一块连续的内存里，可以更好的利用 CPU 缓存提升性能  命令    命令 作用     SET key value 给key设定或更新值   SETNX key value 只有当key不存在时才给key设定值   SETEX key second value 给key设定值，并且设定一个秒为单位的过期时间   PSETEX key milliseconds value 给key设定值，并且设定一个豪秒为单位的过期时间   SETRANGE key offset value 从offset开始，覆盖key的一部分   MSET key value [key value ...] 同时设置多个键值对   MSETNX key value [key value ...] 仅当列出的key都不存在时，同时设置多个键值对   GET key 获取key的value   MGET key1 [key2..] 一次获取多个key的value   GETSET key value 给key设定一个新的value，获取旧的value并返回   GETRANGE key start end 获取value中指定位置的内容   STRLEN key 返回key中value的长度   APPEND key value 将值添加到   INCR key 将key存储的数字加1   INCRBY key increment 将key存储的数字加上指定的数值   INCRBYFLOAT key increment 将key存储的数字加上指定的浮点数数值   DECR key 将key存储的数字减1   DECRBY key decrement 将key存储的数字减去指定的数值    List Redis 的 List 基本上是一个双向链表，可以分别在头部或者尾部添加删除数据，每一个 List 类型的 key 最多可以存储 4294967295 个元素。\n基于这样的特性，Redis 中的 List 常常被用来做消息队列之类的事情。\n使用以下方式实现：\n quicklist  命令    命令 作用     LPUSH key value1 [value2] 在List头部插入一个或多个值   RPUSH key value1 [value2] 在List尾部插入一个或多个值   LPUSHX key value 在List头部插入一个或多个值，key不存在则报错   RPUSHX key value 在List尾部插入一个或多个值，key不存在则报错   LPOP key 移除并返回List头部第一个元素   RPOP key 移除并返回List尾部最后一个元素   RPOPLPUSH source destination 移除列表尾部最后一个元素，添加到另一个列表头部   LINDEX key index 根据列表索引查看元素的值   LLEN key 查看List的长度   LRANGE key start stop 查看一定索引范围内的元素   LREM key count value 删除等于value的元素，如果count为0，则删除所有相等元素   LINSERT key BEFORE/AFTER pivot value 将value插入到列表中，位于pivot之前或之后   LSET key index value 根据index指定修改元素   LTRIM key start stop 切片裁剪List   BLPOP key1 [key2 ] timeout 移除并返回列表头部第一个元素，如果没有元素则阻塞列表直到有元素为止   BRPOP key1 [key2 ] timeout 移除并返回列表尾部最后一个元素，如果没有元素则阻塞列表直到有元素为止   BRPOPLPUSH source destination timeout 移除列表尾部最后一个元素，添加到另一个列表头部，如果没有元素则阻塞列表直到有元素为止    Hash Redis 的 Hash 类型是一个由 field-value 键值对组成的集合。其中 field 和 value 都是字符串类型。\nhash 类型都非常适合用于保存对象。而且，大小较小的 hash（元素较少、值比较短）以特殊的方式存储在内存中，使得其读写效率非常之高。\n实现方式 有两种不同的实现方式：\n ziplist - 满足以下条件时：  元素个数少于 hash-max-ziplist-entries(默认 512) 所有值都小于 hash-max-ziplist-value(默认 64)   hashtable - 不满足 ziplist 条件时  命令    命令 作用     HSET key field value 添加或修改一个字段的值   HMSET key field1 value1 [field2 value2 ] 同时添加或修改一个或多个字段的值   HSETNX key field value 只有当字段不存在时，才添加一个字段的值   HLEN key 获取所有字段的数量   HSTRLEN key field c查看key中指定字段的value的长度   HEXISTS key field 查看字段是否存在   HDEL key field1 [field2] 删除一个或多个字段   HGET key field 获取某一个字段的值   HMGET key field1 [field2] 获取一个或多个字段的值   HKEYS key 获取一个key中所有的field   HVALS key 获取一个key中所有的value   HGETALL key 获取一个key中所有field和value   HINCRBY key field increment 给指定字段的value加上指定的increment数值   HINCRBYFLOAT key field increment 给指定字段的value加上指定的increment浮点数数值    Set Set 类型是由字符串类型元素构成的无序集合，其元素必须是唯一的。由于 Redis 中的集合类型都是通过 HASH 表实现的，所以其添加、查找、删除的复杂度都是O(1)。\nRedis 中还给集合类型提供了求交集、并集、差集等操作。\n实现方式 有两种不同的实现方式：\n intset - 满足以下条件时：  集合中元素都是整数。 元素个数少于 set-maxintset-entries(默认 512)。   hashtable - 不满足 intset 条件时  命令    命令 作用     SADD key member1 [member2] 给集合添加一个或多个元素   SCARD key 返回集合的成员数量   SISMEMBER key member 判断元素是否是集合的成员   SMEMBERS key 返回集合中所有的成员   SRANDMEMBER key [count] 随机返回集合中一个或多个元素   SREM key member1 [member2] 移除集合中的一个或多个元素   SPOP key 随机移除并返回集合中的一个元素   SMOVE source destination member 将一个元素member从source集合移动到destination集合   SDIFF key1 [key2] 返回给定的所有集合的差集   SDIFFSTORE destination key1 [key2] 返回给定的所有集合的差集，并存储到destination集合中   SINTER key1 [key2] 返回给定的所有集合的交集   SINTERSTORE destination key1 [key2] 返回给定的所有集合的交集，并存储到destination集合中   SUNION key1 [key2] 返回给定的所有集合的并集   SUNIONSTORE destination key1 [key2] 返回给定的所有集合的并集，并存储到destination集合中    Sorted Set 有序集合，使用 score 分数进行排序，允许分数相同，不允许集合元素值相同。分数相同时，按照元素值进行排序。\n实现方式 有两种不同的实现方式：\n ziplist - 满足以下条件时：  Set 键值对数量少于 128 个。 每个元素的长度都小于 64 字节。   skiplist - 不满足 ziplist 条件时。  命令    命令 作用     ZADD key score1 member1 [score2 member2] 添加或更新一个或多个元素及其分数   ZCARD key 获取集合中元素的数量   ZCOUNT key min max 获取指定分数范围内元素的数量   ZSCORE key member 获取某个元素的分数   ZRANK key member 获取某个元素的排名   ZLEXCOUNT key min max 获取指定区间内元素的数量   ZRANGE key start stop [WITHSCORES] 返回指定排名区间内的元素   ZRANGEBYLEX key min max [LIMIT offset count] 返回指定区间内的元素   ZRANGEBYSCORE key min max [WITHSCORES][LIMIT] 返回指定分数区间内的元素   ZINCRBY key increment member 给指定元素的分数加上increment数值   ZREM key member [member ...] 移除一个或多个元素   ZREMRANGEBYRANK key start stop 移除排名区间内的元素   ZREMRANGEBYSCORE key min max 移除分数区间内的元素   ","date":"2021-06-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Redis 数据类型"},{"content":"Redis 的性能、整体架构设计、单线程原因等。\n性能 根据官方数据，Redis 的 QPS 可以达到约 100000。使用 pipeline 批处理甚至可以达到 100W+。\n 横轴是连接数 纵轴是 QPS  测试性能 运行以下命令可以测试同时执行 10 万个请求时的性能：\n$ redis-benchmark -n 100000 -q 高性能原因   纯内存 I/O\n相较于其他基于磁盘的 DB，Redis 的纯内存操作有着天然的性能优势。\n  I/O 多路复用\n基于 epoll/select/kqueue 等 I/O 多路复用技术，实现高吞吐的网络 I/O。\n  单线程模型\n保证了每个操作的原子性，避免了多线程频繁上下文切换，以及同步机制如锁带来的开销。\n  高效的数据结构\n 全局哈希表，时间复杂度为 $O(1)$。 根据实际存储的数据类型选择底层不同的数据结构，优化了读写速度。    整体架构 首先需要明确的一点是，常说 Redis 是单线程，指的是 Redis 的数据主处理程序为单线程，在较高版本里，部分命令和网络 IO 部分已被更改为多线程执行：\n Redis v4.0（引入多线程处理异步任务） Redis v6.0（正式在网络模型中实现 I/O 多线程）  架构 使用单线程原因 官方回答：\n It\u0026rsquo;s not very frequent that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound. For instance, using pipelining Redis running on an average Linux system can deliver even 1 million requests per second, so if your application mainly uses O(N) or O(log(N)) commands, it is hardly going to use too much CPU.\n 对于 Redis 这种完全的纯内存的操作来说，执行速度非常快，CPU 通常不会是性能瓶颈，因为大多数请求不是 CPU 密集型任务，而是 I/O 密集型。\nRedis 真正的性能瓶颈在于网络 I/O，也就是客户端和服务端之间的网络传输延迟，因此 Redis 选择了单线程的 I/O 多路复用来实现它的核心网络模型。\n具体原因：\n  避免过多的上下文切换开销\n多线程调度过程中需要在 CPU 之间切换线程上下文 context，上下文的切换又涉及程序计数器、堆栈指针和程序状态字等一系列的寄存器置换、程序堆栈重置甚至是 CPU 高速缓存、TLB 快表的汰换。\n单一进程内多线程共享进程地址空间，因此线程上下文比之进程上下文要小得多，如果是跨进程调度，则需要切换掉整个进程地址空间。\n如果是单线程则可以规避进程内频繁的线程切换开销，因为程序始终运行在进程中单个线程内。\n  避免同步机制的开销\n如果 Redis 选择多线程模型，那么势必涉及到底层数据同步的问题，则必然会引入某些同步机制，比如锁。\nRedis 不仅提供了简单的 key-value 数据结构，还有 list、set 和 hash 等等其他丰富的数据结构，而不同的数据结构对同步访问的加锁粒度又不尽相同，可能会导致在操作数据过程中带来很多加锁解锁的开销，增加程序复杂度的同时还会降低性能。\n  简单可维护\n简单可维护性必然是 Redis 早期的核心准则之一，而引入多线程必然会导致代码的复杂度上升和可维护性下降。\n  多线程异步操作 在 Redis v4.0 中，Redis 添加了一些多线程异步执行的命令。此举主要针对的是那些非常耗时的命令，通过将这些命令的执行进行异步化，避免阻塞单线程的事件循环。\n比如 DEL 命令是用来删除掉一个或多个 key 储存的值，大多数情况下要删除的 key 并不大，所以可以很快执行完，但是如果你要删的是一个超大的键值对，里面有几百万个对象，那么这条命令可能会阻塞至少好几秒，又因为事件循环是单线程的，所以会阻塞后面的其他事件，导致 Redis 吞吐量下降。\n于是，在 Redis v4.0 之后增加了一些非阻塞命令如 UNLINK、FLUSHALL ASYNC、FLUSHDB ASYNC。\nUNLINK 命令是 DEL 的异步版本，它不会同步删除数据，而只是把 key 从 keyspace 中暂时移除掉，然后将任务添加到一个异步队列，最后由后台线程去删除。不过如果用 UNLINK 去删除一个很小的 key，用异步的方式反而开销更大，所以它会先计算一个开销的阈值，只有当这个值大于 64 才会使用异步的方式去删除 key，对于基本的数据类型如 List、Set、Hash，阈值就是其中存储的对象数量。\n除此之外，在 Redis v4.0 中，Redis 主线程启动后，会创建三个子线程来负责 AOF 日志写操作、键值对删除以及关闭文件描述符的异步执行。\nI/O 多路复用 Redis 内部实现了一个高性能的事件库：AE，基于 epoll/select/kqueue/evport 四种事件驱动技术，实现 Linux/MacOS/FreeBSD/Solaris 多平台的高性能事件循环模型。\nRedis 的核心网络模型正式构筑在 AE 之上，包括 I/O 多路复用、各类处理器的注册绑定，都是基于此才得以运行。\n多线程网络模型 Redis 单线程模型 从 Redis 的 v1.0 到 v6.0 版本之前，Redis 的核心网络模型一直是一个典型的单 Reactor 模型：利用 epoll/select/kqueue 等多路复用技术，在单线程的事件循环中不断去处理事件（客户端请求），最后回写响应数据到客户端。\n Redis单线程模型 \n  client\n客户端对象，Redis 是典型的 CS 架构，客户端通过 socket 与服务端建立网络通道然后发送请求命令，服务端执行请求的命令并回复。\nRedis 使用结构体 client 存储客户端的所有相关信息，包括但不限于：\n 封装的套接字连接 *conn 当前选择的数据库指针 *db 读入缓冲区 querybuf 写出缓冲区 buf 写出数据链表 reply    aeApiPoll\nI/O 多路复用 API，是基于 epoll_wait/select/kevent 等系统调用的封装，监听等待读写事件触发，然后处理，它是事件循环（Event Loop）中的核心函数，是事件驱动得以运行的基础。\n  acceptTcpHandler\n连接应答处理器，底层使用系统调用 accept 接受来自客户端的新连接，并为新连接注册绑定命令读取处理器，以备后续处理新的客户端 TCP 连接；除了这个处理器，还有对应的 acceptUnixHandler 负责处理 Unix Domain Socket 以及 acceptTLSHandler 负责处理 TLS 加密连接。\n  readQueryFromClient\n命令读取处理器，解析并执行客户端的请求命令。 beforeSleep：事件循环中进入 aeApiPoll 等待事件到来之前会执行的函数，其中包含一些日常的任务，比如把 client-\u0026gt;buf 或者 client-\u0026gt;reply （后面会解释为什么这里需要两个缓冲区）中的响应写回到客户端，持久化 AOF 缓冲区的数据到磁盘等，相对应的还有一个 afterSleep 函数，在 aeApiPoll 之后执行。\n  sendReplyToClient\n命令回复处理器，当一次事件循环之后写出缓冲区中还有数据残留，则这个处理器会被注册绑定到相应的连接上，等连接触发写就绪事件时，它会将写出缓冲区剩余的数据回写到客户端。\n ","date":"2021-06-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/redis-%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/","title":"Redis 整体架构"},{"content":"sync.Mutex 是一个互斥锁，默认为零值时为开锁状态。\n用法 使用方式 Lock 方法锁住 m，如果 m 已经加锁，则阻塞直到 m 解锁。\nfunc (m *Mutex) Lock() Unlock 方法解锁 m，如果 m 未加锁会导致运行时错误。\nfunc (m *Mutex) Unlock() 数据结构 type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked  mutexWoken mutexStarving mutexWaiterShift = iota )   state\n是一个公用字段，共 32 位。其中低三位分别表示：\n Mutex 是否已被加锁 是否有某个唤醒的 G 要尝试获取锁 Mutex 是否处于饥饿状态  高 29 位则表示等待锁的 G 数量。\n  sema\nsema 是一个信号量，用来实现阻塞/唤醒申请锁的 G。\n  执行流程 Mutex Lock 上锁流程：\n 非饥饿模式下，新获取锁的 G 将会进入自旋，去竞争锁。为了避免自旋消耗太多 cpu，G 最多会自旋 4 次,每次空转 30 个 cpu 时钟周期；   syncMutexLock \nMutex UnLock 解锁流程：\n syncMutexUnlock \n饥饿状态 互斥锁有两种状态：正常状态和饥饿状态。\n正常状态：\n所有等待锁的 G 按照 FIFO 顺序等待。\n 刚唤醒的 G 不会直接拥有锁，而是会和新请求锁的 G 去竞争锁； 新请求锁的 G 具有一个优势：它正在 CPU 上执行； 可能有好几个 G 同时在新请求锁，所以刚唤醒的 G 有很大可能在锁竞争中失败； 在这种情况下，这个被唤醒的 G 在没有获得锁之后会加入到等待队列的最前面。  饥饿状态：\n如果一个等待的 G 超过 1ms 没有获取锁，那么它将会把锁转变为饥饿模式。\n 饥饿模式下，锁的所有权将从执行 unlock 的 G 直接交给等待队列中的第一个 G; 新来的 G 将不能再去尝试竞争锁，即使锁是 unlock 状态，也不会去尝试自旋操作，而是放在等待队列的尾部; 如果一个等待的 G 获取了锁，并且满足以下其中一个条件,那么该 G 会将锁的状态转换为正常状态:  它是队列中的最后一个 G； 它等待的时间小于 1ms；    总结：\n正常模式具有较好的性能，因为 G 可以连续多次尝试获取锁，即使还有其他的阻塞等待锁的 G，也不需要进入休眠阻塞。\n饥饿模式的作用是阻止尾部延迟的现象。\n总结  Mutex 不可被复制； 就算在较低 QPS 下，Mutex 的锁竞争也会比较激烈。如果一定要使用 Mutex，一定要采用取模分片的方式去使用其中一个 Mutex 进行资源控制，降低锁粒度； 不同 G 可以 Unlock 同一个 Mutex，但是 Unlock 一个无锁状态的 Mutex 会报错； Mutex 不是可重入锁，如果连续两次 Lock 操作，会直接死锁。 ","date":"2021-05-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E4%BA%92%E6%96%A5%E9%94%81-sync.mutex/","title":"Go 互斥锁 sync.Mutex"},{"content":"atomic 包封装了系统底层的原子操作。官方建议尽量少使用此包的原子操作，尽量遵循通过通信分享内存，而不是通过分享内存来通信的原则。\n这个包的方法有以下特点：\n 方法操作的都是 int 系列类型或指针。 操作的数据需要其地址。  用法 加法 原子性的将 delta 与 addr 相加，并返回新值。\nfunc AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) 使用 int 时传入负数就意味着减法，但 uint 类型限制了数据的符号，所以如果要减法需要利用二进制补码机制：\nAddUint32(\u0026amp;x, ^uint32(c-1)) AddUint64(\u0026amp;x, ^uint64(c-1)) 每次递减 1 可以这样：\nAddUint32(\u0026amp;x, ^uint32(0)) AddUint64(\u0026amp;x, ^uint64(0)) 读取 原子性的读取 addr 的值。\nfunc LoadInt32(addr *int32) (val int32) func LoadInt64(addr *int64) (val int64) func LoadUint32(addr *uint32) (val uint32) func LoadUint64(addr *uint64) (val uint64) func LoadUintptr(addr *uintptr) (val uintptr) func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer) 存储 原子性的将值 val 存储到 addr。\nfunc StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) 交换 原子性的将值 new 交换给 addr，并返回旧值。\nfunc SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) 先比较再交换，原子性的先进行比较，如果 addr 与 old 值相同，则将 new 交换给 addr，返回的 swapped 表示是否进行了交换。\nfunc CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) Value Value 是 atomic 包中用来存储任意类型值的容器。主要有两个方法：\nfunc (v *Value) Load() (x interface{}) // 获取 v 的值 func (v *Value) Store(x interface{}) // 存储 v 的值 例1，此例用于一个经常读取，但很少写入的数据结构：\ntype Map map[string]string var m atomic.Value m.Store(make(Map)) var mu sync.Mutex // 仅仅用于写入  // 不需要进一步同步的读取函数 func read(key string) (val string) { m1 := m.Load().(Map) return m1[key] } // 不需要进一步同步的写入函数 func insert(key, val string) { mu.Lock() // 保证与其他潜在写入者同步  defer mu.Unlock() m1 := m.Load().(Map) // 读取数据  m2 := make(Map) // 创建一个新 map  for k, v := range m1 { m2[k] = v // 复制所有数据到新的 map 中  } m2[key] = val // 写入更新数据  m.Store(m2) // 原子性的将这个对象替换为更新以后的 map  // 这一点开始后所有新的读取者都会读取新版的数据  // 旧版本将在读取者（如果存在）读取完毕后被垃圾回收 } 例2，此例用于周期性的更新数据，并传播给使用者：\nfunc loadConfig() map[string]string { // 加载 config 数据 \treturn make(map[string]string) } func requests() chan int { // 进来的请求 \treturn make(chan int) } func main() { var config atomic.Value config.Store(loadConfig()) // 存储初始 config 数据 \tgo func() { // 每十秒加载一次 config 数据 \tfor { time.Sleep(10 * time.Second) config.Store(loadConfig()) } }() // 使用最新的 config 数据处理进来的请求 \tfor i := 0; i \u0026lt; 10; i++ { go func() { for r := range requests() { c := config.Load() // 用 c 处理请求 \t_, _ = r, c } }() } } ","date":"2021-05-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C-atomic/","title":"Go 原子操作 atomic"},{"content":"sync.Pool 是一个协程安全的内存池。主要用于增加临时对象的内存复用率，减少内存分配和 GC STW 的开销。、\n用法 使用方式 节选自 gin 的例子：\nfunc (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { c := engine.pool.Get().(*Context) c.writermem.reset(w) c.Request = req c.reset() engine.handleHTTPRequest(c) engine.pool.Put(c) }   Get 方法会获取一个 Pool 已经存在的对象，如果没有，那么就调用初始化时定义的 New 方法来初始化一个对象。\n  Put 方法会把对象放回池子。调用之后仅把这个对象放回池子，池子里面的对象什么时候真正释放不受外部控制。\n  重点  sync.Pool 是线程安全的，但 Pool.New 不是线程安全的，此函数可能被并发调用； sync.Pool 不能被复制； sync.Pool 内部元素的回收被 GC 影响，不适合于做连接池，因为连接池需要自己管理对象的生命周期； 不要对 Get 得到的对象有任何假设，更好的做法是归还对象时，将对象清空； sync.Pool 不可以指定⼤⼩，⼤⼩只受制于 GC 临界值； 在加入 victim 机制前，sync.Pool 里对象的最⼤缓存时间是一个 GC 周期，当 GC 开始时，没有被引⽤的对象都会被清理掉。加入 victim 机制后，最大缓存时间为两个 GC 周期； sync.Pool 的最底层使用切片加链表来实现双端队列，并将缓存的对象存储在切片中。  数据结构 以下是 sync.Pool 的整体结构：\n \nlocal\nsync.Pool 的 local 是一个切片，存储了多个 poolLocal 对象，每个 P 都有一个专属的 poolLocal，这样可以使 P 在执行时基本只需要访问自己拥有的 poolLocal。\npoolLocalInternal\n每个 poolLocal 内部都有一个 **private **和 shared。\n private 区只存放一个对象，因为每个 P 同时执行的 G 只有一个，所以在 private 写入和取出对象是不需要加锁的。 shared 区是一个双端链表，存放了多个对象，此区域的对象可以被其他 P 获取到。  poolChain\n在 go1.13 优化过后，poolChain 不再使用加锁的切片，而是使用双向链表，每个链表节点指向一个无锁环形队列。\n此数据结构逻辑为单生产者，多消费者。\n 只能由所属的 P 进行生产，并只能放在队列的头部。由于每个 P 任意时刻只有一个 G 被运行，所以存放对象不需要加锁。 消费可以由所有的 P 进行消费。  由所属的 P 来 Get 时，从队列头部取，也不需要加锁，理由同上。 由其他 P 来 Get 时，只能从队列尾部取，由于其他 P 可能有多个，所以使用 CAS 来实现无锁。    执行流程 Pool.Get 执行流程：\n syncPoolGet \nPool.Put 执行流程：\n syncPoolPut \nvictim 机制 在 Go 1.13 版本中，新增了 victim 机制来优化 sync.Pool 的性能。\n在旧版本中，每次 GC 都会将 Pool 中所有闲置的对象全部回收。此时如果存在大量的闲置对象，那么 GC 的 STW 压力会骤然变大，消耗的时间也会变长，重新 New 创建对象的消耗也会变大。\nvictim 机制，则是在 GC 时，将 local 中的所有对象移动到 victim 中，在下一次 GC 时，再删除掉 victim 中的元素，并又一次将 local 中的对象移动到 victim 中。\n以下是新版的 Pool GC 执行流程：\n syncPoolGC \n在此过程中，Get 如果在 local 中找不到对象，会去 victim 中查找，Put 会将取出的对象重新放回 local 中。\n此机制使得 sync.Pool 中闲置对象的最大缓存时间，从一个 GC 周期变成了两个 GC 周期。\n","date":"2021-05-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%AF%B9%E8%B1%A1%E6%B1%A0-sync.pool/","title":"Go 对象池 sync.Pool"},{"content":"sync.Map 是标准库 sync 中实现的并发安全的 map。\n用法 使用方式    操作 普通 map sync.Map     map 获取某个 key map[1] sync.Load(1)   map 添加元素 map[1] = 10 sync.Store(1, 10)   map 删除一个 key delete(map, 1) sync.Delete(1)   遍历 map for\u0026hellip;range sync.Range()    sync.Map 两个特有的函数:\n LoadOrStore - sync.Map 存在就返回，不存在就插入 LoadAndDelet - sync.Map 获取某个 key，如果存在的话，同时删除这个 key  例子：\nvar syncMap sync.Map syncMap.Store(\u0026#34;11\u0026#34;, 11) syncMap.Store(\u0026#34;22\u0026#34;, 22) fmt.Println(syncMap.Load(\u0026#34;11\u0026#34;)) // 11 fmt.Println(syncMap.Load(\u0026#34;33\u0026#34;)) // 空  fmt.Println(syncMap.LoadOrStore(\u0026#34;33\u0026#34;, 33)) // 33 fmt.Println(syncMap.Load(\u0026#34;33\u0026#34;)) // 33 fmt.Println(syncMap.LoadAndDelete(\u0026#34;33\u0026#34;)) // 33 fmt.Println(syncMap.Load(\u0026#34;33\u0026#34;)) // 空  syncMap.Range(func(key, value interface{}) bool { fmt.Printf(\u0026#34;key:%v value:%v\\n\u0026#34;, key, value) return true }) 数据结构 type Map struct { mu Mutex read atomic.Value // readOnly read map  dirty map[interface{}]*entry // dirty map  misses int } read\n是 atomic.Value 类型，主要负责并发读取。使用 lock free 的方式保证 load/store 的原子性。\n 如果需要更新 read，则需要加锁保护。对于 read 中存储的 entry 字段，可能会被并发地 CAS 更新。 如果要更新一个之前已被删除的 entry，则需要先将其状态从 expunged 改为 nil，再拷贝到 dirty 中，然后再更新。  dirty\n是一个非线程安全的原始 map。使用 mutex 保证并发安全。\ndirty 包含新写入的 key，并且包含 read 中的所有未被删除的 key。这样，可以快速地将 dirty 提升为 read 对外提供服务。\n如果 dirty 为 nil，那么下一次写入时，会新建一个新的 dirty，这个初始的 dirty 是 read 的一个拷贝，但除掉了其中已被删除的 key。\n 当 dirty 为 nil 的时候，read 就代表 map 所有的数据。 当 dirty 不为 nil 的时候，dirty 代表 map 所有的数据。  misses\n用于记录未命中 read 缓存的次数。\n 每次在 read 中没找到数据，而在 dirty 中找到，则这个数字加 1。 当 misses 大于 dirty 的数量时，会将 dirty 的数据整体复制到 read，并清空 dirty，此操作时间复杂度为 O(N)。  使用场景 sync.Map 里面有两个普通 map，read map 主要负责读，dirty map 负责读和写（加锁）。\n在读多写少的场景下，read map 的值基本不发生变化，可以让 read map 做到无锁操作，就减少了使用 Mutex + Map 必须的加锁/解锁环节，因此也就提高了性能。\n如果某些 key 写操作特别频繁，sync.Map 基本就退化成了 Mutex + Map，甚至有可能性能不如 Mutex + Map。\n所以 sync.Map 适用于以下场景：\n 读多写少 写操作多，但是修改的 key 和读取的 key 特别不重合。  执行流程 sync.Map.Load() 取出对象流程：\n syncMapLoad \nsync.Map.Store() 插入对象流程：\n syncMapStore \nsync.Map.LoadAndDelete() 删除对象流程：\n syncMapDelete \n","date":"2021-05-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8%E7%9A%84-sync.map/","title":"Go 并发安全的 sync.Map"},{"content":"","date":"2021-05-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E6%A0%87%E5%87%86%E5%BA%93-sync.waitgroup/","title":"Go 标准库 sync.WaitGroup"},{"content":"sync.RWMutex 是一个读写锁，在读多写少的场景中，比 Mutex 的并发能力有很大的提升。\n用法 使用方式 读写锁的读锁与写锁、写锁与写锁互斥，读锁与读锁之间互不影响。\nfunc (rw *RWMutex) Lock // 写锁加锁 func (rw *RWMutex) Unlock // 写锁解锁 func (rw *RWMutex) RLock // 读锁加锁 func (rw *RWMutex) RUnlock // 读锁解锁 数据结构 type RWMutex struct { w Mutex // held if there are pending writers \twriterSem uint32 // semaphore for writers to wait for completing readers \treaderSem uint32 // semaphore for readers to wait for completing writers \treaderCount int32 // number of pending readers \treaderWait int32 // number of departing readers } w - 用互斥锁解决多个 writer 的竞争。\n 当有 G 获取写锁后，会阻塞其他 G 的写操作。  writerSem - 写操作的信号量。\nreaderSem - 读操作的信号量。\nreaderCount - 当前读操作的数量，以及是否有写操作在等待。\n 每一次获取读锁，都会将此数量加 1，如果此数量为负数，说明有 G 获取了写锁，当前 G 会陷入休眠等锁释放。 每一次释放读锁，都会将此数量减 1。 获取写锁时，会阻塞后续的读操作，并休眠等待当前正在进行的读操作执行完毕。 释放写锁时，会将此数量变回正数，释放读锁。  readerWait - 写操作请求锁时，需要等待完成的读操作数量。\n总结 读写互斥锁在互斥锁之上提供了额外的更细粒度的控制，能够在读操作远远多于写操作时提升性能。\n","date":"2021-05-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E8%AF%BB%E5%86%99%E9%94%81-sync.rwmutex/","title":"Go 读写锁 sync.RWMutex"},{"content":"在 MySQL 中，不同的 Join 语句会使用不同的算法扫描数据。\n直接使用 Join 时，MySQL 的优化器会自动选定 Join 的驱动表，如果使用 straight_join 可以指定前表为驱动表。\n执行流程 Index Nested-Loop Join 当可以用上被驱动表的索引时，会使用 Index Nested-Loop Join 算法，简称 NLJ。\n执行流程：\n 遍历并取出 t1 驱动表中符合条件的数据。 根据取出数据的 ON 的条件值，去 t2 被驱动表中查找满足条件的数据。  由于查询 t2 被驱动表使用的是索引，所以 NLJ 的性能良好，比拆分成多条单表 SQL 性能更好。\nBlock Nested-Loop Join 当无法使用被驱动表上的索引时，需要全表扫描被驱动表，此时 MySQL 会使用 Block Nested-Loop Join，简称 BNL。\n执行流程：\n 把表 t1 需要用到的数据列读入线程内存 join_buffer 中。 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。  使用 BNL 与直接全表扫描，扫描的行数基本是一样的，但是 BNL 在内存中进行判断，性能会更好。\n由于有可能 join_buffer 放不下驱动表，BNL 会将驱动表分块放入 join_buffer，对比完被驱动表以后换下一块驱动表，这样会导致 Join 性能降低很多，如果遇到这种情况，可以增大 join_buffer_size 的大小。\n准则 是否可以使用 Join  如果可以使用 NLJ，则可以使用 Join 语句，比拆分成多条单表 SQL 性能更好。 如果只能使用 BNL，则会占用大量系统资源，此情况避免使用 Join。  Join 使用准则  Join 关联字段必须建索引。 使用小表为驱动表。  优化 MRR BKA","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/mysql-join-%E8%BF%9E%E6%8E%A5%E8%AF%A6%E8%A7%A3/","title":"MySQL Join 连接详解"},{"content":"根据加锁的范围，MySQL 的锁大致可以分成三类：\n 全局锁 表锁 行锁  根据加锁的方式，锁通常分为两类：\n  读锁（read lock），也叫共享锁（shared lock）\n针对同一份数据，多个读操作可以同时进行而不会互相影响（select），只会阻塞写操作\n  写锁（write lock），也叫排他锁（exclusive lock）\n当前操作没完成之前，会阻塞其它读和写操作（update、insert、delete）\n  全局锁 MySQL 提供一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。\n此命令可以让整个库处于只读状态，之后其他线程的以下语句会被阻塞：\n 数据更新语句（数据的增删改） 数据定义语句（包括建表、修改表结构等） 更新类事务的提交语句  全局锁的典型使用场景是做全库逻辑备份。\n表锁 表锁的语法是 lock tables … read/write。可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。\n注：lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n特点  对整张表加锁 开销小 加锁快 无死锁 锁粒度大，发生锁冲突概率大，并发性低  MDL 元数据锁 元数据锁（metadata lock）是一种表级锁。\nMDL 的作用是，确保读取数据时，表结构不会被修改，保证读写的正确性。MDL 不需要显式使用，每执行一条 DML、DDL 语句时都会申请 MDL 锁。\n  对表做增删改查操作的时候，加 MDL 读锁\n读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n  对表做结构变更操作的时候，加 MDL 写锁\n读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n  特点  事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。 MDL 锁实现于 MySQL 的 server 层。 申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁。  版本  MySQL 5.5 版本中引入 MDL  行锁 MySQL 行锁由引擎层实现，InnoDB 支持行锁，MyISAM 不支持。\n在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n特点  对一行数据加锁 开销大 加锁慢 会出现死锁 锁粒度小，发生锁冲突概率最低，并发性高  优化  如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。  死锁 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。\n处理策略 出现死锁以后，有两种策略：\n  直接进入等待，直到超时。\n这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。\n在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。\n  发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。\n将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，此参数默认为 on。\n  死锁检测 死锁检测是一个时间复杂度是 O(n) 的操作。每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁。如果大量并非要修改同一行数据，会消耗大量的 CPU 资源。\n解决由这种热点行更新导致的性能问题，有以下几个方案：\n  确保业务一定不会出现死锁的情况下，临时关闭死锁检测。\n这种操作本身带有一定的风险，因为关闭死锁检测意味着可能会出现大量的超时，这是业务有损的。\n  控制并发度。\n如果同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。可以从以下几个方向控制并发度：\n 数据库服务端硬性限制并发线程数量 将一行数据横向拆分成多行，比如账户总额拆分成 10 行，总额由 10 行数据相加得到    间隙锁 为了解决幻读问题，InnoDB 引入了间隙锁 (Gap Lock)。间隙锁指的是将两条相连数据间的位置锁住，不能插入数据。\n行锁和间隙锁组合起来，就叫做 next-key lock。\n间隙锁是一个在索引记录之间的间隙上的锁，使用间隙锁，检索条件必须有索引。没有索引 MySQL 会全表扫描，锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加。\n加锁规则  加锁的基本单位是 next-key lock，是前开后闭区间。 查找过程中访问到的对象才会加锁。 索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。 索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。 ","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/mysql-%E4%B8%AD%E7%9A%84%E9%94%81/","title":"MySQL 中的锁"},{"content":"事务是保证一组数据库操作，要么全部成功，要么全部失败。\n在 MySQL 中，事务支持在引擎层实现。MySQL 并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\nACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）。\n隔离级别 通常而言，事务隔离越严格，效率就会越低。因此需要要在二者之间寻找一个平衡点。\n类型 SQL 标准的事务隔离级别包括以下四种，隔离程度依次递增：\n  读未提交（read uncommitted）\n事务还没提交时，它做的变更就能被别的事务看到。\n  读已提交（read committed）\n事务提交之后，它做的变更才会被其他事务看到。\n  可重复读（repeatable read）\n事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n  串行化（serializable）\n对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n  注：MySQL 默认隔离级别为可重复读。\n实现方式  在可重复读隔离级别下，数据库会在事务启动时创建一个视图，整个事务存在期间以此视图的逻辑结果为准。 读提交隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。 读未提交隔离级别下直接返回记录上的最新值，没有视图概念。 串行化隔离级别下直接用加锁的方式来避免并行访问。  可重复读 可重复读的核心就是一致性读（consistent read）。\n而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\nUndo Log undo log 就是在修改数据之前，把数据的原值先保存起来（undo log），以便能够回滚数据。\nundo log 有两个用处，事务回滚和多版本并发控制（MVCC）。\n注：undo log 做的是逻辑上的数据回滚，存储在单独的表空间中。\n类型 undo log 有两种类型，分别是 insert undo log 和 update undo log：\n  insert undo log 记录的是 insert 语句对应的 undo log。\n不涉及 MVCC，事务结束以后就可以删除。\n  update undo log 记录的是 update、delete 语句对应的 undo log。\n涉及 MVCC，需要保存一定时间。当系统判断，没有比这个 undo log 更早的 read-view 的时候，undo log 会被删除。这是不建议使用长事务的一个原因，会导致大量回滚记录都必须保留，大量占用存储空间。\n  MVCC 数据库的多版本并发控制（MVCC），就是同一条记录在系统中可以存在多个版本。\nMVCC 只在读提交和可重复读两种隔离级别下工作，另两个隔离级别不兼容。\nMVCC 使得数据库读数据时不会被更新数据的写锁堵住，提高了数据库的并发处理能力。\n实现方式 InnoDB 里每个事务有一个唯一的事务 ID: transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，按申请顺序严格递增。\n每行数据也是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，数据版本中存储 undo log，并把 transaction id 赋值给这个数据版本的 row trx_id。同时，旧的数据版本保留，并且在新的数据版本中，能够有信息可以直接拿到它。\n也就是说，数据表中的一行记录，可能有多个版本 (row)，每个版本有自己的 row trx_id。\n每次需要之前版本的数据时，通过回滚 undo log 得到之前版本的值。\n数据版本可见性规则 InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前启动了但还没提交的所有事务 ID。\n 数组里面事务 ID 的最小值记为低水位 当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位  这个视图数组和高水位，组成了当前事务的一致性视图（read-view）。\n而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到。\n 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，是可见的。 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的。 如果落在黄色部分，包括两种情况：  若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见。 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。    数据更新 MVCC 只能解决数据更新时不影响读取，而如果要更新数据时，数据更新的逻辑则不能再使用 MVCC 版本控制，只能使用读锁进行阻塞。\n更新数据都是先读后写的，而这个读，只能读当前的值，称为当前读（current read）。\n除了 update 语句外，select 语句如果加锁，也是当前读。\n可能出现的问题 脏读 脏读 (Dirty Read) 是一个事务读到了另一个未提交事务修改过的数据。\n脏读只在读未提交隔离级别才会出现。\n不可重复读 不可重复读指在同一个事务中，同一条数据，查询到的数据内容不同。\n不可重复读在读未提交和读已提交两个级别中可能出现。\n幻读 幻读是指在同一个事务中，同样的查询语句执行多次，得到了不同的结果集。\n除了串行化隔离级别，其他隔离级别都有可能出现幻读问题。\nMySQL 主要使用 MVCC 和间隙锁两种方式解决幻读问题。\n  MVCC：\n由于 MVCC 机制，快照中的普通读取使用的是快照读，只能读取到快照，解决了普通读的幻读问题。\n  间隙锁：\n事务中的更新数据操作都是使用的当前读，如果其他事务在此期间插入了新数据，而读锁又锁不住加锁之后新插入的数据，就会出现幻读问题。查询行为如果加锁，也会变成当前读，也会出现幻读问题。\n间隙锁将读取行为扫描到的所有数据的间隙间和行上锁，使其他事务无法在这个范围内插入新数据，由此解决了幻读问题。\n ","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/mysql-%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","title":"MySQL 事务与隔离级别"},{"content":"MySQL 在今年初发布了正式的 8.0 版本，据说性能相比 5.7 提升了两倍。今天我们就来安装和配置一下MySQL8.0。\n安装环境为 Centos7。\nMySQL 的安装主要有两种方式，一种是使用 yum 命令在线安装，一种是下载源代码，离线安装。\n在线安装 添加仓库及安装 首先，我们需要将 MySQL 的仓库添加到你系统的仓库列表之中：\n  访问 MySQL仓库下载地址，选择你需要下载的 MySQL 版本，我们要安装的是 MySQL8.0，安装环境为Centos7，所以我们选择的是：mysql80-community-release-el7-1.noarch.rpm\n  在 Centos 中使用 wget 将仓库下载下来：\nwget https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm   然后将仓库添加到系统仓库列表\nsudo yum localinstall mysql80-community-release-el7-1.noarch.rpm 添加完成之后，就可以开始安装 MySQL 了。\n  安装 MySQL\nsudo yum install mysql-community-server   启用服务 安装完毕之后，我们需要开启 MySQL 的服务，才能正常使用:\nsudo systemctl start mysqld 开启之后，我们可以使用以下命令查看服务的状态：\nshell\u0026gt; sudo service mysqld status Redirecting to /bin/systemctl status mysqld.service ● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 二 2018-08-28 16:36:37 CST; 27min ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 997 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 1026 (mysqld) Status: \u0026#34;SERVER_OPERATING\u0026#34; CGroup: /system.slice/mysqld.service └─1026 /usr/sbin/mysqld 8月 28 16:36:34 localhost.localdomain systemd[1]: Starting MySQL Server... 8月 28 16:36:37 localhost.localdomain systemd[1]: Started MySQL Server. 设置密码 开启服务后，我们就可以连接 MySQL 了：\nmysql -u root -p 需要注意的是，在使用 yum 自动安装之后，MySQL 会自动给 root 账户设置一个随机密码，我们需要先获得这个随机密码，登陆后，再去修改 root 用户密码。\n使用以下命令可以查看随机密码：\nshell\u0026gt; sudo grep \u0026#39;temporary password\u0026#39; /var/log/mysqld.log 2018-08-28T08:17:04.632047Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: sbt1Y9o.s5k5 使用此密码登陆成功后，我们需要修改这个密码\nALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;MyNewPass4!\u0026#39;; 需要注意的是，MySQL8.0 设置的密码需要包含大小写字母，数字以及特殊字符，才能设置成功。\n编码问题 MySQL8.0 还有一点改进是，不再使用 latin 作为默认编码，转而使用 utf8mb4 作为默认编码。\n这样在使用时就不用再修改默认编码了\nmysql\u0026gt; show variables like \u0026#39;%char%\u0026#39;; +--------------------------------------+--------------------------------+ | Variable_name | Value | +--------------------------------------+--------------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql-8.0/charsets/ | | validate_password.special_char_count | 1 | +--------------------------------------+--------------------------------+ 9 rows in set (0.02 sec) 临时修改编码 利用以下命令可以修改编码格式：\nset character_set_database = utf8; set character_set_server = utf8; 但在命令行中修改的话，每次重启Mysql就会失效，所以我们需要把这两行语句写入到Mysql的配置文件中。\n修改配置文件 首先，我们可以通过 mysql --help 命令查看mysql读取配置文件的优先路径。一般会看到如下所示的内容：\n Default options are read from the following files in the given order: /etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf\n 所以我们就可以使用以下命令编辑或创建配置文件：\nvim /etc/my.cnf 在 [mysqld] 标签下加上以下内容：\n default-character-set = utf8 character_set_server = utf8\n 注意：如果此标签下已经存在 default-character-set=GBK 类似的内容，只需修改即可。\n在 [mysql] 标签下加上一行\n default-character-set = utf8\n 之后再次进入 MySql 用之前提到过的查看命令查看即可。\nsudo service mysql restart ","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/mysql-%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/","title":"MySQL 安装与配置"},{"content":"建表 语句 CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tb_name (create_definition,...) [table_options] [partition_options] 关键字：\n TEMPORARY - 可以使用此关键字创建临时表，临时表只在当前会话中可见，并且会在会话关闭时自动删除。 IF NOT EXISTS - 当表中不存在此表时，才执行 CREATE TABLE 语句，以免创建重名表引发异常。 create_definition - 在 tb_name 字段后方括号中的，是表中定义字段的语句，定义多条字段字段时用逗号分隔。 table_options - 用来优化表的选项。在大多数时候不需要指定。可以在这里指定表的引擎(engine)，如果没有指定的话则默认使用 InnoDB 引擎。 partition_optins - 可以用于创建表的分区。  定义字段 即上方建表语句中的 create_definition。\ncol_name data_type[size] [NOT NULL|NULL] [DEFAULT value] [AUTO_INCREMENT], 除了需要在这里指定字段的名字、数据类型和约束条件之外，还有一些选项可以在此指定：\n  COMMENT\n使用 COMMENT 可以为字段写入注释，最多 1024 个字符。如果要显示注释的话需要使用 SHOW CREATE TABLE 或者 SHOW FULL COLUMNS 语句。\n  UNSIGNED\n无符号，数值类型可以使用 UNSIGNED 来指定数据只表示正数，这样的话能使字段表示的最大范围翻倍。\n  ZEROFILL\n用 0 填充，当数值类型插入的数据长度比设定的最大长度小时，设定了 ZEROFILL 选项的字段将自动在数据的左端填充 0，将数据补充到设定的最大长度。\n  约束条件 所谓约束条件，指的是对于字段，除了数据类型和数据长度以外其他的规定，例如非空、自增长等。\n  NOT NULL\n非空，如果没有指定 NOT NULL 这个约束条件的话，那么插入一条数据的时候，这个字段是可以不插入值的，这个时候，MySQL 会自动将这个字段的值设置为 NULL。\n而如果设置了 NOT NULL 约束条件，那么在插入数据的时候，这个字段必须有值，否则会报错。\nname VARCHAR(20) NOT NULL;   AUTO_INCREMENT\n自增长，整数类型或浮点数类型，可以设置这个约束条件，每张表中只能设置一个 AUTO_INCREMENT 字段，且不能设置默认值 DEFAULT。AUTO_INCREMENT 字段必须为一个 KEY。\n当你在插入数据的时候，如果给这个字段插入 NULL 或者 0，甚至不插入值时，这个字段会自动找出这个字段中最大的值，并将这个值 +1 并填充到当前这条数据中。\nid INT(11) AUTO_INCREMENT,   DEFAULT\n指定默认值，如果插入数据时，这个字段没有插入值，那么将会使用默认值来填充此字段。\nname VARCHAR(20) DEFAULT \u0026#39;nobody\u0026#39;,   UNIQUE\n唯一值，当我们希望某一个字段的值都唯一的情况下，我们可以给这个字段指定 UNIQUE 约束条件。如果在插入一条新数据时，给一个 UNIQUE 字段插入一个已经存在的值，那么将会抛出一个异常。\n需要注意的是，UNIQUE 不会把 NULL 视为重复的值，也就是说，UNIQUE 字段中可以包含多个 NULL。\nid INT(11) UNIQUE, 如果需要在建表之后再设定某个字段为UNIQUE，可以用这种方式：\nALTER TABLE tb_name ADD UNIQUE KEY(number);   PRIMARY KEY\n主键，通常是用来作为一条数据的唯一标识，所以主键字段的值必须是唯一的，且这个字段必须设置为 NOT NULL，每一张表中也只能设置一个主键。\n当没有设置主键的时候，表中第一个出现的 NOT NULL 且 UNIQUE 字段，将会被视为主键。\nid INT(11) PRIMARY KEY, 当建表之后需要设置主键时：\nALTER TABLE tb_name ADD PRIMARY KEY (id); 主键还可以被撤销：\nALTER TABLE tb_name DROP PRIMARY KEY;   FOREIGN KEY\n外键，可以将表中的某一个字段与另一张表中的一个字段联系起来，从而为两张表建立联系。\nCONSTRAINT foreign_name FOREIGN KEY (Id_P) REFERENCES Persons(Id_P)   修改表结构 可以使用 ALTER TABLE 语句来更改现有表的结构。\n修改语句 ALTER TABLE 语句可用来添加列，删除列，更改列的数据类型，添加主键，重命名表等等。 以下是 ALTER TABLE 语句语法：\nALTER TABLE tb_name [alter_specification [, alter_specification] ...] [partition_options] 需要注意的是多条修改语句间需要使用,分割。\n例子   重命名表\nALTER TABLE tb_name RENAME new_name;   添加字段\nALTER TABLE tb_name ADD col_name TIMESTAMP; 如果需要指定添加字段的位置，那么可以在后面跟上一个 AFTER 子句，添加到某个字段下方。\nALTER TABLE tb_name ADD col_name TIMESTAMP AFTER col_name2; 使用 AFTER 能添加到除了第一行之外的所有位置，那么想添加到第一行的话，需要使用 FIRST。\nALTER TABLE tb_name ADD col_name TIMESTAMP FIRST;   删除字段\nALTER TABLE tb_name DROP COLUMN col_name;   重命名并修改字段\nALTER TABLE tb_name CHANGE old_col_name new_col_name data_type;   修改字段\nALTER TABLE tb_name MODIFY col_name data_type;  ","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/mysql-%E5%BB%BA%E8%A1%A8%E4%B8%8E%E4%BF%AE%E6%94%B9/","title":"MySQL 建表与修改"},{"content":"MySQL 数据库与 Oracle、 SQL Server 等数据库相比，有其内核上的优势与劣势。我们在使用 MySQL 数据库的时候需要遵循一定规范，扬长避短。\n本规范旨在帮助或指导 RD、QA、OP 等技术人员做出适合线上业务的数据库设计。在数据库变更和处理流程、数据库表设计、SQL 编写等方面予以规范，从而为公司业务系统稳定、健康地运行提供保障。\n设计规范 数据库设计 以下所有规范会按照【高危】、【强制】、【建议】三个级别进行标注，遵守优先级从高到低。\n对于不满足【高危】和【强制】两个级别的设计，DBA会强制打回要求修改。\n库名  【强制】库的名称必须控制在32个字符以内，相关模块的表名与表名之间尽量体现join的关系，如user表和user_login表。 【强制】库的名称格式：业务系统名称_子系统名，同一模块使用的表名尽量使用统一前缀。 【强制】一般分库名称命名格式是库通配名_编号，编号从0开始递增，比如wenda_001以时间进行分库的名称格式是“库通配名_时间” 【强制】创建数据库时必须显式指定字符集，并且字符集只能是utf8或者utf8mb4。创建数据库SQL举例：create database db1 default character set utf8;。  表结构  【强制】表和列的名称必须控制在32个字符以内，表名只能使用字母、数字和下划线，一律小写。 【强制】表名要求模块名强相关，如师资系统采用”sz”作为前缀，渠道系统采用”qd”作为前缀等。 【强制】创建表时必须显式指定字符集为utf8或utf8mb4。 【强制】创建表时必须显式指定表存储引擎类型，如无特殊需求，一律为InnoDB。当需要使用除InnoDB/MyISAM/Memory以外的存储引擎时，必须通过DBA审核才能在生产环境中使用。因为Innodb表支持事务、行锁、宕机恢复、MVCC等关系型数据库重要特性，为业界使用最多的MySQL存储引擎。而这是其他大多数存储引擎不具备的，因此首推InnoDB。 【强制】建表必须有comment 【强制】中间表用于保留中间结果集，名称必须以tmp_开头。备份表用于备份或抓取源表快照，名称必须以bak_开头。中间表和备份表定期清理。 【强制】对于超过100W行的大表进行alter table，必须经过DBA审核，并在业务低峰期执行。因为alter table会产生表锁，期间阻塞对于该表的所有写入，对于业务可能会产生极大影响。 【建议】建表时关于主键：(1)强制要求主键为id，类型为int或bigint，且为auto_increment(2)标识表里每一行主体的字段不要设为主键，建议设为其他字段如user_id，order_id等，并建立unique key索引（可参考cdb.teacher表设计）。因为如果设为主键且主键值为随机插入，则会导致innodb内部page分裂和大量随机I/O，性能下降。 【建议】核心表（如用户表，金钱相关的表）必须有行数据的创建时间字段create_time和最后更新时间字段update_time，便于查问题。 【建议】表中所有字段必须都是NOT NULL属性，业务可以根据需要定义DEFAULT值。因为使用NULL值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问题。 【建议】建议对表里的blob、text等大字段，垂直拆分到其他表里，仅在需要读这些对象的时候才去select。 【建议】反范式设计：把经常需要join查询的字段，在其他表里冗余一份。如user_name属性在user_account，user_login_log等表里冗余一份，减少join查询。  列数据类型优化  【建议】表中的自增列（auto_increment属性），推荐使用bigint类型。因为无符号int存储范围为-2147483648~2147483647（大约21亿左右），溢出后会导致报错。 【建议】业务中选择性很少的状态status、类型type等字段推荐使用tinytint或者smallint类型节省存储空间。 【建议】业务中IP地址字段推荐使用int类型，不推荐用char(15)。因为int只占4字节，可以用如下函数相互转换，而char(15)占用至少15字节。一旦表数据行数到了1亿，那么要多用1.1G存储空间。 SQL：select inet_aton('192.168.2.12'); select inet_ntoa(3232236044); PHP: ip2long(‘192.168.2.12’); long2ip(3530427185); 【建议】不推荐使用enum，set。 因为它们浪费空间，且枚举值写死了，变更不方便。推荐使用tinyint或smallint。 【建议】不推荐使用blob，text等类型。它们都比较浪费硬盘和内存空间。在加载表数据时，会读取大字段到内存里从而浪费内存空间，影响系统性能。建议和PM、RD沟通，是否真的需要这么大字段。Innodb中当一行记录超过8098字节时，会将该记录中选取最长的一个字段将其768字节放在原始page里，该字段余下内容放在overflow-page里。不幸的是在compact行格式下，原始page和overflow-page都会加载。 【建议】存储金钱的字段，建议用int，程序端乘以100和除以100进行存取。因为int占用4字节，而double占用8字节，空间浪费。 【建议】文本数据尽量用varchar存储。因为varchar是变长存储，比char更省空间。MySQL server层规定一行所有文本最多存65535字节，因此在utf8字符集下最多存21844个字符，超过会自动转换为mediumtext字段。而text在utf8字符集下最多存21844个字符，mediumtext最多存 2^24^/3 个字符，longtext最多存 2^32^ 个字符。一般建议用varchar类型，字符数不要超过2700。 【建议】时间类型尽量选取timestamp。因为datetime占用8字节，timestamp仅占用4字节，但是范围为1970-01-01 00:00:01到2038-01-01 00:00:00。更为高阶的方法，选用int来存储时间，使用SQL函数unix_timestamp()和from_unixtime()来进行转换。  索引设计  【强制】InnoDB表必须主键为id int/bigint auto_increment,且主键值禁止被更新。 【强制】InnoDB和MyISAM存储引擎表，索引类型必须为BTREE；MEMORY表可以根据需要选择HASH或者BTREE类型索引。 【强制】单个索引中每个索引记录的长度不能超过64KB。 【建议】主键的名称以“pk_”开头，唯一键以“uk_”或“uq_”开头，普通索引以“idx_”开头，一律使用小写格式，以表名/字段的名称或缩写作为后缀。 【建议】单个表上的索引个数不能超过7个。 【建议】在建立索引时，多考虑建立联合索引，并把区分度最高的字段放在最前面。如列userid的区分度可由select count(distinct userid)计算出来。 【建议】在多表join的SQL里，保证被驱动表的连接列上有索引，这样join执行效率最高。 【建议】建表或加索引时，保证表里互相不存在冗余索引。对于MySQL来说，如果表里已经存在key(a,b)，则key(a)为冗余索引，需要删除。  分库分表、分区表  【强制】分区表的分区字段（partition-key）必须有索引，或者是组合索引的首列。 【强制】单个分区表中的分区（包括子分区）个数不能超过1024。 【强制】上线前RD或者DBA必须指定分区表的创建、清理策略。 【强制】访问分区表的SQL必须包含分区键。 【强制】对于分区表执行alter table操作，必须在业务低峰期执行。 【强制】采用分库策略的，库的数量不能超过1024 【强制】采用分表策略的，表的数量不能超过4096 【建议】单个分区文件不超过2G，总大小不超过50G。建议总分区数不超过20个。 【建议】单个分表不超过500W行，ibd文件大小不超过2G，这样才能让数据分布式变得性能更佳。 【建议】水平分表尽量用取模方式，日志、报表类数据建议采用日期进行分表。  字符集  【强制】数据库本身库、表、列所有字符集必须保持一致，为utf8或utf8mb4。 【强制】前端程序字符集或者环境变量中的字符集，与数据库、表的字符集必须一致，统一为utf8。  程序层 DAO 设计建议  【建议】新的代码不要用model，推荐使用手动拼SQL+绑定变量传入参数的方式。因为model虽然可以使用面向对象的方式操作db，但是其使用不当很容易造成生成的SQL非常复杂，且model层自己做的强制类型转换性能较差，最终导致数据库性能下降。 【建议】前端程序连接MySQL或者redis，必须要有连接超时和失败重连机制，且失败重试必须有间隔时间。 【建议】前端程序报错里尽量能够提示MySQL或redis原生态的报错信息，便于排查错误。 【建议】对于有连接池的前端程序，必须根据业务需要配置初始、最小、最大连接数，超时时间以及连接回收机制，否则会耗尽数据库连接资源，造成线上事故。 【建议】对于log或history类型的表，随时间增长容易越来越大，因此上线前RD或者DBA必须建立表数据清理或归档方案。 【建议】在应用程序设计阶段，RD必须考虑并规避数据库中主从延迟对于业务的影响。尽量避免从库短时延迟（20秒以内）对业务造成影响，建议强制一致性的读开启事务走主库，或更新后过一段时间再去读从库。 【建议】多个并发业务逻辑访问同一块数据（innodb表）时，会在数据库端产生行锁甚至表锁导致并发下降，因此建议更新类SQL尽量基于主键去更新。 【建议】业务逻辑之间加锁顺序尽量保持一致，否则会导致死锁。 【建议】对于单表读写比大于10:1的数据行或单个列，可以将热点数据放在缓存里（如mecache或redis），加快访问速度，降低MySQL压力。  一个规范的建表语句示例 一个较为规范的建表语句为：\nCREATE TABLE user ( `id` bigint(11) NOT NULL AUTO_INCREMENT, `user_id` bigint(11) NOT NULL COMMENT ‘用户id’ `username` varchar(45) NOT NULL COMMENT \u0026#39;真实姓名\u0026#39;, `email` varchar(30) NOT NULL COMMENT ‘用户邮箱’, `nickname` varchar(45) NOT NULL COMMENT \u0026#39;昵称\u0026#39;, `avatar` int(11) NOT NULL COMMENT \u0026#39;头像\u0026#39;, `birthday` date NOT NULL COMMENT \u0026#39;生日\u0026#39;, `sex` tinyint(4) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;性别\u0026#39;, `short_introduce` varchar(150) DEFAULT NULL COMMENT \u0026#39;一句话介绍自己，最多50个汉字\u0026#39;, `user_resume` varchar(300) NOT NULL COMMENT \u0026#39;用户提交的简历存放地址\u0026#39;, `user_register_ip` int NOT NULL COMMENT ‘用户注册时的源ip’, `create_time` timestamp NOT NULL COMMENT ‘用户记录创建的时间’, `update_time` timestamp NOT NULL COMMENT ‘用户资料修改的时间’, `user_review_status` tinyint NOT NULL COMMENT ‘用户资料审核状态，1为通过，2为审核中，3为未通过，4为还未提交审核’, PRIMARY KEY (`id`), UNIQUE KEY `idx_user_id` (`user_id`), KEY `idx_username`(`username`), KEY `idx_create_time`(`create_time`,`user_review_status`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=\u0026#39;网站用户基本信息\u0026#39;; SQL DML 语句  【强制】SELECT语句必须指定具体字段名称，禁止写成*。因为select *会将不该读的数据也从MySQL里读出来，造成网卡压力。且表字段一旦更新，但model层没有来得及更新的话，系统会报错。 【强制】insert语句指定具体字段名称，不要写成insert into t1 values(…)，道理同上。 【强制】事务涉及的表必须全部是innodb表。否则一旦失败不会全部回滚，且易造成主从库同步终端。 【强制】写入和事务发往主库，只读SQL发往从库。 【强制】除静态表或小表（100行以内），DML语句必须有where条件，且使用索引查找。 【强制】生产环境禁止使用hint，如sql_no_cache，force index，ignore key，straight join等。因为hint是用来强制SQL按照某个执行计划来执行，但随着数据量变化我们无法保证自己当初的预判是正确的，因此我们要相信MySQL优化器！ 【强制】where条件里等号左右字段类型必须一致，否则无法利用索引。 【强制】生产数据库中强烈不推荐大表上发生全表扫描，但对于100行以下的静态表可以全表扫描。查询数据量不要超过表行数的25%，否则不会利用索引。 【强制】WHERE 子句中禁止只使用全模糊的LIKE条件进行查找，必须有其他等值或范围查询条件，否则无法利用索引。 【建议】insert into…values(XX),(XX),(XX)…。这里XX的值不要超过5000个。值过多虽然上线很很快，但会引起主从同步延迟。 【建议】SELECT语句不要使用UNION，推荐使用UNION ALL，并且UNION子句个数限制在5个以内。因为union all不需要去重，节省数据库资源，提高性能。 【建议】in值列表限制在500以内。例如select… where userid in(….500个以内…)，这么做是为了减少底层扫描，减轻数据库压力从而加速查询。 【建议】事务里批量更新数据需要控制数量，进行必要的sleep，做到少量多次。 【建议】SELECT|UPDATE|DELETE|REPLACE要有WHERE子句，且WHERE子句的条件必需使用索引查找。 【建议】索引列不要使用函数或表达式，否则无法利用索引。如where length(name)='Admin'或where user_id+2=10023。 【建议】减少使用or语句，可将or语句优化为union，然后在各个where条件上建立索引。如where a=1 or b=2优化为where a=1… union …where b=2, key(a),key(b)。 【建议】分页查询，当limit起点较高时，可先用过滤条件进行过滤。如select a,b,c from t1 limit 10000,20;优化为: select a,b,c from t1 where id\u0026gt;10000 limit 20;。  多表连接  【强制】禁止跨db的join语句。因为这样可以减少模块间耦合，为数据库拆分奠定坚实基础。 【强制】禁止在业务的更新类SQL语句中使用join，比如update t1 join t2…。 【建议】不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用join来代替子查询。 【建议】线上环境，多表join不要超过3个表。 【建议】多表连接查询推荐使用别名，且SELECT列表中要用别名引用字段，数据库.表格式，如select a from db1.table1 alias1 where …。 【建议】在多表join中，尽量选取结果集较小的表作为驱动表，来join其他表。  事务  【强制】程序设计必须考虑“数据库事务隔离级别”带来的影响，包括脏读、不可重复读和幻读。线上建议事务隔离级别为repeatable-read。 【建议】事务中INSERT|UPDATE|DELETE|REPLACE语句操作的行数控制在2000以内，以及WHERE子句中IN列表的传参个数控制在500以内。 【建议】批量操作数据时，需要控制事务处理间隔时间，进行必要的sleep，一般建议值5-10秒。 【建议】对于有auto_increment属性字段的表的插入操作，并发需要控制在200以内。 【建议】事务里包含SQL不超过5个（支付业务除外）。因为过长的事务会导致锁数据较久，MySQL内部缓存、连接消耗过多等雪崩问题。 【建议】事务里更新语句尽量基于主键或unique key，如update … where id=XX; 否则会产生间隙锁，内部扩大锁定范围，导致系统性能下降，产生死锁。 【建议】尽量把一些典型外部调用移出事务，如调用webservice，访问文件存储等，从而避免事务过长。 【建议】对于MySQL主从延迟严格敏感的select语句，请开启事务强制访问主库。  排序和分组  【建议】减少使用order by，和业务沟通能不排序就不排序，或将排序放到程序端去做。order by、group by、distinct这些语句较为耗费CPU，数据库的CPU资源是极其宝贵的。 【建议】order by、group by、distinct这些SQL尽量利用索引直接检索出排序好的数据。如where a=1 order by可以利用key(a,b)。 【建议】包含了order by、group by、distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。  线上禁止使用的 SQL 语句  【高危】禁用update|delete t1 … where a=XX limit XX; 这种带limit的更新语句。因为会导致主从不一致，导致数据错乱。建议加上order by PK。 【高危】禁止使用关联子查询，如update t1 set … where name in(select name from user where…);效率极其低下。 【强制】禁用procedure、function、trigger、views、event、外键约束。因为他们消耗数据库资源，降低数据库实例可扩展性。推荐都在程序端实现。 【强制】禁用insert into …on duplicate key update…在高并发环境下，会造成主从不一致。 【强制】禁止联表更新语句，如update t1,t2 where t1.id=t2.id…。 ","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/mysql-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/","title":"MySQL 数据库设计规范"},{"content":"索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。\n索引模型 优点：\n 能大大的加快数据库中查询的速度。  缺点：\n 索引会占用额外的存储空间，如果创建索引过多，占用空间会很大。 在对建立了索引的表中写入数据时，索引需要动态的维护。也就是说，会影响写入数据的效率。  注意事项：\n 避免给经常更新的表建立太多索引，以免影响太多写入效率。 建立索引的字段，越短越好，数值类型越简单越好。 尽量避免字段中出现 NULL，因为 NULL 值的查询是不走索引的，含空值的列是很难做查询优化的。所以要在建立字段时加上 NOT NULL 的约束条件，空值用 0 或者空字符代替。 索引不要盲目建立，一般只需要给在 WHERE 和 JOIN 字句中需要出现的字段建立索引即可。 建立索引后，查询的时候不要进行运算，因为运算的话会变成全表查询。只有这些运算符：\u0026lt;，\u0026lt;=，=，\u0026gt;，\u0026gt;=，BETWEEN，IN，以及某些时候的LIKE会被索引支持。  索引类型\n索引是在存储引擎中实现的，不同的存储引擎有不同的索引方式。常用的 InnoDB 和 MyISAM 引擎都只能使用 B-tree 索引。\n根据索引的使用方式，分为单列索引、组合索引、全文索引和空间索引，这其中单例索引又分为普通索引、唯一索引和主键索引。\n常见索引模型 常见的三种索引模型分别是哈希表、有序数组和搜索树。\n 哈希表：由于哈希表存储数据是无序的，所以适用于等值查询，不适用于范围查询，效率很低。 有序数组：由于是有序的，等值查询可以用二分法，所以等值查询和范围查询都适合。但更新数据效率很低。 搜索树：根据搜索需求逐渐演变，从二叉树到 N 叉树。N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。  单列索引 在 InnoDB 中，表根据主键顺序以索引的形式存放，这种存储方式的表称为索引组织表。同时，InnoDB 使用了 B+ 树索引模型，所以数据都存储在 B+ 树中。\n每一个索引在 InnoDB 里面对应一棵 B+ 树。\n普通索引 以下是创建普通索引三种的方式：\nCREATE INDEX indexName ON tbname(colname(length)); ALTER table tableName ADD INDEX indexName(colname); CREATE TABLE tbname( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (colname(length)) ); 创建索引时，如果字段是 CHAR，VARCHAR 类型，length 可以小于字段实际长度。如果是BLOB和TEXT类型，必须指定 length。\n同时，索引的名字也是可选的，如果没有指定名字的话，那么 MySQL 会默认用字段名作为索引的名字。\n索引建好之后，可以使用以下命令查看：\nSHOW INDEX FROM table_name; 同样也可以使用以下命令删除普通索引：\nDROP INDEX [indexName] ON table_name; 唯一索引 在 MySQL 之中，有一个比较特殊的地方就是，KEY 和 INDEX 常常被混淆在一起，虽然说本质上 KEY 和 INDEX 不是同一个东西，但是究其原因，MySQL 中的约束效果是通过索引来实现的，MySQL数据库判断是否当前列是否 unique 就是通过 unique 索引判断的。\n因为这个原因，所以其实我们的 UNIQUE KEY 约束条件其实也就建立了索引，两者被完全绑定到了一起。\n以下是建立唯一索引的方式：\nCREATE UNIQUE INDEX indexName ON tablename(colname(length)); ALTER TABLE table_name ADD UNIQUE indexName ON (colname(length)); CREATE TABLE table ( id int NOT NULL AUTO_INCREMENT, name varchar(20) NOT NULL, UNIQUE [indexName] (colname(length)) ); 唯一索引的删除方式与普通索引是一致的。\n主键索引 主键索引也是类似，与主键这个约束条件基本是相同的，创建的方式与主键通用，就不一一赘述了。\n这里主要讲一讲 InnoDB 引擎上主键的选择。在没有特殊需求的情况下，主键都应该使用无关业务逻辑的自增字段。\n有人会觉得，使用身份证之类的数据来作为主键也是可以的，但是在算法层面上，如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。这样会形成一个紧凑的索引结构，提高效率。\n而如果使用的是身份证号这种非自增数据的话，那么数据的值就是类似随机的数据，就达不到这个效果了。\n主键索引和普通索引   主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n  非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n  基于主键索引和普通索引的查询区别：\n 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树。 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。  也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，在应用中应该尽量使用主键查询。\n为什么要使用自增主键：\n  每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。\n而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n  主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。\n  组合索引 组合索引其实就是用多个字段做一个索引，在查询时如果有多个字段做为索引条件的话，那么组合索引的效率会大大高于每个字段做一个单列索引。\n因为 MySQL 的查询每次只能使用一个索引，所以多个单列索引只会用到一个索引，其他字段的查询就会变成全文搜索。\n建立组合索引的方式：\nCREATE INDEX indexname On tbName(colname(length),colname(length),...); ALTER TABLE tbname ADD INDEX indexname (colname(length),colname(length),...); 覆盖索引 如果查询的值已经在索引树上了，则可以直接提供查询结果，不需要回表，可以减少数的搜索次数。这种情况被称为覆盖索引，是一种常用的性能优化手段。\n而通过联合索引，可以将需要查询的值放到索引上，用于加速查询效率。\n例如，如果要根据市民的身份证号查询他的姓名，那么可以建立一个（身份证号、姓名）的联合索引。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。\n最左前缀 B+ 树中，索引项是按照索引定义里面出现的字段顺序排序的。由于 B+ 树这种索引结构，可以利用索引的最左前缀，来定位记录。\n这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。只要满足最左前缀，就可以利用索引来加速检索。\n如何安排联合索引字段顺序？\n评估标准是，索引的复用能力。\n因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n索引下推 在搜索时，如果满足最左前缀原则，则可以直接在索引上定位记录。\n在 MySQL 5.6 之前，如果有不满足最左前缀原则的搜索条件，只能先根据最左前缀索引找出所有匹配的记录，然后逐条数据开始一个个回表。到主键索引上找出数据行，再对比字段值。\n而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再开始回表查询，减少了回表次数。\n","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/mysql-%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3/","title":"MySQL 索引详解"},{"content":"MySQL 常用类型简单介绍如下：\n整数类型：BIT、BOOL、TINY INT、SMALL INT、MEDIUM INT、 INT、 BIG INT\n浮点数类型：FLOAT、DOUBLE、DECIMAL\n字符串类型：CHAR、VARCHAR、TINY TEXT、TEXT、MEDIUM TEXT、LONGTEXT、TINY BLOB、BLOB、MEDIUM BLOB、LONG BLOB\n日期类型：Date、DateTime、TimeStamp、Time、Year\n其他数据类型：BINARY、VARBINARY、ENUM、SET\u0026hellip;\n运算符 MySQL中主要有四种运算符，分别是：\n 算术运算符 比较运算符 逻辑运算符 位运算符  算术运算符    算术运算符 + - * / %     作用 加 减 乘 除 取余    逻辑运算符    逻辑运算符 \u0026amp;\u0026amp;或AND !或NOT ||或OR XOR     作用 与 非 或 异或    位运算符    位运算符 \u0026amp; | ~ ^ \u0026lt;\u0026lt; \u0026gt;\u0026gt;     作用 按位与 按位或 按位取反 按位异或 按位左移 按位右移    比较运算符    比较运算符 作用 示例     = 等于 Id=5   \u0026gt; 大于 Id\u0026gt;5   \u0026lt; 小于 Id\u0026lt;5   \u0026gt;= 大于等于 Id\u0026gt;=5   \u0026lt;= 小于等于 Id\u0026lt;=5   !=或\u0026lt;\u0026gt; 不等于 Id!=5   IS NULL 为NULL Id IS NULL   IS NOT NULL 不为NULL Id IS NOT NULL   BETWEEN AND 在\u0026hellip;范围之间 Id BETWEEN 10 AND 15   IN 在\u0026hellip;列表中 Id IN (3,4,5)   NOT IN 不在\u0026hellip;列表中 Id NOT IN (3,4,5)   LIKE 模式匹配 Name LIKE \u0026lsquo;brow_\u0026rsquo;   NOT LIKE 模式匹配 Name NOT LIKE \u0026lsquo;brow_\u0026rsquo;   REGEXP 正则表达式匹配 Name REGEXP \u0026lsquo;^bro\u0026rsquo;    数据类型 MySQL 主要提供了大致三大类数据类型：数值类型，字符类型和日期类型。\nCHAR 和 VARCHAR 字符类型。\n   类型 最大长度 占用空间     CHAR(M) 0-255 字节 数据实际长度   VARCHAR(M) 0-65535 字节 数据长度+1或+2    注1：M 表示的是字符数，而最大长度的单位是字节。\n注2：当插入的数据长度超出 M 的范围时，超出部分会被裁剪，严格模式下如果超出长度，则会发生异常。\n区别：\n CHAR 存储的长度指定后为固定值，占用存储空间也会固定。在存储的值没有达到指定值时，会在字符串右方补齐空格，而在检索的时候，右方补齐的空格会被删掉。 VARCHAR 存储的字符长度是可变的，存储的空间大小也相对应是可变的。当字符长度在 0-255 范围时，VARCHAR 会使用一个字节来记录字符的长度，当长度超过 255 时，VARCHAR 会使用两个字节来记录字符的长度。  VARCHAR 大于某些数值的时候，其会自动转换为 text，大概规则如下：\n 大于 varchar(255) 变为 TINYTEXT 大于 varchar(500) 变为 TEXT 大于 varchar(20000) 变为 MEDIUMTEXT  Char 和 Varchar 区别 CHAR 是固定长度的字符类型，VARCHAR 则是可变长度的字符类型。\n共同点\nCHAR(M) 和 VARCHAR(M) 都表示该列能存储 M 个字符。\nCHAR类型特点\n CHAR 最多可以存储 255 个字符 (注意不是字节)，字符有不同的编码集，比如 UTF8 编码 (3字节)、GBK 编码 (2字节) 等。 对于 CHAR(M) 如果实际存储的数据长度小于M，则 MySQL 会自动会在它的右边用空格字符补足，但是在检索操作中那些填补出来的空格字符会被去掉。  VARCHAR类型特点\n VARCHAR 的最大长度为 65535 个字节。 VARCHAR 存储的是实际的字符串加1或2个字节用来记录字符串实际长度，字符串长度小于255字节用1字节记录，超过255就需要2字节记录。  BLOB 和 TEXT BLOB 表示的是二进制字符串(byte strings)。\nTEXT 表示的则是非二进制字符串，也就是普通的字符串。\nBLOB 和 TEXT 都分别有四个类型，类型间的区别只是长度的区别。L 表示插入的字符串实际占用的字节大小。\n   数据类型 占用存储空间     TINYBLOB，TINYTEXT 当L \u0026lt; 2的8次方，需要L + 1字节   BLOB，TEXT 当L \u0026lt; 2的16次方，需要L + 2字节   MEDIUMBLOB，MEDIUMTEXT 当L \u0026lt; 2的24次方，需要L + 3字节   LONGBLOB，LONGTEXT 当L \u0026lt; 2的32次方，需要L + 4字节    大多数情况下，TEXT 和 VARCHAR 基本可以等同，它们的区别主要有两个方面：\n BLOB 和 TEXT 不能设置默认值。 对 BLOB 和 TEXT 的索引，必须指定索引长度。  ENUM 枚举类型，声明枚举类型的字段可以指定一个由字符串组成的列表，则之后插入的值只能在指定的字符串中选择。\n整形    类型 存储大小(字节) 有符号最小值 无符号最小值 无符号最大值 无符号最大值     TINYINT 1 -128 0 127 255   SMALLINT 2 -32768 0 32767 65535   MEDIUMINT 3 -8388608 0 8388607 16777215   INT 4 -2147483648 0 2147483647 4294967295   BIGINT 8 -2的63次方 0 2的63次方-1 2的64次方-1    int(10) 和 bigint(10)能存储的数据大小一样吗？ 不一样，具体原因如下：\n int 能存储四字节有符号整数。 bigint 能存储八字节有符号整数。  所以能存储的数据大小不一样，其中的数字 10 代表的只是数据的显示宽度。[^13]\n 显示宽度指明Mysql最大可能显示的数字个数，数值的位数小于指定的宽度时数字左边会用空格填充，空格不容易看出。 如果插入了大于显示宽度的值，只要该值不超过该类型的取值范围，数值依然可以插入且能够显示出来。 建表的时候指定 zerofill 选项，则不足显示宽度的部分用 0 填充，如果是 1 会显示成 0000000001。 如果没指定显示宽度， bigint 默认宽度是 20 ，int默认宽度 11。  浮点型 浮点型数值类型主要两种，FlOAT 和 DOUBLE 类型，分别表示单精度和双精度数值。\nFLOAT 类型可以表示精度在 0-23 范围内的单精度数值，存储时占四个字节大小。\nDOUBLE 类型可以表示精度在 24-53 范围内的双精度数值，存储时占八个字节大小。\n浮点型数据可以使用一种非标准的语法来指定数据的精度，例如 FLOAT(M,D)，DOUBLE(M,D)。在这里 M 值指的是整个数字的最大位数，N 值指的是小数部分的最大位数，如 FLOAT(7,4) 能表示的最大数值是 999.9999。同时，MySQL 采用四舍五入，如果把 999.00009 插入到 FLOAT(7,4) 中，那么最终保存的结果是 999.0001。\n定点型 由于有一些应用场景需要精确的数字，所以就有了 DECIMAL 类型，主要用来表示精确小数。\nDECIMAL 同样能使用跟浮点数一样的语法来指定数据的精度，如 DECIMAL(M,D)。需要注意的是 DECIMAL 最大能表示的位数为 65，但是 DECIMAL 默认的限制位数为 DECIMAL(10,0)，所以如果要表示更大的位数，需要自行指定。\n日期类型    数据类型 描述 范围     DATE() 日期。格式：YYYY-MM-DD 从 \u0026lsquo;1000-01-01\u0026rsquo; 到 \u0026lsquo;9999-12-31\u0026rsquo;   DATETIME() 日期和时间的组合。格式：YYYY-MM-DD HH:MM:SS 从 \u0026lsquo;1000-01-01 00:00:00\u0026rsquo; 到 \u0026lsquo;9999-12-31 23:59:59\u0026rsquo;   TIMESTAMP() 时间戳。TIMESTAMP 值使用 Unix 纪元(\u0026lsquo;1970-01-01 00:00:00\u0026rsquo; UTC) 至今的秒数来存储。格式：YYYY-MM-DD HH:MM:SS 从 \u0026lsquo;1970-01-01 00:00:01\u0026rsquo; UTC 到 \u0026lsquo;2038-01-09 03:14:07\u0026rsquo; UTC   TIME() 时间。格式：HH:MM:SS 从 \u0026lsquo;-838:59:59\u0026rsquo; 到 \u0026lsquo;838:59:59\u0026rsquo;   YEAR() 2 位或 4 位格式的年。 4 位格式所允许的值：1901 到 2155。2 位格式所允许的值：70 到 69，表示从 1970 到 2069。   ","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/mysql-%E8%BF%90%E7%AE%97%E7%AC%A6%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"MySQL 运算符与数据类型"},{"content":"单机安装 准备   安装依赖包\n  Centos\nyum install -y gcc readline readline-devel openssl openssl-devel zlib zlib-devel   Ubuntu\nsudo apt-get install gcc make libreadline-dev openssl zlib1g-dev     创建特定的数据库用户\ngroupadd -g 60000 postgres useradd -u 60000 -g postgres postgres passwd postgres   创建所需要的数据库相关目录，并对用户授权\nmkdir -p /postgres/{pgdata,pg12,archive} chown -R postgres:postgres /postgres chmod -R 750 /postgres   下载 https://www.postgresql.org/download/ 源文件。\n  解压源文件\ntar -xjf postgresql-12.4.tar.bz2   安装   进入源文件解压后目录，配置安装位置\n./configure --prefix=/postgres/pg12   编译并安装\nmake \u0026amp;\u0026amp; make install   环境变量 在 .bash_profile 等启动文件中配置以下环境变量：\nexport PGHOME=/postgres/pg12 export PATH=$PGHOME/bin:$PATH export PGDATA=/postgres/pgdata 初始化数据库集簇 初始化之前需要切换到 postgres 用户\n/postgres/pg12/bin/initdb -D /postgres/pgdata -U postgres 基础配置 连接权限 此配置文件位于 $PGDATA/pg_hba.conf，用于控制数据库连接权限。配置格式：\n# TYPE DATABASE USER ADDRESS METHOD host test pgtest 10.10.56.17/32 md5 5个字段的意思分别是：\n TYPE - 访问类型。值：  local - 本机连接 host - 通过 TCP/IP 连接 hostssl - SSL 的 TCP/IP 连接   DATABASE - 数据库名称。值：  all - 所有数据库，不包括 replication sameuser - 只能连接到与 user 相同的数据库 replication - 物理复制连接 具体数据库名称   USER - 用户  all - 所有账户 具体用户名称   ADDRESS - 访问来源地址  0.0.0.0/0 - 所有 ipv4 地址   METHOD - 请求方法  trust - 表示信任，不需要密码即可访问 reject - 拒绝连接 password - 密码访问 md5 - 通过 md5 加密密码    数据库密码 \\password postgres 开启日志 postgres 的日志记录默认是关闭的，需要在 postgresql.conf 配置里手动开启，默认路径为 $PGDATA/pg_log/。\nlogging_collector = on # 开启日志 log_directory = 'pg_log' # 日志文件路径 log_filename = 'postgresql-%a.log' log_truncate_on_rotation = on 时区   查看当前数据库时间\nselect now();   查看当前数据库时区\nshow time zone;   查看数据库可供选择的时区\nselect * from pg_timezone_names;   修改数据库时区，在 postgresql.conf 中找到 time_zone 字段，更改为指定的时区名即可\ntime_zone = Asia/Shanghai   高级设置 开机自启动 使用 systemctl 服务实现开机自启动。\n在 /etc/systemd/system/ 文件夹下，创建一个 .server 文件，文件内容如下，主要分为[unit]，[service]，[install] 三个小节。\n[Unit] Description=postgresql project # 描述 After=pgserver.service # 在此服务启动后才启动，这里可以不写 [Service] Type=forking User=ppas Group=ppas ExecStart=/opt/PostgresPlus/9.5AS/bin/pg_ctl start -D /opt/PostgresPlus/9.5AS/data # 启动命令 ExecReload=/opt/PostgresPlus/9.5AS/bin/pg_ctl restart -D /opt/PostgresPlus/9.5AS/data # 重新加载 ExecStop=/opt/PostgresPlus/9.5AS/bin/pg_ctl stop -D /opt/PostgresPlus/9.5AS/data # 停止，以上三命令都需要绝对路径 PrivateTmp=true # 是否给服务分配独立的临时空间（true/false） [Install] WantedBy=multi-user.target  Type - 服务的类型，常用的有 simple（默认类型） 和 forking。默认的 simple 类型可以适应于绝大多数的场景，因此一般可以忽略这个参数的配置。而如果服务程序启动后会通过 fork 系统调用创建子进程，然后关闭应用程序本身进程的情况，则应该将 Type 的值设置为 forking，否则 systemd 将不会跟踪子进程的行为，而认为服务已经退出。 postgres 需要通过 fork 来创建一些子进程，所以这里选择 forKing。 WantedBy - 依赖当前服务的模块。WantedBy=multi-user.target 表明当系统以多用户方式（默认的运行级别）启动时，这个服务需要被自动运行。当然还需要 systemctl enable 激活这个服务以后自动运行才会生效  主从复制   主库配置 postgresql.conf\n# 选择物理复制模式 wal_level = replica # 开启归档 archive_mode = on # 归档命令 archive_command = 'test ! -f /postgres/archive/%f \u0026amp;\u0026amp; cp %p /postgres/archive/%f' max_wal_senders = 10 wal_keep_segments = 256 # 归档超时时间 wal_sender_timeout = 60s 切换归档\nselect pg_switch_wal();   主库创建流复制角色\ncreate role repuser login encrypted password \u0026#39;password\u0026#39; replication;   主库打开流复制权限\nhost replication repuser 0.0.0.0/0 md5   切换到从库，使用命令拷贝主库数据库\npg_basebackup -D /postgres/pgdata -F p -P -R -h 192.168.1.61 -p 5432 -U repuser   配置从库 postgresql.conf\n# 配置到主库的连接 primary_conninfo = 'host=192.168.1.67 port=5432 user=repuser password=password'   主库查看备份配置情况\nselect * from pg_stat_replication;   分区表 首先创建主表：\nCREATE TABLE measurement ( city_id int not null, logdate date not null, peaktemp int, unitsales int ) PARTITION BY RANGE (logdate); 然后按照需要的时间粒度创建分区：\nCREATE TABLE measurement_y2006m02 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-02-01\u0026#39;) TO (\u0026#39;2006-03-01\u0026#39;); CREATE TABLE measurement_y2006m03 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2006-03-01\u0026#39;) TO (\u0026#39;2006-04-01\u0026#39;); 在主表上创建的索引会自动创建到分区上：\nCREATE INDEX ON measurement (logdate); 另外，需要在配置文件中将 constraint_exclusion 修改为 partition。\n","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/postgresql-%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/","title":"PostgreSQL 安装与配置"},{"content":"数据库 创建数据库 创建数据库需要 superuser 或者 CREATEDB 的权限。\n默认情况下，创建的新数据库是克隆的数据库标准模板 template1，如果需要创建原始的数据库，需要指定模板为 template0。\n语法：\nCREATE DATABASE name [ [ WITH ] [ OWNER [=] user_name ] [ TEMPLATE [=] template ] [ ENCODING [=] encoding ] [ LC_COLLATE [=] lc_collate ] [ LC_CTYPE [=] lc_ctype ] [ TABLESPACE [=] tablespace_name ] [ ALLOW_CONNECTIONS [=] allowconn ] [ CONNECTION LIMIT [=] connlimit ] [ IS_TEMPLATE [=] istemplate ] ] 参数：\n name - 数据库名。 user_name - 数据库的拥有者，未指定则默认为执行创建数据库命令的用户。 template - 数据库创建模板，默认为 template1。 encoding - 字符编码，默认为模板的编码。 tablespace_name - 默认表空间的名称。 connlimit - 连接数量限制。  删除数据库 如果有任何人正在连接到数据库，则此时无法删除数据库。\n语法：\nDROP DATABASE [ IF EXISTS ] name 查看数据库 使用 \\l+ 可以列出数据库的详细信息：\nList of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+------------+------------+-----------------------  postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres 切换数据库 使用 \\c 可以切换数据库，使用 \\conninfo 可以查看当前连接情况：\npostgres=# \\c test; You are now connected to database \u0026#34;test\u0026#34; as user \u0026#34;postgres\u0026#34;. test=# \\conninfo You are connected to database \u0026#34;test\u0026#34; as user \u0026#34;postgres\u0026#34; via socket in \u0026#34;/var/run/postgresql\u0026#34; at port \u0026#34;5432\u0026#34;. ","date":"2021-02-06T00:00:00Z","permalink":"https://wnanbei.github.io/post/postgresql-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E8%A1%A8/","title":"PostgreSQL 数据库与表"},{"content":"Kubernetes 对象指的是 Kubernetes 系统的持久化实体，所有这些对象合起来，代表了集群的实际情况。\n常规的应用里，把应用程序的数据存储在数据库中，Kubernetes 将其数据以对象的形式通过 apiserver 存储在 etcd 中。\n这些 Kubernetes 对象描述了：\n 集群中运行了哪些容器化应用程序，以及在哪个节点上运行。 集群中对应用程序可用的资源。 应用程序相关的策略定义，例如：重启策略、升级策略、容错策略。 其他 Kubernetes 管理应用程序时所需要的信息。  一个 Kubernetes 对象代表着用户的一个意图，一旦创建了一个 Kubernetes 对象，Kubernetes 将持续工作，以尽量实现此用户的意图。\nspec 和 status 每一个 Kubernetes 对象都包含了两个重要的字段：\n spec 由用户提供，描述了对该对象所期望的目标状态。 status 由 Kubernetes 系统来修改，描述了该对象在 Kubernetes 系统中的实际状态。  Kubernetes 系统将不断地比较实际状态 staus 和目标状态 spec 之间的差异，并根据差异做出对应的调整。例如，如果任何一个副本运行失败了，Kubernetes 将启动一个新的副本，以替代失败的副本。\n用 yaml 描述对象 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: .... .yaml 文件中有几个必填字段：\n  apiVersion - 创建对象所使用的 Kubernetes API 版本。\n  kind - 被创建对象的类型。\n  metadata - 用于唯一确定该对象的元数据，包括 name 和 namespace。\n如果 namespace 为空，则默认值为 default。\n  spec - 描述用户对该对象的期望状态。不同类型的对象，其 spec 的格式不同。\n  以下命令可以使用 .yaml 文件创建对象：\nkubectl apply -f xxxxx.yaml Pod Pod 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。\n Pod 通常封装一个或多个紧密相关的容器，共享一个生命周期和消耗性资源。同一个 Pod 里的容器可以使用 localhost 互相通信。 Pod 默认不能从集群外部访问，需要设置端口才能访问。  在 k8s 中，Pod 的生命周期是短暂的，并不是持续性实体。\n通常不需要直接管理 Pod，而应该使用更好的可管理的高级对象，例如 Services、Deployment。在这些高级对象中，常常会自动的创建、销毁 Pod。\nPod 通常也不需要一个个分别创建，而是可以使用模版批量创建。\n示例 apiVersion: v1 kind: Pod metadata: name: twocontainers namespace: default labels: app: twocontainers annotations: version: v1 releasedBy: david purpose: demo spec: restartPolicy: Always containers: - name: sise #容器的名称 image: quay.io/openshiftlabs/simpleservice:0.5.0 #创建容器所使用的镜像 ports: - containerPort: 9876 #应用监听的端口 - name: shell #容器的名称 image: centos:7 #创建容器所使用的镜像 command: #容器启动命令 - \u0026#34;bin/bash\u0026#34; - \u0026#34;-c\u0026#34; - \u0026#34;sleep 10000\u0026#34; Label 一些 Pod 是有 Label 的，这些 Label 用于声明 Pod 的属性。\nmetadata: labels: key1: value1 key2: value2 标签的例子有：\n release: stable、release: canary environment: dev、environment: qa、environment: production tier: frontend、tier: backend、tier: cache partition: customerA、partition: customerB track: daily、track: weekly  而其他的高级对象，可以使用 Label Selector 批量选择特定 Label 的 Pod，来进行操作。\nselector: component: redis Annotation annotation 可以用来向 Kubernetes 对象的 metadata.annotations 字段添加任意的信息。Kubernetes 的客户端或者自动化工具可以存取这些信息以实现其自定义的逻辑。\n类似于下面的信息可以记录在注解中：\n 声明式配置层用到的状态信息。 Build、release、image 信息，例如：timestamp、release ID、git branch、PR number、image hash、registry address。 日志、监控、分析、审计系统的参数。 第三方工具所需要的信息，例如：name、version、build information、URL。 轻量级的发布工具用到的信息，例如：config、checkpoint。 负责人的联系方式，例如：电话号码、网址、电子信箱。 用户用来记录备忘信息的说明，例如：对标准镜像做了什么样的修改、维护过程中有什么特殊信息需要记住。  NameSpace Kubernetes 通过 namespace 在同一个物理集群上支持多个虚拟集群。\nnamespace 的用途是为不同团队的用户（或项目）提供虚拟的集群空间，也可以用来区分开发环境/测试环境、准上线环境/生产环境。\n namespace 内部的同类型对象不能重名。 namespace 不可以嵌套，任何一个 Kubernetes 对象只能在一个 namespace 中。  当 Kubernetes 对象之间的差异不大时，无需使用名称空间来区分。\nService Service 主要用于描述一组 pod 的网络状态，服务连接方式。\nDeployment Deployment 主要用于描述一组 pod 的创建、运行、升级方式。\n","date":"2021-01-06T16:17:25Z","permalink":"https://wnanbei.github.io/post/kubernetes-%E5%AF%B9%E8%B1%A1/","title":"Kubernetes 对象"},{"content":"以下是 k8s 官方的架构图：\n \nControl Plane Kubernetes 的控制面 Control Plane，负责整个集群的管理和控制。为了保证高可用，需要将控制面部署在多个 Master 实例上。\nkube-apiserver kube-apiserver 提供了所有内部和外部的 API 请求操作的唯一入口。同时也负责整个集群的认证、授权、访问控制、服务发现等能力。APIServer 还提供很多可扩展的能力，方便增强自己的功能。\n当集群规模很大的时候，APIServer 的吞吐量以及占用的 CPU 和内存都要很大。\nkube-scheduler Kube-scheduler 监听未调度的 Pod，按照预定的调度策略绑定到满足条件的节点上。\nkube-controller-manager Kube-Controller-Manager 负责维护整个 Kubernetes 集群的状态，比如多副本创建、滚动更新等。\nKube-controller-manager 并不是一个单一组件，内部包含了一组资源控制器，在启动的时候，会通过 goroutine 拉起多个资源控制器。这些控制器的逻辑仅依赖于当前状态，因为在分布式系统中没办法保证全局状态的同步。\netcd etcd 是兼具一致性和高可用性的分布式键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。\nNode Node 为计算节点，或者叫作工作负载节点，每个 Node 上都会运行一些负载容器。\nkubelet Kubelet 负责维护 Pod 的生命周期，比如创建和删除 Pod 对应的容器。同时也负责存储和网络的管理。一般会配合 CSI、CNI 插件一起工作。\nkube-proxy Kube-Proxy 主要负责 Kubernetes 内部的服务通信，在主机上维护网络规则并提供转发及负载均衡能力。\ncontainer runtime 容器运行时主要负责容器的镜像管理以及容器创建及运行。\nDocker 就是很常用的容器，此外还有 Kata、Frakti 等。只要符合 CRI（Container Runtime Interface，容器运行时接口）规范的运行时，都可以在 Kubernetes 中使用。\n","date":"2021-01-06T16:17:25Z","permalink":"https://wnanbei.github.io/post/kubernetes-%E6%9E%B6%E6%9E%84/","title":"Kubernetes 架构"},{"content":"子序列是指给定一个序列，将给定序列中零个或多个元素去掉之后得到的结果，子序列可以是不连续的。\n一般来说，这类问题都是求一个最长子序列。而一旦涉及到子序列和最值，那几乎可以肯定，考察的是动态规划技巧，时间复杂度一般都是 $O(n^2)$。\n思路 子序列问题大概分为两种套路。\n一维 DP 数组 var n int = len(array) dp := make([]int, n) for i := 1; i \u0026lt; n; i++ { for j := 0; j \u0026lt; i; j++ { dp[i] = 最值(dp[i], dp[j]+...) } } 此思路中 DP 数组定义为：\n在子数组 array[0..i] 中，以 array[i] 结尾的目标子序列（最长递增子序列）的长度是 dp[i]。\n二维 DP 数组 var n int = len(array) dp := make([][]int, n) for i := 0; i \u0026lt; n; i++ { for j := 1; j \u0026lt; n; j++ { if arr[i] == arr[j] { dp[i][j] += ... } else { dp[i][j] = 最值(...) } } } 在这种思路中，分为两种情况：\n  涉及两个字符串/数组时：\nDP 数组的含义为：在子数组 arr1[0..i] 和子数组 arr2[0..j] 中，我们要求的子序列长度为 dp[i][j]。\n  只涉及一个字符串/数组时：\nDP 数组的含义为：在子数组 array[i..j] 中，我们要求的子序列的长度为 dp[i][j]。\n  题解 编辑距离 Leetcode: 72. 编辑距离\n给定两个单词 word1 和 word2，计算出将 word1 转换成 word2 所使用的最少操作数。\n你可以对一个单词进行如下三种操作：\n 插入一个字符 删除一个字符 替换一个字符  func minDistance(word1 string, word2 string) int { m, n := len(word1), len(word2) dp := make([]int, n+1) for i := range dp { dp[i] = i } for i := 1; i \u0026lt;= m; i++ { last := i - 1 dp[0] = i for j := 1; j \u0026lt;= n; j++ { tmp := dp[j] if word1[i-1] == word2[j-1] { dp[j] = last } else { dp[j] = min( last, dp[j], dp[j-1], ) + 1 } last = tmp } } return dp[n] } func min(n ...int) (m int) { m = n[0] for _, v := range n[1:] { if v \u0026lt; m { m = v } } return m } 最长递增子序列 Leetcode: 300. 最长递增子序列\n给定一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n动态规划解法：\n \n longest-increasing-subsequence_2 \nfunc lengthOfLIS(nums []int) int { dp := make([]int, len(nums)) for i := range nums { dp[i] = 1 for j := 0; j \u0026lt; i; j++ { if nums[j] \u0026lt; nums[i] { if dp[j]+1 \u0026gt; dp[i] { dp[i] = dp[j] + 1 } } } } res := 0 for _, v := range dp { if v \u0026gt; res { res = v } } return res } 最长公共子序列 Leetcode: 1143. 最长公共子序列\n给定两个字符串 text1 和 text2，返回这两个字符串的最长公共子序列的长度。如果不存在公共子序列，返回 0。\n一个字符串的子序列是指这样一个新的字符串：\n  由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。\n例如，ace 是 abcde 的子序列，但 aec 不是 abcde 的子序列。\n  两个字符串的公共子序列是这两个字符串所共同拥有的子序列。\n  func longestCommonSubsequence(text1 string, text2 string) int { m, n := len(text1), len(text2) dp := make([]int, n+1) for i := 0; i \u0026lt; m; i++ { last := 0 for j := 0; j \u0026lt; n; j++ { tmp := dp[j+1] if text1[i] == text2[j] { dp[j+1] = last + 1 } else { if dp[j] \u0026gt; dp[j+1] { dp[j+1] = dp[j] } } last = tmp } } return dp[n] } 两个字符串的删除操作 Leetcode: 583. 两个字符串的删除操作\n给定两个单词 word1 和 word2，找到使得 word1 和 word2 相同所需的最小的操作步数，每步可以删除任意一个字符串中的一个字符。\nfunc minDistance(word1 string, word2 string) int { l := longestCommonSubsequence(word1, word2) return len(word1) - l + len(word2) - l } func longestCommonSubsequence(text1 string, text2 string) int { m, n := len(text1), len(text2) dp := make([]int, n+1) for i := 0; i \u0026lt; m; i++ { last := 0 for j := 0; j \u0026lt; n; j++ { tmp := dp[j+1] if text1[i] == text2[j] { dp[j+1] = last + 1 } else { if dp[j] \u0026gt; dp[j+1] { dp[j+1] = dp[j] } } last = tmp } } return dp[n] } 两个字符串的最小ASCII删除和 Leetcode: 712. 两个字符串的最小ASCII删除和\n给定两个字符串 s1, s2，找到使两个字符串相等所需删除字符的ASCII值的最小和。\nfunc minimumDeleteSum(s1 string, s2 string) int { return sumStr(s1) + sumStr(s2) - longestCommonSubsequence(s1, s2)*2 } func longestCommonSubsequence(text1 string, text2 string) int { m, n := len(text1), len(text2) dp := make([]int, n+1) for i := 0; i \u0026lt; m; i++ { last := 0 for j := 0; j \u0026lt; n; j++ { tmp := dp[j+1] if text1[i] == text2[j] { dp[j+1] = last + int(text1[i]) } else { if dp[j] \u0026gt; dp[j+1] { dp[j+1] = dp[j] } } last = tmp } } return dp[n] } func sumStr(s string) (asciiCount int) { for i := range s { asciiCount += int(s[i]) } return asciiCount } 最长回文子序列 leetcode: 516. 最长回文子序列\n给定一个字符串 s，找出其中最长的回文子序列，并返回该序列的长度。\nfunc longestPalindromeSubseq(s string) int { n := len(s) dp := make([]int, n) for i := range dp { dp[i] = 1 } for i := n - 2; i \u0026gt;= 0; i-- { last := 0 for j := i + 1; j \u0026lt; n; j++ { tmp := dp[j] if s[i] == s[j] { dp[j] = last + 2 } else { if dp[j] \u0026lt; dp[j-1] { dp[j] = dp[j-1] } } last = tmp } } return dp[n-1] } ","date":"2020-10-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E5%AD%90%E5%BA%8F%E5%88%97%E9%97%AE%E9%A2%98/","title":"动态规划之子序列问题"},{"content":"背包问题（Knapsack problem）是一种组合优化的NP完全问题。\n问题可以描述为：给定一组物品，每种物品都有自己的重量和价格，在限定的总重量内，我们如何选择，才能使得物品的总价格最高。\n问题的名称来源于如何选择最合适的物品放置于给定背包中。\n类型 0-1背包问题 给定一个可装载重量为 W 的背包和 N 个物品，每个物品有重量和价值两个属性。\n 其中第 i 个物品的重量为 wt[i]，价值为 val[i]  现在让你用这个背包装物品，最多能装的价值是多少？\n题解 分割等和子集 Leetcode: 416. 分割等和子集\n给定一个只包含正整数的非空数组 nums，判断是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。\nfunc canPartition(nums []int) bool { sum := 0 for _, v := range nums { sum += v } if sum%2 != 0 { return false } m := len(nums) n := sum / 2 dp := make([]bool, n+1) dp[0] = true for i := 0; i \u0026lt; m; i++ { for j := n; j \u0026gt;= 0; j-- { if j \u0026gt;= nums[i] { dp[j] = dp[j] || dp[j-nums[i]] } } } return dp[n] } 零钱兑换 II Leetcode: 518. 零钱兑换 II\n给定一个整数数组 coins 表示不同面额的硬币，另给一个整数 amount 表示总金额。\n计算并返回可以凑成总金额的硬币组合数。如果任何硬币组合都无法凑出总金额，返回 0。\n 每一种面额的硬币有无限个。  func change(amount int, coins []int) int { m := len(coins) dp := make([]int, amount+1) dp[0] = 1 for i := 1; i \u0026lt;= m; i++ { for j := 1; j \u0026lt;= amount; j++ { if j \u0026gt;= coins[i-1] { dp[j] += dp[j-coins[i-1]] } } } return dp[amount] } ","date":"2020-10-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/","title":"动态规划之背包问题"},{"content":"贪心算法可以认为是动态规划算法的一个特例，相比动态规划：\n 使用贪心算法需要满足更多的条件（贪心选择性质）。 效率比动态规划高。  一个算法问题使用暴力解法需要指数级时间，如果能使用动态规划消除重叠子问题，就可以降到多项式级别的时间，如果满足贪心选择性质，那么可以进一步降低时间复杂度，达到线性级别。\n概念 贪心选择性质 贪心选择性质就是：\n 每一步都做出一个局部最优的选择，最终的结果就是全局最优。\n 注：这是一种特殊性质，只有一小部分问题拥有这个性质。\n题解 无重叠区间 Leetcode: 435. 无重叠区间\n给定一个区间的集合，找到需要移除区间的最小数量，使剩余区间互不重叠。\n 可以认为区间的终点总是大于它的起点。 区间 [1,2] 和 [2,3] 的边界相互接触，但没有相互重叠。  func eraseOverlapIntervals(intervals [][]int) int { sort.Slice(intervals, func(i, j int) bool { return intervals[i][1] \u0026lt; intervals[j][1] }) count := len(intervals) - 1 end := intervals[0][1] for _, v := range intervals[1:] { if v[0] \u0026gt;= end { end = v[1] count-- } } return count } 用最少数量的箭引爆气球 Leetcode: 452. 用最少数量的箭引爆气球\n在二维空间中有许多球形的气球。对于每个气球，提供的输入是水平方向上，气球直径的开始和结束坐标。由于它是水平的，所以纵坐标并不重要，因此只要知道开始和结束的横坐标就足够了。开始坐标总是小于结束坐标。\n一支弓箭可以沿着 x 轴从不同点完全垂直地射出。在坐标 x 处射出一支箭，若有一个气球的直径的开始和结束坐标为 xstart，xend， 且满足 xstart ≤ x ≤ xend，则该气球会被引爆。\n 可以射出的弓箭的数量没有限制。 弓箭一旦被射出之后，可以无限地前进。  求想找到使得所有气球全部被引爆，所需的弓箭的最小数量。\n给定一个数组 points，其中 points [i] = [xstart,xend]，返回引爆所有气球所必须射出的最小弓箭数。\nfunc findMinArrowShots(points [][]int) int { sort.Slice(points, func(i, j int) bool { return points[i][1] \u0026lt; points[j][1] }) count := 1 end := points[0][1] for _, v := range points[1:] { if v[0] \u0026gt; end { end = v[1] count++ } } return count } ","date":"2020-10-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/","title":"动态规划之贪心算法"},{"content":"二叉搜索树 Binary Search Tree 简称 BST，是二叉树的一种特殊形式。二叉搜索树每个节点 node 都具有以下性质：\n 左子树所有子节点的值都比 node 的值要小，右子树所有子节点的值都比 node 的值大。 它的左侧子树和右侧子树都是 BST。  BST 有一个重要的性质: BST 的中序遍历结果是有序的（升序）。\n \n题解 不同的二叉搜索树 II Leetcode 题目描述: 不同的二叉搜索树 II\n一个整数 n，生成并返回所有由 n 个节点组成且节点值从 1 到 n 互不相同的不同二叉搜索树。\n可以按任意顺序返回答案。\nfunc generateTrees(n int) []*TreeNode { return generate(1, n) } func generate(low, high int) []*TreeNode { trees := make([]*TreeNode, 0) if low \u0026gt; high { trees = append(trees, nil) return trees } for i := low; i \u0026lt;= high; i++ { leftTrees := generate(low, i-1) rightTrees := generate(i+1, high) for _, left := range leftTrees { for _, right := range rightTrees { n := \u0026amp;TreeNode{ Val: i, Left: left, Right: right, } trees = append(trees, n) } } } return trees } 不同的二叉搜索树 Leetcode 题目描述: 不同的二叉搜索树\n给定一个整数 n，求由 n 个节点组成且节点值从 1 到 n 互不相同的二叉搜索树有多少种？\nvar cache [][]int func numTrees(n int) int { cache = make([][]int, n+1) for i:=1; i \u0026lt;=n; i++ { cache[i] = make([]int, n+1) } return count(1, n) } func count(low, high int) int { if low \u0026gt; high { return 1 } if cache[low][high] != 0 { return cache[low][high] } var c int for i := low; i \u0026lt;= high; i++ { left := count(low, i-1) right := count(i + 1, high) c += left * right } cache[low][high] = c return c } 验证二叉搜索树 Leetcode 题目描述: 验证二叉搜索树\n给定一个二叉树，判断其是否是一个有效的二叉搜索树。\nfunc isValidBST(root *TreeNode) bool { var validBST func(n, min, max *TreeNode) bool validBST = func(n, min, max *TreeNode) bool { if n == nil { return true } if min != nil \u0026amp;\u0026amp; n.Val \u0026lt;= min.Val { return false } if max != nil \u0026amp;\u0026amp; n.Val \u0026gt;= max.Val { return false } return validBST(n.Left, min, n) \u0026amp;\u0026amp; validBST(n.Right, n, max) } return validBST(root, nil, nil) } 二叉搜索树中第K小的元素 Leetcode 题目描述: 二叉搜索树中第K小的元素\n给定一个二叉搜索树的根节点 root，和一个整数 k，设计一个算法查找其中第 k 个最小元素（从 1 开始计数）。\nfunc kthSmallest(root *TreeNode, k int) int { stack := []*TreeNode{} for root != nil || len(stack) \u0026gt; 0 { if root != nil { stack = append(stack, root) root = root.Left } else { node := stack[len(stack)-1] stack = stack[:len(stack)-1] k-- if k == 0 { return node.Val } root = node.Right } } return 0 } 删除二叉搜索树中的节点 Leetcode 题目描述: 删除二叉搜索树中的节点\n给定一个二叉搜索树的根节点 root 和一个值 key，删除二叉搜索树中的 key 对应的节点，保证二叉搜索树的性质不变。返回二叉搜索树的根节点。\nfunc deleteNode(root *TreeNode, key int) *TreeNode { if root == nil { return nil } switch { case root.Val == key: if root.Left == nil { return root.Right } else if root.Right == nil { return root.Left } else { m := min(root.Right) root.Val = m.Val root.Right = deleteNode(root.Right, m.Val) } case root.Val \u0026lt; key: root.Right = deleteNode(root.Right, key) case root.Val \u0026gt; key: root.Left = deleteNode(root.Left, key) } return root } func min(n *TreeNode) *TreeNode { for n.Left != nil { n = n.Left } return n } 把二叉搜索树转换为累加树 Leetcode 题目描述: 把二叉搜索树转换为累加树\n给出二叉搜索树的根节点，该树的节点值各不相同，将其转换为累加树（Greater Sum Tree），使每个节点 node 的新值等于原树中大于或等于 node.val 的值之和。\n二叉搜索树满足下列约束条件：\n 节点的左子树仅包含键小于节点键的节点。 节点的右子树仅包含键大于节点键的节点。 左右子树也必须是二叉搜索树。  func convertBST(root *TreeNode) *TreeNode { var sum int var bfs func(n *TreeNode) bfs = func(n *TreeNode) { if n == nil { return } bfs(n.Right) sum += n.Val n.Val = sum bfs(n.Left) } bfs(root) return root } 二叉搜索树中的搜索 Leetcode 题目描述: 二叉搜索树中的搜索\n给定二叉搜索树的根节点和一个值，在 BST 中找到节点值等于给定值的节点，返回以该节点为根的子树，如果节点不存在，返回 NULL。\nfunc searchBST(root *TreeNode, val int) *TreeNode { var node *TreeNode var dfs func(n *TreeNode) dfs = func(n *TreeNode) { if n == nil { return } switch { case val == n.Val: node = n case val \u0026lt; n.Val: dfs(n.Left) case val \u0026gt; n.Val: dfs(n.Right) } } dfs(root) return node } 二叉搜索树中的插入操作 Leetcode 题目描述: 二叉搜索树中的插入操作\n给定二叉搜索树的根节点和要插入树中的值，将值插入二叉搜索树。返回插入后二叉搜索树的根节点。\n 输入的数据和原始二叉搜索树中的任意节点值都不同。  func insertIntoBST(root *TreeNode, val int) *TreeNode { var dfs func(n *TreeNode) *TreeNode dfs = func(n *TreeNode) *TreeNode { if n == nil { return \u0026amp;TreeNode{Val: val} } switch { case val \u0026lt; n.Val: n.Left = dfs(n.Left) case val \u0026gt; n.Val: n.Right = dfs(n.Right) } return n } return dfs(root) } ","date":"2020-10-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/","title":"数据结构与算法之二叉搜索树"},{"content":"树是一种经常用到的数据结构，用来模拟具有树状结构性质的数据集合。树里的每一个节点有一个值和一个包含所有子节点的列表。\n从图的观点来看，树也可视为一个拥有 N 个节点和 N-1 条边的一个有向无环图。\n二叉树是一种典型的树状结构，是每个节点最多有两个子树的树结构，通常子树被称作左子树和右子树。\n概念 完美二叉树 Perfect Binary Tree，国内也称满二叉树。指二叉树所有叶子节点都在同一层，每个父节点都有两个子节点。\n如果完美二叉树的层数为 K，则节点总数为 $k^2 - 1$。\n \n完全二叉树 Complete Binary Tree，指每一层节点都紧凑靠左排列。\n如果完全二叉树的层数为 K，则：\n 除第 K 层外，其他所有层的节点都是满的。 第 K 层所有节点都连续集中在左边。   \nFull binary tree Full binary tree 所有节点，要么两个子节点都存在，要么两个子节点都不存在。\n \n深度优先搜索 这是递归遍历二叉树的三种方式：\n// 二叉树遍历框架 func traverse(root *Node) { // 前序遍历  traverse(root.Left) // 中序遍历  traverse(root.Right) // 后序遍历 }   快速排序就是个二叉树的前序遍历\n  归并排序就是个二叉树的后序遍历\n  前序遍历 前序遍历首先访问根节点，然后遍历左子树，最后遍历右子树。\n binary_tree_1 \n中序遍历 中序遍历是先遍历左子树，然后访问根节点，然后遍历右子树。\n binary_tree_2 \n后序遍历 后序遍历是先遍历左子树，然后遍历右子树，最后访问树的根节点。\n binary_tree_3 \n二叉树题解 从前序与中序遍历序列构造二叉树 Leetcode 题目描述: 从前序与中序遍历序列构造二叉树\n给定一棵树的前序遍历 preorder 与中序遍历 inorder。请构造二叉树并返回其根节点。\n注意: 可以假设树中没有重复的元素。\nfunc buildTree(preorder []int, inorder []int) *TreeNode { if len(preorder) == 0 || len(inorder) == 0 { return nil } n := new(TreeNode) n.Val = preorder[0] var rootIndex int for i, v := range inorder { if v == preorder[0] { rootIndex = i break } } n.Left = buildTree(preorder[1:rootIndex+1], inorder[:rootIndex]) n.Right = buildTree(preorder[rootIndex+1:], inorder[rootIndex+1:]) return n } 从中序与后序遍历序列构造二叉树 Leetcode 题目描述: 从中序与后序遍历序列构造二叉树\n根据一棵树的中序遍历与后序遍历构造二叉树。\n注意: 可以假设树中没有重复的元素。\nfunc buildTree(inorder []int, postorder []int) *TreeNode { if len(inorder) == 0 || len(postorder) == 0 { return nil } n := new(TreeNode) n.Val = postorder[len(postorder)-1] var rootIndex int for i, v := range inorder { if v == n.Val { rootIndex = i break } } n.Left = buildTree(inorder[:rootIndex], postorder[:rootIndex]) n.Right = buildTree(inorder[rootIndex+1:], postorder[rootIndex:len(postorder)-1]) return n } 二叉树展开为链表 Leetcode 题目描述: 二叉树展开为链表\n给你二叉树的根结点 root，将它展开为一个单链表：\n 展开后的单链表应该同样使用 TreeNode，其中 right 子指针指向链表中下一个结点，而左子指针始终为 null。 展开后的单链表应该与二叉树先序遍历顺序相同。  func flatten(root *TreeNode) { if root == nil { return } flatten(root.Left) flatten(root.Right) tmp := root.Right root.Right = root.Left root.Left = nil p := root for p.Right != nil { p = p.Right } p.Right = tmp } 填充每个节点的下一个右侧节点指针 Leetcode 题目描述: 填充每个节点的下一个右侧节点指针\n给定一个完美二叉树，其所有叶子节点都在同一层，每个父节点都有两个子节点。\n二叉树定义如下：\nstruct Node { int val; Node *left; Node *right; Node *next; } 填充它的每个 next 指针，让这个指针指向其下一个右侧节点。如果找不到下一个右侧节点，则将 next 指针设置为 NULL。\n初始状态下，所有 next 指针都被设置为 NULL。\nfunc connect(root *Node) *Node { if root == nil { return nil } for top := root; top.Left != nil; top = top.Left { for node := top; node != nil; node = node.Next { node.Left.Next = node.Right if node.Next != nil { node.Right.Next = node.Next.Left } } } return root } 翻转二叉树 Leetcode 题目描述: 翻转二叉树\n翻转一棵二叉树。\nfunc invertTree(root *TreeNode) *TreeNode { invert(root) return root } func invert(n *TreeNode) { if n == nil { return } n.Left, n.Right = n.Right, n.Left invert(n.Left) invert(n.Right) } 二叉树的最近公共祖先 Leetcode 题目描述: 二叉树的最近公共祖先\n给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。\n 一个节点可以是它自己的祖先。  func lowestCommonAncestor(root, p, q *TreeNode) *TreeNode { if root == nil { return nil } if root.Val == p.Val || root.Val == q.Val { return root } left := lowestCommonAncestor(root.Left, p, q) right := lowestCommonAncestor(root.Right, p, q) switch { case left != nil \u0026amp;\u0026amp; right != nil: return root case left == nil \u0026amp;\u0026amp; right == nil: return nil case left != nil: return left case right != nil: return right } return nil } 二叉树的序列化与反序列化 Leetcode 题目描述: 二叉树的序列化与反序列化\n序列化是将一个数据结构或者对象转换为连续的比特位的操作，进而可以将转换后的数据存储在一个文件或者内存中，同时也可以通过网络传输到另一个计算机环境，采取相反方式重构得到原数据。\n请设计一个算法来实现二叉树的序列化与反序列化。这里不限定你的序列/反序列化算法执行逻辑，你只需要保证一个二叉树可以被序列化为一个字符串并且将这个字符串反序列化为原始的树结构。\nimport ( \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; ) type Codec struct{} func Constructor() Codec { return Codec{} } // Serializes a tree to a single string. func (this *Codec) serialize(root *TreeNode) string { builder := \u0026amp;strings.Builder{} var serl func(n *TreeNode) serl = func(n *TreeNode) { if n == nil { builder.WriteString(\u0026#34;null,\u0026#34;) return } builder.WriteString(strconv.Itoa(n.Val)) builder.WriteString(\u0026#34;,\u0026#34;) serl(n.Left) serl(n.Right) } serl(root) return builder.String() } // Deserializes your encoded data to tree. func (this *Codec) deserialize(data string) *TreeNode { d := strings.Split(data, \u0026#34;,\u0026#34;) return deserl(\u0026amp;d) } func deserl(data *[]string) *TreeNode { nodeV := (*data)[0] *data = (*data)[1:] if nodeV == \u0026#34;null\u0026#34; { return nil } v, _ := strconv.Atoi(nodeV) n := \u0026amp;TreeNode{Val: v} n.Left = deserl(data) n.Right = deserl(data) return n } 寻找二叉树重复的子树 Leetcode 题目描述: 寻找二叉树重复的子树\n给定一棵二叉树，返回所有重复的子树。对于同一类的重复子树，你只需要返回其中任意一棵的根结点即可。\n两棵树重复是指它们具有相同的结构以及相同的结点值。\nfunc findDuplicateSubtrees(root *TreeNode) []*TreeNode { nodes := make([]*TreeNode, 0) count := make(map[string]int, 0) var dfs func(node *TreeNode) string dfs = func(node *TreeNode) string { if node == nil { return \u0026#34;\u0026#34; } strBuilder := \u0026amp;strings.Builder{} strBuilder.WriteString(strconv.Itoa(node.Val)) strBuilder.WriteString(\u0026#34;,\u0026#34;) strBuilder.WriteString(dfs(node.Left)) strBuilder.WriteString(\u0026#34;,\u0026#34;) strBuilder.WriteString(dfs(node.Right)) s := strBuilder.String() if v, ok := count[s]; ok { if v == 1 { nodes = append(nodes, node) } } count[s] += 1 return s } dfs(root) return nodes } 最大二叉树 Leetcode: 最大二叉树\n给定一个不含重复元素的整数数组 nums 。一个以此数组直接递归构建的最大二叉树定义如下：\n 二叉树的根是数组 nums 中的最大元素。 左子树是通过数组中 最大值左边部分 递归构造出的最大二叉树。 右子树是通过数组中 最大值右边部分 递归构造出的最大二叉树。  返回有给定数组 nums 构建的 最大二叉树 。\nfunc constructMaximumBinaryTree(nums []int) *TreeNode { if len(nums) == 0 { return nil } node := new(TreeNode) if len(nums) == 1 { node.Val = nums[0] return node } var index, nodeVal int for i, v := range nums { if v \u0026gt; nodeVal { index = i nodeVal = v } } node.Val = nodeVal node.Left = constructMaximumBinaryTree(nums[0:index]) node.Right = constructMaximumBinaryTree(nums[index+1 : len(nums)]) return node } 完全二叉树题解 完全二叉树的节点个数 Leetcode: 222. 完全二叉树的节点个数\n求出一棵完全二叉树的节点个数。\nfunc countNodes(root *TreeNode) int { if root == nil { return 0 } leftHeight := countLeft(root.Left) rightHeight := countRight(root.Right) if leftHeight == rightHeight { return 2\u0026lt;\u0026lt;leftHeight - 1 } return 1 + countNodes(root.Left) + countNodes(root.Right) } func countLeft(n *TreeNode) int { var count int for n != nil { count += 1 n = n.Left } return count } func countRight(n *TreeNode) int { var count int for n != nil { count += 1 n = n.Right } return count } ","date":"2020-10-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"数据结构与算法之二叉树"},{"content":"常说的链表为单链表，数据结构如下：\n \nGo 实现：\ntype ListNode struct { Val int Next *ListNode } 题解 反转链表 Leetcode: 206. 反转链表\n输入一个链表的头节点，反转该链表并输出反转后链表的头节点。\n示例：\n 输入: 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;NULL 输出: 5-\u0026gt;4-\u0026gt;3-\u0026gt;2-\u0026gt;1-\u0026gt;NULL\n 双指针\nfunc reverseList(head *ListNode) *ListNode { var pre, cur *ListNode = nil, head for cur != nil { cur.Next, pre, cur = pre, cur, cur.Next } return pre } 递归\nfunc reverseList(head *ListNode) *ListNode { if head == nil || head.Next == nil { // head == nil 判断是避免传入一个无节点空链表时发生异常  return head } var newNode *ListNode newNode = reverseList(head.Next) head.Next.Next = head head.Next = nil return newNode } 反转部分链表 Leetcode: 92. 反转链表 II\n给定单链表的头指针 head 和两个整数 left 和 right，其中 left \u0026lt;= right。\n反转从位置 left 到位置 right 的链表节点，返回反转后的链表 。\nfunc reverseBetween(head *ListNode, left, right int) *ListNode { // 设置 dummyNode 是这一类问题的一般做法  dummyNode := \u0026amp;ListNode{Val: -1} dummyNode.Next = head pre := dummyNode for i := 0; i \u0026lt; left-1; i++ { pre = pre.Next } cur := pre.Next for i := 0; i \u0026lt; right-left; i++ { next := cur.Next cur.Next = next.Next next.Next = pre.Next pre.Next = next } return dummyNode.Next } K 个一组翻转链表 Leetcode: 25. K 个一组翻转链表\n给定一个链表，每 k 个节点一组进行翻转，返回翻转后的链表。\n  k 是一个正整数，它的值小于或等于链表的长度。\n  如果节点总数不是 k 的整数倍，那么将最后剩余的节点保持原有顺序。\n  func reverse(head, tail *ListNode) (*ListNode, *ListNode) { pre, cur := tail.Next, head for pre != tail { tmp := cur.Next cur.Next = pre pre = cur cur = tmp } return tail, head } func reverseKGroup(head *ListNode, k int) *ListNode { dmy := new(ListNode) dmy.Next = head pre := dmy for head != nil { tail := pre for i := 0; i \u0026lt; k; i++ { tail = tail.Next if tail == nil { return dmy.Next } } nex := tail.Next head, tail = reverse(head, tail) pre.Next = head tail.Next = nex pre = tail head = tail.Next } return dmy.Next } 回文链表 Leetcode: 234. 回文链表\n给定一个单链表的头节点 head，判断该链表是否为回文链表。\nfunc isPalindrome(head *ListNode) bool { slow, fast := head, head for fast != nil \u0026amp;\u0026amp; fast.Next != nil { slow = slow.Next fast = fast.Next.Next } if fast != nil { slow = slow.Next } right := reverse(slow) for right != nil { if head.Val != right.Val { return false } head = head.Next right = right.Next } return true } func reverse(head *ListNode) *ListNode { var pre *ListNode var cur *ListNode = head for cur != nil { next := cur.Next cur.Next = pre pre = cur cur = next } return pre } ","date":"2020-10-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E5%8D%95%E9%93%BE%E8%A1%A8%E9%97%AE%E9%A2%98/","title":"数据结构与算法之单链表问题"},{"content":"动态规划问题的一般形式就是求最值。比如求最长递增子序列，最小编辑距离等等。\n求解动态规划的核心问题是穷举。因为要求最值，要把所有可行的答案穷举出来，然后在其中找最值。\n概念 动态规划三要素  重叠子问题 - 动态规划的穷举比较特别，因为存在重叠子问题，如果暴力穷举的话效率会极其低下，所以需要备忘录或者 DP table 来优化穷举过程，避免不必要的计算。 最优子结构 - 动态规划问题一定会具备最优子结构，才能通过子问题的最值得到原问题的最值。 状态转移方程 - 虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出正确的状态转移方程，才能正确地穷举。  状态转移方程 动态规划三要素中，写出状态转移方程是最困难的，以下是辅助思考状态转移方程的一个思维框架：\n 明确 base case 明确 状态 明确 选择 定义 dp 数组/函数的含义  最优子结构 最优子结构是某些问题的一种特定性质，通过子问题的最优值推出规模更大的问题的最优值。\n找最优子结构的过程，其实就是证明状态转移方程正确性的过程，方程符合最优子结构就可以写暴力解了，写出暴力解就可以看出有没有重叠子问题了，有则优化，无则 OK。\n题解 斐波那契数 Leetcode: 509. 斐波那契数\n斐波那契数，通常用 F(n) 表示，形成的序列称为斐波那契数列。\n该数列由 0 和 1 开始，后面的每一项数字都是前面两项数字的和。也就是：\n F(0) = 0，F(1) = 1 F(n) = F(n - 1) + F(n - 2)，其中 n \u0026gt; 1\n 代码实现：\nfunc fib(n int) int { if n \u0026lt; 1 { return 0 } if n \u0026lt; 3 { return 1 } pre, cur := 1, 1 for i := 3; i \u0026lt;= n; i++ { sum := pre + cur pre, cur = cur, sum } return cur } 零钱兑换 Leetcode: 322. 零钱兑换\n给定一个整数数组 coins，表示不同面额的硬币。以及一个整数 amount，表示总金额。\n 计算并返回可以凑成总金额所需的最少的硬币个数。 如果没有任何一种硬币组合能组成总金额，返回 -1。 每种硬币的数量是无限的。  状态转移方程：\n$ dp(n)=\\left{\\begin{aligned} 0,n=0 \\ -1,n\u0026lt;1 \\ \\min{dp(n-coin)+1|coin\\in(coins)},n\u0026gt;0 \\end{aligned} \\right.$\n代码实现：\nfunc coinChange(coins []int, amount int) int { dp := make([]int, amount+1) for i := range dp { dp[i] = amount + 1 } dp[0] = 0 for i := range dp { for _, coin := range coins { if i \u0026lt; coin { continue } next := dp[i-coin] + 1 if dp[i] \u0026gt; next { dp[i] = next } } } if dp[amount] == amount+1 { return -1 } return dp[amount] } 下降路径最小和 Leetcode: 931. 下降路径最小和\n给定一个 n x n 的方形整数数组 matrix ，找出并返回通过 matrix 的下降路径的最小和 。\n下降路径：\n  可以从第一行中的任何元素开始，并从每一行中选择一个元素。\n  在下一行选择的元素和当前行所选元素最多相隔一列（即位于正下方或者沿对角线向左或者向右的第一个元素）。\n具体来说，位置 (row, col) 的下一个元素应当是 (row + 1, col - 1)、(row + 1, col) 或者 (row + 1, col + 1) 。\n  func minFallingPathSum(matrix [][]int) int { n := len(matrix) for i := n - 2; i \u0026gt;= 0; i-- { for j := 0; j \u0026lt; n; j++ { m := matrix[i+1][j] if j \u0026gt; 0 { if matrix[i+1][j-1] \u0026lt; m { m = matrix[i+1][j-1] } } if j \u0026lt; n-1 { if matrix[i+1][j+1] \u0026lt; m { m = matrix[i+1][j+1] } } matrix[i][j] += m } } return min(matrix[0]...) } func min(i ...int) int { res := math.MaxInt32 for _, v := range i { if v \u0026lt; res { res = v } } return res } ","date":"2020-10-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E5%B8%B8%E8%A7%81%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98/","title":"数据结构与算法之常见动态规划问题"},{"content":"题解 两数之和 Leetcode: 1. 两数之和\n给定一个整数数组 nums 和一个整数目标值 target，在该数组中找出和为目标值 target 的那两个整数，并返回它们的数组下标。\n 可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。 可以按任意顺序返回答案。  func twoSum(nums []int, target int) []int { hashTable := map[int]int{} for i, x := range nums { if p, ok := hashTable[target-x]; ok { return []int{p, i} } hashTable[x] = i } return nil } 时间复杂度：O(N)，其中 N 是数组中的元素数量。对于每一个元素 x，我们可以 O(1) 地寻找 target - x。\n空间复杂度：O(N)，其中 N 是数组中的元素数量。主要为哈希表的开销。\n","date":"2020-10-10T00:00:00Z","permalink":"https://wnanbei.github.io/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E6%95%B0%E7%BB%84/","title":"数据结构与算法之数组"},{"content":"Gin 的安装、启动、配置与部分简介。\n安装 安装：\n$ go get -u github.com/gin-gonic/gin 导入：\nimport \u0026#34;github.com/gin-gonic/gin\u0026#34; 简单例子：\npackage main import \u0026#34;github.com/gin-gonic/gin\u0026#34; func main() { r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;, }) }) r.Run() // 默认监听并在 0.0.0.0:8080 上启动服务 } 启动 创建路由 通常情况下使用 gin.Default() 方法获取 gin 实例，但此方法获取的引擎默认使用两个中间件 Logger 和 Recovery。\nr := gin.Default() 如果希望使用无中间件的实例，使用以下方法：\nr := gin.New() 自定义 HTTP 配置 直接使用 http.ListenAndServe() ：\nfunc main() { router := gin.Default() http.ListenAndServe(\u0026#34;:8080\u0026#34;, router) } 或者\nfunc main() { router := gin.Default() s := \u0026amp;http.Server{ Addr: \u0026#34;:8080\u0026#34;, Handler: router, ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, MaxHeaderBytes: 1 \u0026lt;\u0026lt; 20, } s.ListenAndServe() } 运行多个服务 package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) var ( g errgroup.Group ) func router01() http.Handler { e := gin.New() e.Use(gin.Recovery()) e.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.JSON( http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: http.StatusOK, \u0026#34;error\u0026#34;: \u0026#34;Welcome server 01\u0026#34;, }, ) }) return e } func router02() http.Handler { e := gin.New() e.Use(gin.Recovery()) e.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.JSON( http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: http.StatusOK, \u0026#34;error\u0026#34;: \u0026#34;Welcome server 02\u0026#34;, }, ) }) return e } func main() { server01 := \u0026amp;http.Server{ Addr: \u0026#34;:8080\u0026#34;, Handler: router01(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, } server02 := \u0026amp;http.Server{ Addr: \u0026#34;:8081\u0026#34;, Handler: router02(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, } g.Go(func() error { return server01.ListenAndServe() }) g.Go(func() error { return server02.ListenAndServe() }) if err := g.Wait(); err != nil { log.Fatal(err) } } ","date":"2020-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/gin-%E5%90%AF%E5%8A%A8%E4%B8%8E%E9%85%8D%E7%BD%AE/","title":"Gin 启动与配置"},{"content":"Gin 获取客户端发送请求的各种路由、URL、Post 表单、header 等数据，或者将这些数据绑定到模型中。\n直接获取 路由参数 Gin 可以直接使用 Param() 方法或者 Params 字段获取路由中的参数：\nfunc (c *Context) Param(key string) string type Params []Param func (ps Params) ByName(name string) (va string) func (ps Params) Get(name string) (string, bool) 例子：\nrouter.GET(\u0026#34;/user/:name/*action\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) action := c.Param(\u0026#34;action\u0026#34;) }) router.GET(\u0026#34;/user/:id\u0026#34;,func(c *gin.Context){ id, err := c.Params.Get(\u0026#34;id\u0026#34;) id := c.Params.ByName(\u0026#34;id\u0026#34;) }) url 参数   获取单个参数\nfunc (c *Context) GetQuery(key string) (string, bool) func (c *Context) Query(key string) string func (c *Context) DefaultQuery(key, defaultValue string) string   获取数组\nfunc (c *Context) GetQueryArray(key string) ([]string, bool) func (c *Context) QueryArray(key string) []string 例子：\nr.GET(\u0026#34;/user\u0026#34;, func(c *gin.Context) { ids := c.QueryArray(\u0026#34;id\u0026#34;) c.JSON(200,ids) }) // 请求：http://localhost:8080/user?id=10\u0026amp;id=11\u0026amp;id=12 // 响应：[\u0026#34;10\u0026#34;,\u0026#34;11\u0026#34;,\u0026#34;12\u0026#34;]   获取 Map\nfunc (c *Context) QueryMap(key string) map[string]string func (c *Context) GetQueryMap(key string) (map[string]string, bool) 例子：\nr.GET(\u0026#34;/user\u0026#34;, func(c *gin.Context) { ids := c.QueryMap(\u0026#34;ids\u0026#34;) //ids, err := c.GetQueryMap(\u0026#34;ids\u0026#34;)  c.JSON(200,ids) }) // 请求：http://localhost:8080/user?ids[10]=zhang // 响应：{\u0026#34;10\u0026#34;:\u0026#34;zhang\u0026#34;}   Post 表单 以下方法，只能获取 Content-type 是 application/x-www-form-urlencoded 或 multipart/form-data 时 body 中的数据。\nfunc (c *Context) PostForm(key string) string func (c *Context) DefaultPostForm(key, defaultValue string) string func (c *Context) PostFormArray(key string) []string func (c *Context) PostFormMap(key string) map[string]string func (c *Context) GetPostForm(key string) (string, bool) func (c *Context) GetPostFormArray(key string) ([]string, bool) func (c *Context) GetPostFormMap(key string) (map[string]string, bool) 例子：\nrouter.POST(\u0026#34;/form_post\u0026#34;, func(c *gin.Context) { message := c.PostForm(\u0026#34;message\u0026#34;) nick := c.DefaultPostForm(\u0026#34;nick\u0026#34;, \u0026#34;anonymous\u0026#34;) }) 原始数据 如果需要获取请求 body 中的原始数据，可以使用此方法\nfunc (c *Context) GetRawData() ([]byte, error) 绑定 Model Gin 提供了两类方法来绑定 Model，分别是：\n Bind，BindUri，BindQuery，BindJSON，BindXML，BindYAML ShouldBind，ShouldBindUri，ShouldBindQuery，ShouldBindJSON，ShouldBindXML，ShouldBindYAML  他们的区别是，Bind 类型的方法，如果绑定发生异常，那么请求会被 c.AbortWithError(400, err).SetType(ErrorTypeBind) 拒绝，这会将响应状态码设置为 400 并且将 Content-Type 设置为 text/plain; charset=utf-8。\n而 Should 类型方法，如果绑定发生异常，那么将会返回异常，由开发者来负责处理。\n绑定的 Model 需要几个参数来分别设置字段类型\ntype Login struct { User string `form:\u0026#34;user\u0026#34; json:\u0026#34;user\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `form:\u0026#34;password\u0026#34; json:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` }  form - 用于 url 参数或者 post 表单 json - 用于 Json 绑定 xml - 用于 xml 绑定 time_format - 用于 time.Time 字段的格式 binding  required - 要求此参数为必要参数 - - 表示不绑定此参数    BindUri BindUri 用于绑定路由路径参数。\ntype User struct { Uid int Username string } r.GET(\u0026#34;/bind/:uid/username\u0026#34;, func(c *gin.Context) { var u User err := c.BindUri(\u0026amp;u) if err == nil{ c.JSON(200,u) } }) // 请求：http://localhost:8080/bind/1/小张 // 输入：{1,\u0026#34;小张\u0026#34;} BindQuery BindQuery 方法将会只绑定 url 参数，忽略 Post 表单。\nr.GET(\u0026#34;/bind\u0026#34;, func(c *gin.Context) { var u User e := c.BindQuery(\u0026amp;u) if e == nil{ c.JSON(200,u) } }) // 请求：http://localhost:8080/bind?uid=1\u0026amp;username=小张 // 输出：{1,\u0026#34;小张\u0026#34;} Bind Bind 方法较为智能，分为以下几种情况：\n 如果是 GET 请求，只使用 Form 绑定 url 参数。 如果是 POST 请求，首先检查 content-type 是否为 JSON 或 XML，然后再使用 Form（form-data）。  绑定 Body 当我们在 HTTP 请求中 Body 设置不同数据格式，需要设置相应头部 Content-Type 的值，比较常用为 json、xml、yaml。\ngin.Context 提供下面三个方法绑定对应 Content-type 时 body 中的数据。\nfunc (c *Context) BindJSON(obj interface{}) error func (c *Context) BindXML(obj interface{}) error func (c *Context) BindYAML(obj interface{}) error 绑定特定类型 Gin 框架将数据绑定的操作都封装在 gin/binding 这个包中，下面是 gin/binding包 处理不同 Content-type 提交数据的处理结构体。\nvar ( JSON = jsonBinding{} XML = xmlBinding{} Form = formBinding{} Query = queryBinding{} FormPost = formPostBinding{} FormMultipart = formMultipartBinding{} ProtoBuf = protobufBinding{} MsgPack = msgpackBinding{} YAML = yamlBinding{} Uri = uriBinding{} ) 如果需要绑定指定类型，则可以使用这两个方法。\nfunc (c *Context) BindWith(obj interface{}, b binding.Binding) error func (c *Context) MustBindWith(obj interface{}, b binding.Binding) error 例子：\nr.POST(\u0026#34;bind\u0026#34;,func(c *gin.Context){ u := User{} c.BindWith(\u0026amp;u, binding.JSON) c.MustBindWith(\u0026amp;u, binding.JSON) }) 文件上传 单个文件上传 func main() { router := gin.Default() // 可以给Post表单设置内存限制(默认是32MiB) \t// router.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 // 8 MiB \trouter.POST(\u0026#34;/upload\u0026#34;, func(c *gin.Context) { // single file \tfile, _ := c.FormFile(\u0026#34;file\u0026#34;) log.Println(file.Filename) // 上传文件到指定的dst. \t// c.SaveUploadedFile(file, dst) \tc.String(http.StatusOK, fmt.Sprintf(\u0026#34;\u0026#39;%s\u0026#39; uploaded!\u0026#34;, file.Filename)) }) router.Run(\u0026#34;:8080\u0026#34;) } 注意：file.Filename 不应该被信任，需要去除路径信息，并且转换成服务的文件系统规则。\n多个文件上传 func main() { router := gin.Default() // 可以给Post表单设置内存限制(默认是32MiB) \t// router.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 // 8 MiB \trouter.POST(\u0026#34;/upload\u0026#34;, func(c *gin.Context) { // Multipart form \tform, _ := c.MultipartForm() files := form.File[\u0026#34;upload[]\u0026#34;] for _, file := range files { log.Println(file.Filename) // 上传文件到指定的dst. \t// c.SaveUploadedFile(file, dst) \t} c.String(http.StatusOK, fmt.Sprintf(\u0026#34;%d files uploaded!\u0026#34;, len(files))) }) router.Run(\u0026#34;:8080\u0026#34;) } ","date":"2020-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/gin-%E8%8E%B7%E5%8F%96%E8%AF%B7%E6%B1%82%E6%95%B0%E6%8D%AE/","title":"Gin 获取请求数据"},{"content":"Gin 设置全局 Middleware、自定义中间件用法。\n用法 全局中间件 gin.Engine 有一个 Use() 方法，可以设置使用的中间件，在此设置后，此实例下所有路由的请求都会通过此中间件。\nrouter := gin.New() router.Use(gin.Loggter()) 路由中间件 除了设置全局的中间件，还可以根据不同的路由分组使用不同的中间件。\nrouter := gin.New() user := router.Group(\u0026#34;/user\u0026#34;, gin.Logger(), gin.Recovery()) 或者\nrouter := gin.New() user := router.Group(\u0026#34;/user\u0026#34;).Use(gin.Logger(), gin.Recovery()) 单个路由也可以使用这两个方法。\n自定义中间件 Gin 的中间件其实就是一个 HandlerFunc，那么只要我们自己实现一个 HandlerFunc，就可以自定义一个自己的中间件。\n这之中，c.Next 方法为执行后续中间件请求处理的意思。\nfunc Logger() gin.HandlerFunc { return func(c *gin.Context) { t := time.Now() // 设置例子变量 \tc.Set(\u0026#34;example\u0026#34;, \u0026#34;12345\u0026#34;) // request之前 \tc.Next() // request之后 \tlatency := time.Since(t) log.Print(latency) // 接收我们发出的状态 \tstatus := c.Writer.Status() log.Println(status) } } 传递数据 在中间件中，有时需要传递数据到下一个中间件，或者最终的请求方法中，那么可以使用 gin.Context 中提供的方法，将数据放在 gin.Context 中。\n传入数据：\nfunc (c *Context) Set(key string, value interface{}) 取出数据：\nfunc (c *Context) Get(key string) (value interface{}, exists bool) 如果可以确认数据类型，那么可以使用对应类型的方法：\nfunc (c *Context) GetBool(key string) (b bool) func (c *Context) GetDuration(key string) (d time.Duration) func (c *Context) GetFloat64(key string) (f64 float64) func (c *Context) GetInt(key string) (i int) func (c *Context) GetInt64(key string) (i64 int64) func (c *Context) GetString(key string) (s string) func (c *Context) GetStringMap(key string) (sm map[string]interface{}) func (c *Context) GetStringMapString(key string) (sms map[string]string) func (c *Context) GetStringMapStringSlice(key string) (smss map[string][]string) func (c *Context) GetStringSlice(key string) (ss []string) func (c *Context) GetTime(key string) (t time.Time) Gin 内置中间件 以下为 Gin 内置中间件的列表：\nfunc BasicAuth(accounts Accounts) HandlerFunc func BasicAuthForRealm(accounts Accounts, realm string) HandlerFunc func Bind(val interface{}) HandlerFunc // 拦截请求参数并进行绑定 func ErrorLogger() HandlerFunc // 错误日志处理 func ErrorLoggerT(typ ErrorType) HandlerFunc // 自定义类型的错误日志处理 func Logger() HandlerFunc // 日志记录 func LoggerWithConfig(conf LoggerConfig) HandlerFunc func LoggerWithFormatter(f LogFormatter) HandlerFunc func LoggerWithWriter(out io.Writer, notlogged ...string) HandlerFunc func Recovery() HandlerFunc func RecoveryWithWriter(out io.Writer) HandlerFunc func WrapF(f http.HandlerFunc) HandlerFunc // 将http.HandlerFunc包装成中间件 func WrapH(h http.Handler) HandlerFunc // 将http.Handler包装成中间件 使用BasicAuth()中间件 // 模拟一些私人数据 var secrets = gin.H{ \u0026#34;foo\u0026#34;: gin.H{\u0026#34;email\u0026#34;: \u0026#34;foo@bar.com\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;123433\u0026#34;}, \u0026#34;austin\u0026#34;: gin.H{\u0026#34;email\u0026#34;: \u0026#34;austin@example.com\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;666\u0026#34;}, \u0026#34;lena\u0026#34;: gin.H{\u0026#34;email\u0026#34;: \u0026#34;lena@guapa.com\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;523443\u0026#34;}, } func main() { r := gin.Default() // 分组使用 gin.BasicAuth() 中间件 \t// gin.Accounts 是 map[string]string 的别名 \tauthorized := r.Group(\u0026#34;/admin\u0026#34;, gin.BasicAuth(gin.Accounts{ \u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;austin\u0026#34;: \u0026#34;1234\u0026#34;, \u0026#34;lena\u0026#34;: \u0026#34;hello2\u0026#34;, \u0026#34;manu\u0026#34;: \u0026#34;4321\u0026#34;, })) // /admin/secrets 端点 \t// 点击 \u0026#34;localhost:8080/admin/secrets \tauthorized.GET(\u0026#34;/secrets\u0026#34;, func(c *gin.Context) { // get user, it was set by the BasicAuth middleware \tuser := c.MustGet(gin.AuthUserKey).(string) if secret, ok := secrets[user]; ok { c.JSON(http.StatusOK, gin.H{\u0026#34;user\u0026#34;: user, \u0026#34;secret\u0026#34;: secret}) } else { c.JSON(http.StatusOK, gin.H{\u0026#34;user\u0026#34;: user, \u0026#34;secret\u0026#34;: \u0026#34;NO SECRET :(\u0026#34;}) } }) r.Run(\u0026#34;:8080\u0026#34;) } 在中间件中使用协程 当在 middleware 或者 handler 中开启一个新的协程时，你不能再在其中使用原版的 context，只能使用只读的拷贝内容。\nfunc main() { r := gin.Default() r.GET(\u0026#34;/long_async\u0026#34;, func(c *gin.Context) { // 创建在协程中使用的copy \tcCp := c.Copy() go func() { // 用休眠5秒来模拟一个长任务 \ttime.Sleep(5 * time.Second) // 注意：你正在使用一个拷贝的context \tlog.Println(\u0026#34;Done! in path \u0026#34; + cCp.Request.URL.Path) }() }) r.GET(\u0026#34;/long_sync\u0026#34;, func(c *gin.Context) { // 用休眠5秒来模拟一个长任务 \ttime.Sleep(5 * time.Second) // 如果我们不使用协程，那么就不需要拷贝 context \tlog.Println(\u0026#34;Done! in path \u0026#34; + c.Request.URL.Path) }) r.Run(\u0026#34;:8080\u0026#34;) } ","date":"2020-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/gin-%E8%AE%BE%E7%BD%AE-middleware-%E4%B8%AD%E9%97%B4%E4%BB%B6/","title":"Gin 设置 Middleware 中间件"},{"content":"Gin 设置请求方式与路由，包括重定向、动态路由、路由分组等。\n请求 请求 func main() { router := gin.Default() router.GET(\u0026#34;/someGet\u0026#34;, getting) router.POST(\u0026#34;/somePost\u0026#34;, posting) router.PUT(\u0026#34;/somePut\u0026#34;, putting) router.DELETE(\u0026#34;/someDelete\u0026#34;, deleting) router.PATCH(\u0026#34;/somePatch\u0026#34;, patching) router.HEAD(\u0026#34;/someHead\u0026#34;, head) router.OPTIONS(\u0026#34;/someOptions\u0026#34;, options) router.Any(\u0026#34;/anyRequest\u0026#34;, options) // 可以处理任何类型请求  router.Run(\u0026#34;:3000\u0026#34;) } 默认情况下 gin 会把服务运行在 8080 端口，除非定义了 PORT 环境变量。\n除此之外，也可以使用 Handle() 创建路由，通过指定 Handle() 函数的第一个参数来确定处理何种请求：\nrouter.Handle(\u0026#34;POST\u0026#34;,\u0026#34;/testHandlePost\u0026#34;,func(c *gin.Context){}) 拦截请求 在中间件或请求方法中，当用户请求不合法时，可以中断用户的请求。\nfunc (c *Context) Abort() func (c *Context) AbortWithError(code int, err error) *Error func (c *Context) AbortWithStatus(code int) func (c *Context) AbortWithStatusJSON(code int, jsonObj interface{}) 重定向 发布一个 HTTP 重定向非常简单，而且支持外部和内部地址。\nr.GET(\u0026#34;/test\u0026#34;, func(c *gin.Context) { c.Redirect(http.StatusMovedPermanently, \u0026#34;http://www.google.com/\u0026#34;) }) 内部重定向，使用 HandleContext 。\nr.GET(\u0026#34;/test\u0026#34;, func(c *gin.Context) { c.Request.URL.Path = \u0026#34;/test2\u0026#34; r.HandleContext(c) }) r.GET(\u0026#34;/test2\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{\u0026#34;hello\u0026#34;: \u0026#34;world\u0026#34;}) }) 路由 动态路由 除了直接匹配路径，Gin 框架还支持使用通配符冒号 : 和星号 * 来匹配请求路径。\n  精确匹配\nrouter.GET(\u0026#34;user/:name\u0026#34;,func(c *gin.Context){}) // /user/gordon 匹配 // /user/you 匹配 // /user/gordon/profile 不匹配 // /user/ 不匹配   模糊匹配\nrouter.GET(\u0026#34;user/*name\u0026#34;,func(c *gin.Context){}) // /user/gordon 匹配 /gordon // /user/you 匹配 /you // /user/gordon/profile 匹配 /gordon/profile // /user/ 匹配 /   注意：Gin 的路由是单一不可重复的。\n注意：对于模糊匹配，不建议使用，因为匹配的太多，会导致我们自己搞不清楚哪些路由被注册了。\n路由分组 router := gin.Default() // 组: v1 v1 := router.Group(\u0026#34;/v1\u0026#34;) { v1.POST(\u0026#34;/login\u0026#34;, loginEndpoint) v1.POST(\u0026#34;/submit\u0026#34;, submitEndpoint) v1.POST(\u0026#34;/read\u0026#34;, readEndpoint) } // 组: v2 v2 := router.Group(\u0026#34;/v2\u0026#34;) { v2.POST(\u0026#34;/login\u0026#34;, loginEndpoint) v2.POST(\u0026#34;/submit\u0026#34;, submitEndpoint) v2.POST(\u0026#34;/read\u0026#34;, readEndpoint) } ","date":"2020-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/gin-%E8%AF%B7%E6%B1%82%E4%B8%8E%E8%B7%AF%E7%94%B1/","title":"Gin 请求与路由"},{"content":"Gin 框架在 *gin.Context 实例中封装了所有处理请求并响应客户端的方法。\nGin 支持多种响应方法，包括我们常见的 String、HTML、JSON、XML、YAML、JSONP，也支持直接响应 Reader 和 []byte，而且还支持重定向。\n以下为 gin.Context 中响应客户端的方法列表：\nfunc (c *Context) Data(code int, contentType string, data []byte) func (c *Context) DataFromReader(code int, contentLength int64, contentType string, reader io.Reader, extraHeaders map[string]string) func (c *Context) HTML(code int, name string, obj interface{}) func (c *Context) ProtoBuf(code int, obj interface{}) func (c *Context) Redirect(code int, location string) func (c *Context) Render(code int, r render.Render) func (c *Context) String(code int, format string, values ...interface{}) func (c *Context) XML(code int, obj interface{}) func (c *Context) YAML(code int, obj interface{}) JSON 返回 Json 响应数据的几种方法：\n// 返回普通 JSON 数据 func (c *Context) JSON(code int, obj interface{}) // 基于 JSON，解决浏览器跨域访问问题 func (c *Context) JSONP(code int, obj interface{}) // 按字面对字符进行编码，不使用 unicode 替换特殊 HTML 字符转义 func (c *Context) PureJSON(code int, obj interface{}) // 把非 Ascii 字符串转为 unicode 编码 func (c *Context) AsciiJSON(code int, obj interface{}) // 防止 JSON 劫持 func (c *Context) SecureJSON(code int, obj interface{}) // 返回缩进美化后的 JSON 数据 func (c *Context) IndentedJSON(code int, obj interface{}) 返回的内容可以是 gin.H，也可以是一个 struct，gin.H 是 map[string]interface{} 的一种快捷方式。\n使用 struct 时，需要设置 tag，与正常的 Json Tag 一致。\nvar msg struct { Name string `json:\u0026#34;user\u0026#34;` Message string Number int } JSON 返回普通 JSON 数据\nr.GET(\u0026#34;/someJSON\u0026#34;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;hey\u0026#34;, \u0026#34;status\u0026#34;: http.StatusOK }) }) r.GET(\u0026#34;/moreJSON\u0026#34;, func(c *gin.Context) { var msg struct { // 使用一个结构体  Name string `json:\u0026#34;user\u0026#34;` Message string Number int } msg.Name = \u0026#34;Lena\u0026#34; msg.Message = \u0026#34;hey\u0026#34; msg.Number = 123 // 注意 msg.Name 在 JSON 中变成了 \u0026#34;user\u0026#34;  // 将输出：{\u0026#34;user\u0026#34;: \u0026#34;Lena\u0026#34;, \u0026#34;Message\u0026#34;: \u0026#34;hey\u0026#34;, \u0026#34;Number\u0026#34;: 123}  c.JSON(http.StatusOK, msg) }) JSONP JSONP 是一种基于 JSON，而用于解决浏览器跨域访问问题的机制，使用gin.Context 的 JSONP() 返回数据时，会将 URL 中的 callback 参数按照 JSONP 的数据格式放在 json 数据前面，并返回给客户端。\nr.GET(\u0026#34;/JSONP\u0026#34;, func(c *gin.Context) { data := map[string]interface{}{ \u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;, } // /JSONP?callback=x  // 将输出：x({\\\u0026#34;foo\\\u0026#34;:\\\u0026#34;bar\\\u0026#34;})  c.JSONP(http.StatusOK, data) }) PureJSON 通常，JSON 使用 unicode 替换特殊 HTML 字符，例如 \u0026lt; 变为 \\u003c。如果要按字面对这些字符进行编码，不进行转义，则可以使用 PureJSON。\n// 提供字面字符 r.GET(\u0026#34;/purejson\u0026#34;, func(c *gin.Context) { c.PureJSON(200, gin.H{ \u0026#34;html\u0026#34;: \u0026#34;\u0026lt;b\u0026gt;Hello, world!\u0026lt;/b\u0026gt;\u0026#34;, }) }) AsciiJSON 把所有的非 Ascii 字符全部转义为 unicode 编码。\nr.GET(\u0026#34;/someJSON\u0026#34;, func(c *gin.Context) { data := map[string]interface{}{ \u0026#34;lang\u0026#34;: \u0026#34;GO语言\u0026#34;, \u0026#34;tag\u0026#34;: \u0026#34;\u0026lt;br\u0026gt;\u0026#34;, } // 输出 : {\u0026#34;lang\u0026#34;:\u0026#34;GO\\u8bed\\u8a00\u0026#34;,\u0026#34;tag\u0026#34;:\u0026#34;\\u003cbr\\u003e\u0026#34;}  c.AsciiJSON(http.StatusOK, data) }) SecureJSON 防止 json 劫持。如果给定的结构是数组值，则默认预置 \u0026quot;while(1),\u0026quot; 到响应体。\n// 你也可以使用自己的 SecureJSON 前缀 // r.SecureJsonPrefix(\u0026#34;)]}\u0026#39;,\\n\u0026#34;) r.GET(\u0026#34;/someJSON\u0026#34;, func(c *gin.Context) { names := []string{\u0026#34;lena\u0026#34;, \u0026#34;austin\u0026#34;, \u0026#34;foo\u0026#34;} // 将输出：while(1);[\u0026#34;lena\u0026#34;,\u0026#34;austin\u0026#34;,\u0026#34;foo\u0026#34;]  c.SecureJSON(http.StatusOK, names) }) IndentedJSON 返回缩进美化后的 JSON 数据。\nr.GET(\u0026#34;/users/456\u0026#34;, func(c *gin.Context) { c.IndentedJSON(200, user{ID: 456, Name: \u0026#34;李四\u0026#34;, Age: 25}) }) // 输出： // { // \u0026#34;id\u0026#34;: 456, // \u0026#34;name\u0026#34;: \u0026#34;李四\u0026#34;, // \u0026#34;age\u0026#34;: 25 // } 加速 JSON 编码 在 Gin 中，提供了两种 JSON 解析器，用于生成 JSON 字符串。默认的是 Go 内置的 JSON。\n也可以使用 jsoniter，速度很快。如果要使用 jsoniter，我们在 go build 编译的时候只需要这么做即可：\n$ go build -tags=jsoniter . HTML渲染 使用 LoadHTMLGlob() 或者 LoadHTMLFiles()。\nfunc main() { router := gin.Default() router.LoadHTMLGlob(\u0026#34;templates/*\u0026#34;) //router.LoadHTMLFiles(\u0026#34;templates/template1.html\u0026#34;, \u0026#34;templates/template2.html\u0026#34;) \trouter.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;index.tmpl\u0026#34;, gin.H{ \u0026#34;title\u0026#34;: \u0026#34;Main website\u0026#34;, }) }) router.Run(\u0026#34;:8080\u0026#34;) } templates/index.tmpl\n\u0026lt;html\u0026gt; \u0026lt;h1\u0026gt; {{ .title }} \u0026lt;/h1\u0026gt; \u0026lt;/html\u0026gt; 在不同的目录里使用相同名字的模板\nfunc main() { router := gin.Default() router.LoadHTMLGlob(\u0026#34;templates/**/*\u0026#34;) router.GET(\u0026#34;/posts/index\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;posts/index.tmpl\u0026#34;, gin.H{ \u0026#34;title\u0026#34;: \u0026#34;Posts\u0026#34;, }) }) router.GET(\u0026#34;/users/index\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;users/index.tmpl\u0026#34;, gin.H{ \u0026#34;title\u0026#34;: \u0026#34;Users\u0026#34;, }) }) router.Run(\u0026#34;:8080\u0026#34;) } templates/posts/index.tmpl\n{{ define \u0026#34;posts/index.tmpl\u0026#34; }} \u0026lt;html\u0026gt;\u0026lt;h1\u0026gt; {{ .title }} \u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Using posts/index.tmpl\u0026lt;/p\u0026gt; \u0026lt;/html\u0026gt; {{ end }} templates/users/index.tmpl\n{{ define \u0026#34;users/index.tmpl\u0026#34; }} \u0026lt;html\u0026gt;\u0026lt;h1\u0026gt; {{ .title }} \u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Using users/index.tmpl\u0026lt;/p\u0026gt; \u0026lt;/html\u0026gt; {{ end }} 自定义模板渲染器 import \u0026#34;html/template\u0026#34; func main() { router := gin.Default() html := template.Must(template.ParseFiles(\u0026#34;file1\u0026#34;, \u0026#34;file2\u0026#34;)) router.SetHTMLTemplate(html) router.Run(\u0026#34;:8080\u0026#34;) } 自定义分隔符 r := gin.Default() r.Delims(\u0026#34;{[{\u0026#34;, \u0026#34;}]}\u0026#34;) r.LoadHTMLGlob(\u0026#34;/path/to/templates\u0026#34;) 自定义模板功能 main.go\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func formatAsDate(t time.Time) string { year, month, day := t.Date() return fmt.Sprintf(\u0026#34;%d%02d/%02d\u0026#34;, year, month, day) } func main() { router := gin.Default() router.Delims(\u0026#34;{[{\u0026#34;, \u0026#34;}]}\u0026#34;) router.SetFuncMap(template.FuncMap{ \u0026#34;formatAsDate\u0026#34;: formatAsDate, }) router.LoadHTMLFiles(\u0026#34;./testdata/template/raw.tmpl\u0026#34;) router.GET(\u0026#34;/raw\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;raw.tmpl\u0026#34;, gin.H{ \u0026#34;now\u0026#34;: time.Date(2017, 07, 01, 0, 0, 0, 0, time.UTC), }) }) router.Run(\u0026#34;:8080\u0026#34;) } raw.tmpl\nDate: {[{.now | formatAsDate}]} 结果：\nDate: 2017/07/01 ","date":"2020-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/gin-%E8%BF%94%E5%9B%9E%E5%93%8D%E5%BA%94%E6%96%B9%E5%BC%8F/","title":"Gin 返回响应方式"},{"content":"此包用于自动化生成 API 文档。\n下载 swag 工具：\n$ go get -u github.com/swaggo/swag/cmd/swag 下载 gin-swagger 库：\n$ go get -u github.com/swaggo/gin-swagger $ go get -u github.com/swaggo/files 使用 启用文档   首先需要在项目代码中根据需求编写相应的注释。\n  使用 swag 生成 swagger 所需的 Json 文件。\n$ swag init 此命令会在当前目录下生成 docs 目录以及里面的部分文件。\n  在项目的 main.go 文件中配置 swagger 的启用方式。\nimport ( \u0026#34;github.com/gin-gonic/gin\u0026#34; swaggerFiles \u0026#34;github.com/swaggo/files\u0026#34; ginSwagger \u0026#34;github.com/swaggo/gin-swagger\u0026#34; \u0026#34;projectName/docs\u0026#34; ) func main() { r := gin.New() r.GET(\u0026#34;/swagger/*any\u0026#34;, ginSwagger.WrapHandler(swaggerFiles.Handler)) r.Run() }   启动后，就可以在 http://localhost:8080/swagger/index.html 看到 API 文档了。\n  禁用文档 很多时候我们不需要开启文档，这时候可以使用 DisablingWrapHandler。\nr.GET(\u0026#34;/swagger/*any\u0026#34;, ginSwagger.DisablingWrapHandler(swaggerFiles.Handler, \u0026#34;NAME_OF_ENV_VARIABLE\u0026#34;)) 只要在运行程序前，将 NAME_OF_ENV_VARIABLE 环境变量设置成任何值，都将会禁用 Swagger 文档。\nAPI 整体文档 此注释用于声明整个 API 文档的信息，注释的位置在项目的 main 函数位置\n// @title Swagger Example API // @version 1.0 // @description This is a sample server celler server. // @termsOfService http://swagger.io/terms/ func main() {} 字段    字段名 说明 示例     @title 必填 应用程序的名称 Swagger Example API   @version 必填 提供应用程序API的版本 1.0   @description 应用程序的简短描述 This is a sample server celler server.   @tag.name 标签的名称 This is the name of the tag   @tag.description 标签的描述 Cool Description   @tag.docs.url 标签的外部文档的URL https://example.com   @tag.docs.description 标签的外部文档说明 Best example documentation   @termsOfService API的服务条款 http://swagger.io/terms/   @contact.name 公开的API的联系信息 API Support   @contact.url 联系信息的URL，必须采用网址格式 http://www.swagger.io/support   @contact.email 联系人/组织的电子邮件地址。 必须采用电子邮件地址的格式 support@swagger.io   @license.name 必填 用于API的许可证名称 Apache 2.0   @license.url 用于API的许可证的URL，必须采用网址格式 http://www.apache.org/licenses/LICENSE-2.0.html   @host 运行API的主机（主机名或IP地址） localhost:8080   @BasePath 运行API的基本路径 /api/v1   @query.collection.format 请求URI query里数组参数的默认格式：csv，multi，pipes，tsv，ssv。 如果未设置，则默认为csv multi   @schemes 用空格分隔的请求的传输协议 http https   @x-name 扩展的键必须以x-开头，并且只能使用json值 {\u0026ldquo;key\u0026rdquo;: \u0026ldquo;value\u0026rdquo;}    Markdown 如果文档中的短字符串不足以完整表达，或者需要展示图片，代码示例等类似的内容，则需要使用 Markdown 描述。\n   字段名 说明     @description.markdown API 的简短描述，从 api.md 文件中解析   @tag.name tag 的名称   @tag.description.markdown tag 的描述，该描述将从名为 tagname.md 的文件中读取    API 接口文档 此注释用于声明单个 API 接口的信息，注释的位置在具体的 controller 函数位置\n// FindUserByName 查询用户信息 // // @Summary 查询用户信息 // @Description 根据用户名查询用户信息 // @Tags 用户接口 // @Accept application/x-www-form-urlencoded // @Produce application/json // @Param name path string true \u0026#34;用户账户名\u0026#34; // @Success 200 {object} response.BasicResponse \u0026#34;基础响应类型\u0026#34; // @Router /user/{name} [get] func FindUserByName(c *gin.Context) {} 字段    字段名 描述     @summary API 行为的简短摘要   @description API 行为的详细说明   @description.markdown API 行为的详细说明，从 endpointname.md 文件中读取   @id 用于标识 API 的唯一字符串，在所有 API 中必须唯一   @tags 每个 API 操作的 tag 列表，以逗号分隔   @accept API 可以接收的 MIME 类型的列表   @produce API 可以返回的 MIME 类型的列表   @param API 可以接收的参数   @security API 操作的安全性。   @success 访问 API 成功的响应内容   @failure 访问 API 失败的响应内容   @response 与 success、failure 作用相同   @header 头字段   @router 此 API 的路由路径   @x-name 扩展字段，必须以 x- 开头，并且只能使用 json 值    MIME 类型 swag 接受所有格式正确的 MIME 类型, 即使匹配 */*。\n除此之外，swag 还接受某些 MIME 类型的别名，如下所示：\n   别名 MIME 类型     json application/json   xml text/xml   plain text/plain   html text/html   mpfd multipart/form-data   x-www-form-urlencoded application/x-www-form-urlencoded   json-api application/vnd.api+json   json-stream application/x-json-stream   octet-stream application/octet-stream   png image/png   jpeg image/jpeg   gif image/gif    response 声明响应，主要有 success, failure, response 三类，格式一致：\n@Success {return code} {param type} {data type} comment @Failure {return code} {param type} {data type} comment @Response {return code} {param type} {data type} comment @Header {return code} {param type} {data type} comment 示例：\n@Success 200 {array} model.Account @Header 200 {string} Token \u0026#34;qwerty\u0026#34; @Failure 400,404 {object} httputil.HTTPError @Failure 500 {object} httputil.HTTPError @Failure default {object} httputil.DefaultError router 声明 API 的路由:\n@Router path [httpMethod] 多路径参数:\n@Param group_id path int true \u0026#34;Group ID\u0026#34; @Param account_id path int true \u0026#34;Account ID\u0026#34; @Router /examples/groups/{group_id}/accounts/{account_id} [get] Param 此字段用于声明 API 接收的数据字段，用空格分隔，如下所示：\n@param name param_type data_type is_mandatory comment attribute(optional) 示例：\n@Param enumstring query string false \u0026#34;string enums\u0026#34; Enums(A, B, C) @Param enumint query int false \u0026#34;int enums\u0026#34; Enums(1, 2, 3) @Param enumnumber query number false \u0026#34;int enums\u0026#34; Enums(1.1, 1.2, 1.3) @Param string query string false \u0026#34;string valid\u0026#34; minlength(5) maxlength(10) @Param int query int false \u0026#34;int valid\u0026#34; minimum(1) maximum(10) @Param default query string false \u0026#34;string default\u0026#34; default(A) @Param collection query []string false \u0026#34;string collection\u0026#34; collectionFormat(multi) 直接声明  name - 字段名 param_type - 字段类型，说明此字段的类型  query - url 参数中的字段 path - url 路径中的字段 header - 请求头 formData - post 表单类型字段 body - 请求体中的内容   data_tape - 字段的数据类型  string (string) integer (int, uint, uint32, uint64) number (float32) boolean (bool) user defined struct   is_mandatory - 此字段是否是必须的 comment - 注释，通常是字段的描述 attribute - 额外的属性，此部分为可选  attribute 直接声明中的字段都是必须字段，而 attribute 有部分额外功能\n   字段名 类型 描述     default * 服务器将使用的默认参数值   maximum number int 最大值   minimum number int 最小值   maxLength integer 字符串最大长度   minLength integer 字符串最小长度   enums [*] 枚举类型   format string 格式   collectionFormat string 指定query数组参数的格式     注1：default 对于必需的参数没有意义 注2：与 JSON 模式不同，default 务必符合此参数的定义类型  结构体字段 逐个编写 Param，Response 等字段是非常麻烦的，且不利于维护，所以通常使用 Struct 来定义字段的类型。\ntype JSONResult struct { Code int `json:\u0026#34;code\u0026#34; ` // ID this is userid  Message string `json:\u0026#34;message\u0026#34;` // This is Name  Data interface{} `json:\u0026#34;data\u0026#34;` } type Order struct { //in `proto` package  ... } @param result formData jsonresult.JSONResult{data=proto.Order} true \u0026#34;登录参数\u0026#34; @success 200 {object} jsonresult.JSONResult{data=proto.Order} \u0026#34;desc\u0026#34; @success 200 {object} jsonresult.JSONResult{data=[]proto.Order} \u0026#34;desc\u0026#34; @success 200 {object} jsonresult.JSONResult{data=string} \u0026#34;desc\u0026#34; @success 200 {object} jsonresult.JSONResult{data=[]string} \u0026#34;desc\u0026#34;  struct 字段后方的注释，会被读取为这个字段的描述  Tag 在使用 struct 作为数据的定义时，主要使用 struct 的 tag 作为声明的方式。\n   Tag 描述 示例     example 声明字段示例值 example:\u0026ldquo;account name\u0026rdquo;   binding 声明字段为必须 binding:\u0026ldquo;required\u0026rdquo;   swaggertype 重新声明字段类型 swaggertype:\u0026ldquo;array,number\u0026rdquo;   swaggerignore 不展示某些字段 swaggerignore:\u0026ldquo;true\u0026rdquo;   extensions 扩展信息 extensions:\u0026ldquo;x-nullable,x-abc=def\u0026rdquo;     除此之外，还包括 Param 的 Attribute 也可以使用到 Tag 中。  重命名模型 在展示时更改模型名称\ntype Resp struct { Code int }//@name Response ","date":"2020-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/gin-%E9%85%8D%E7%BD%AE-swagger-%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/","title":"Gin 配置 Swagger 接口文档"},{"content":"Gin 提供的日志功能和部分其他功能，包括：优雅关闭或重启、提供静态文件、http2 服务推送、自定义验证器、设置和获取 Cookies、从 reader 提供数据。\n日志 日志文件 func main() { // 禁用控制台颜色，写入日志文件时不需要颜色.  gin.DisableConsoleColor() // 设置日志文件  f, _ := os.Create(\u0026#34;gin.log\u0026#34;) gin.DefaultWriter = io.MultiWriter(f) // 如果希望同时将日志输出到控制台和文件，使用以下代码  // gin.DefaultWriter = io.MultiWriter(f, os.Stdout)  router := gin.Default() router.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.String(200, \u0026#34;pong\u0026#34;) }) router.Run(\u0026#34;:8080\u0026#34;) } 自定义日志格式 func main() { router := gin.New() // LoggerWithFormatter 中间件会将日志写入到 gin.DefaultWriter \t// 默认情况下 gin.DefaultWriter = os.Stdout \trouter.Use(gin.LoggerWithFormatter(func(param gin.LogFormatterParams) string { // 自定义格式 \treturn fmt.Sprintf(\u0026#34;%s - [%s] \\\u0026#34;%s %s %s %d %s \\\u0026#34;%s\\\u0026#34; %s\\\u0026#34;\\n\u0026#34;, param.ClientIP, param.TimeStamp.Format(time.RFC1123), param.Method, param.Path, param.Request.Proto, param.StatusCode, param.Latency, param.Request.UserAgent(), param.ErrorMessage, ) })) router.Use(gin.Recovery()) router.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.String(200, \u0026#34;pong\u0026#34;) }) router.Run(\u0026#34;:8080\u0026#34;) } 控制日志输出颜色 默认情况下，输出到控制台的日志会按照检测到的TTY进行着色。\n禁用彩色日志：\nfunc main() { // 禁用日志颜色  gin.DisableConsoleColor() router := gin.Default() router.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.String(200, \u0026#34;pong\u0026#34;) }) router.Run(\u0026#34;:8080\u0026#34;) } 强制启用彩色日志：\nfunc main() { // 强制启用日志颜色  gin.ForceConsoleColor() router := gin.Default() router.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.String(200, \u0026#34;pong\u0026#34;) }) router.Run(\u0026#34;:8080\u0026#34;) } 其他功能 设置和获取 cookie import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { router := gin.Default() router.GET(\u0026#34;/cookie\u0026#34;, func(c *gin.Context) { cookie, err := c.Cookie(\u0026#34;gin_cookie\u0026#34;) if err != nil { cookie = \u0026#34;NotSet\u0026#34; c.SetCookie(\u0026#34;gin_cookie\u0026#34;, \u0026#34;test\u0026#34;, 3600, \u0026#34;/\u0026#34;, \u0026#34;localhost\u0026#34;, false, true) } fmt.Printf(\u0026#34;Cookie value: %s \\n\u0026#34;, cookie) }) router.Run() } 自定义验证器 注册自定义验证器也是可行的。\npackage main import ( \u0026#34;net/http\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/gin-gonic/gin/binding\u0026#34; \u0026#34;gopkg.in/go-playground/validator.v8\u0026#34; ) // Booking 包含绑定和验证的数据 type Booking struct { CheckIn time.Time `form:\u0026#34;check_in\u0026#34; binding:\u0026#34;required,bookabledate\u0026#34; time_format:\u0026#34;2006-01-02\u0026#34;` CheckOut time.Time `form:\u0026#34;check_out\u0026#34; binding:\u0026#34;required,gtfield=CheckIn\u0026#34; time_format:\u0026#34;2006-01-02\u0026#34;` } func bookableDate( v *validator.Validate, topStruct reflect.Value, currentStructOrField reflect.Value, field reflect.Value, fieldType reflect.Type, fieldKind reflect.Kind, param string, ) bool { if date, ok := field.Interface().(time.Time); ok { today := time.Now() if today.Year() \u0026gt; date.Year() || today.YearDay() \u0026gt; date.YearDay() { return false } } return true } func main() { route := gin.Default() if v, ok := binding.Validator.Engine().(*validator.Validate); ok { v.RegisterValidation(\u0026#34;bookabledate\u0026#34;, bookableDate) } route.GET(\u0026#34;/bookable\u0026#34;, getBookable) route.Run(\u0026#34;:8085\u0026#34;) } func getBookable(c *gin.Context) { var b Booking if err := c.ShouldBindWith(\u0026amp;b, binding.Query); err == nil { c.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;Booking dates are valid!\u0026#34;}) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } } $ curl \u0026#34;localhost:8085/bookable?check_in=2018-04-16\u0026amp;check_out=2018-04-17\u0026#34; {\u0026#34;message\u0026#34;:\u0026#34;Booking dates are valid!\u0026#34;} $ curl \u0026#34;localhost:8085/bookable?check_in=2018-03-08\u0026amp;check_out=2018-03-09\u0026#34; {\u0026#34;error\u0026#34;:\u0026#34;Key: \u0026#39;Booking.CheckIn\u0026#39; Error:Field validation for \u0026#39;CheckIn\u0026#39; failed on the \u0026#39;bookabledate\u0026#39; tag\u0026#34;} 优雅关闭或重启 考虑使用 http.Server 的内建方法 Shutdown() 来优雅的关闭。\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { router := gin.Default() router.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { time.Sleep(5 * time.Second) c.String(http.StatusOK, \u0026#34;Welcome Gin Server\u0026#34;) }) srv := \u0026amp;http.Server{ Addr: \u0026#34;:8080\u0026#34;, Handler: router, } go func() { // service connections \tif err := srv.ListenAndServe(); err != nil \u0026amp;\u0026amp; err != http.ErrServerClosed { log.Fatalf(\u0026#34;listen: %s\\n\u0026#34;, err) } }() // 等待超时五秒的中断信号，优雅的关闭服务 \tquit := make(chan os.Signal) // kill (no param) default send syscall.SIGTERM \t// kill -2 is syscall.SIGINT \t// kill -9 is syscall.SIGKILL but can\u0026#39;t be catch, so don\u0026#39;t need add it \tsignal.Notify(quit, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-quit log.Println(\u0026#34;Shutdown Server ...\u0026#34;) ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() if err := srv.Shutdown(ctx); err != nil { log.Fatal(\u0026#34;Server Shutdown:\u0026#34;, err) } // catching ctx.Done(). timeout of 5 seconds. \tselect { case \u0026lt;-ctx.Done(): log.Println(\u0026#34;timeout of 5 seconds.\u0026#34;) } log.Println(\u0026#34;Server exiting\u0026#34;) } 提供静态文件 func main() { router := gin.Default() router.Static(\u0026#34;/assets\u0026#34;, \u0026#34;./assets\u0026#34;) router.StaticFS(\u0026#34;/more_static\u0026#34;, http.Dir(\u0026#34;my_file_system\u0026#34;)) router.StaticFile(\u0026#34;/favicon.ico\u0026#34;, \u0026#34;./resources/favicon.ico\u0026#34;) router.Run(\u0026#34;:8080\u0026#34;) } 从 reader 提供数据 func main() { router := gin.Default() router.GET(\u0026#34;/someDataFromReader\u0026#34;, func(c *gin.Context) { response, err := http.Get(\u0026#34;https://raw.githubusercontent.com/gin-gonic/logo/master/color.png\u0026#34;) if err != nil || response.StatusCode != http.StatusOK { c.Status(http.StatusServiceUnavailable) return } reader := response.Body contentLength := response.ContentLength contentType := response.Header.Get(\u0026#34;Content-Type\u0026#34;) extraHeaders := map[string]string{ \u0026#34;Content-Disposition\u0026#34;: `attachment; filename=\u0026#34;gopher.png\u0026#34;`, } c.DataFromReader(http.StatusOK, contentLength, contentType, reader, extraHeaders) }) router.Run(\u0026#34;:8080\u0026#34;) } http2 服务推送 package main import ( \u0026#34;html/template\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) var html = template.Must(template.New(\u0026#34;https\u0026#34;).Parse(` \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Https Test\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;/assets/app.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1 style=\u0026#34;color:red;\u0026#34;\u0026gt;Welcome, Ginner!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; `)) func main() { r := gin.Default() r.Static(\u0026#34;/assets\u0026#34;, \u0026#34;./assets\u0026#34;) r.SetHTMLTemplate(html) r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { if pusher := c.Writer.Pusher(); pusher != nil { // 使用 pusher.Push() 来做服务推送 \tif err := pusher.Push(\u0026#34;/assets/app.js\u0026#34;, nil); err != nil { log.Printf(\u0026#34;Failed to push: %v\u0026#34;, err) } } c.HTML(200, \u0026#34;https\u0026#34;, gin.H{ \u0026#34;status\u0026#34;: \u0026#34;success\u0026#34;, }) }) r.RunTLS(\u0026#34;:8080\u0026#34;, \u0026#34;./testdata/server.pem\u0026#34;, \u0026#34;./testdata/server.key\u0026#34;) } ","date":"2020-08-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/gin-%E9%AB%98%E7%BA%A7%E5%8A%9F%E8%83%BD/","title":"Gin 高级功能"},{"content":"context 指的是上下文，以下是几种 ctx 类型:\n emptyCtx - 所有 ctx 类型的根，用 context.TODO()，或 context.Background() 来生成。 valueCtx - 主要就是为了在 ctx 中嵌入上下文数据，一个简单的 k 和 v 结构，同一个 ctx 内只支持一对 kv，需要更多的 kv 的话，会形成一棵树形结构。 cancelCtx - 用来取消程序的执行树，一般用 WithCancel，WithTimeout，WithDeadline 返回的取消函数本质上都是对应了 cancelCtx。 timerCtx - 在 cancelCtx 上包了一层，支持基于时间的 cancel。  用法 初始化 context 一般使用 context.TODO() 和 context.Background() 创建 context，是所有 context 的根，todo 和 background 两者本质上只有名字区别，在按 string 输出的时候会有区别。\nvalueCtx valueCtx 主要就是用来携带贯穿整个逻辑流程的数据，使用 WithValue 创建。\ntype orderID int var x = context.TODO() x = context.WithValue(x, orderID(1), \u0026#34;1234\u0026#34;) x = context.WithValue(x, orderID(2), \u0026#34;2345\u0026#34;) x = context.WithValue(x, orderID(3), \u0026#34;3456\u0026#34;) key 必须为非空，且可比较。\n在查找值，即执行 Value 操作时，会先判断当前节点的 k 是不是等于用户的输入 k，如果相等，返回结果，如果不等，会依次向上从子节点向父节点，一直查找到整个 ctx 的根。没有找到返回 nil。是一个递归流程：\nfunc (c *valueCtx) Value(key interface{}) interface{} { if c.key == key { return c.val } return c.Context.Value(key) // 这里发生了递归，c.Context 就是 c.parent } cancelCtx cancelCtx 主要用于协程的控制，例如关闭协程。使用 WithCancel 创建。\nctx, cancelFn := context.WithCancel(context.TODO()) go func() { for { select { case \u0026lt;-jobChan: fmt.Println(\u0026#34;do my job\u0026#34;) case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;parent call me to quit\u0026#34;) break jobLoop } } }() // 停止所有 worker cancelFn() timerCtx timerCtx 用于定时的取消任务。\nctx, cancel := context.WithTimeout(context.Background(), 50*time.Millisecond) defer cancel() select { case \u0026lt;-time.After(1 * time.Second): fmt.Println(\u0026#34;overslept\u0026#34;) case \u0026lt;-ctx.Done(): fmt.Println(ctx.Err()) // prints \u0026#34;context deadline exceeded\u0026#34; } ","date":"2020-06-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E4%B8%8A%E4%B8%8B%E6%96%87-context/","title":"Go 上下文 context"},{"content":"反射是程序在运行期间检查其自身结构的一种方式 。\n反射三大法则：\n 反射可以将接口类型变量转换为反射类型对象 反射可以将反射类型对象转换为接口类型变量 如果要修改反射类型对象，其值必须是可写的(settable)  Type Type 表示的是对象的具体类型。\n从普通类型变量获取反射类型 Type：\nfunc TypeOf(i interface{}) Type 其他方法：\nfunc ChanOf(dir ChanDir, t Type) Type func FuncOf(in, out []Type, variadic bool) Type func MapOf(key, elem Type) Type func SliceOf(t Type) Type func ArrayOf(count int, elem Type) Type func StructOf(fields []StructField) Type Type 本身是一个 reflect 库暴露出的接口，定义了许多方法，但根据其本身的具体类型，可以使用的方法并不相同。\n方法 // 只返回类型名，不含包名 Name() string // 返回类型名字，为包名 + Name() String() string // 返回导入路径，即 import 路径 PkgPath() string // 返回 rtype.size 即类型大小，单位是字节数 Size() uintptr // 返回 rtype.kind，描述一种基础类型 Kind() Kind // 返回类型的位大小，但不是所有类型都能调这个方法，不能调的会 panic Bits() int // 检查当前类型能不能做比较运算，主要根据此类型底层有没有绑定 typeAlg 的 equal 方法。 Comparable() bool // 变量的内存对齐，返回 rtype.align Align() int Struct // 返回 struct 字段数量，不是 struct 会 panic NumField() int // 返回 struct 类型的第 i 个字段，不是 struct 会 panic，i 越界也会 panic Field(i int) StructField // 返回 struct 类型的字段，是嵌套调用，比如 [1, 2] 就是返回当前 struct 的第 1 个 struct 的第 2 个字段，适用于 struct 本身嵌套的类型 FieldByIndex(index []int) StructField // 按名字找 struct 字段，第二个返回值 ok 表示有没有 FieldByName(name string) (StructField, bool) // 按函数签名找 struct 字段，因为 struct 字段也可能是 func 类型 FieldByNameFunc(match func(string) bool) (StructField, bool) // 根据传入的 i，返回方法实例，表示类型的第 i 个方法 Method(int) Method // 根据名字返回方法实例，这个比较常用 MethodByName(string) (Method, bool) // 返回类型方法集中可导出的方法的数量 NumMethod() int // struct 字段的内存对齐，返回 rtype.fieldAlign FieldAlign() int 函数 // 返回函数的参数数量，不是 func 会 panic NumIn() int // 返回函数的返回值数量，不是 func 会 panic NumOut() int // 返回函数第 i 个参数的类型，不是 func 会 panic In(i int) Type // 返回函数第 i 个返回值的类型，不是 func 会 panic Out(i int) Type // 返回函数类型的最后一个参数是不是可变数量的，\u0026#34;...\u0026#34; 就这样的，同样，如果不是函数类型，会 panic IsVariadic() bool Interface // 检查当前类型有没有实现接口 u Implements(u Type) bool // 检查当前类型能不能赋值给接口 u AssignableTo(u Type) bool // 检查当前类型能不能转换成接口 u 类型 ConvertibleTo(u Type) bool 基础数据类型 // 返回 map 的 key 的类型，不是 map 会 panic Key() Type // 返回 array 的长度，不是 array 会 panic Len() int // 返回 channel 类型的方向，如果不是 channel，会 panic ChanDir() ChanDir // 返回所包含元素的类型，只有 Array, Chan, Map, Ptr, Slice 这些才能调，其他类型会 panic。 Elem() Type Value Value 表示的是对象的值。\n从普通类型变量获取反射值 Value：\nfunc ValueOf(i interface{}) Value 创建 Value 以下这些方法可以创建指定类型的 Value：\nfunc MakeChan(typ Type, buffer int) Value func MakeFunc(typ Type, fn func(args []Value) (results []Value)) Value func MakeMap(typ Type) Value func MakeMapWithSize(typ Type, n int) Value func MakeSlice(typ Type, len, cap int) Value // 创建值并返回指向它的指针 func New(typ Type) Value func NewAt(typ Type, p unsafe.Pointer) Value 操作 Value // 将值添加到 Slice 中 func Append(s Value, x ...Value) Value // 将一个 Slice 内的内容添加到 Slice 中 func AppendSlice(s, t Value) Value // 解引用，获取指针 v 指向的值 func Indirect(v Value) Value // Select func Select(cases []SelectCase) (chosen int, recv Value, recvOK bool) // 返回一个类型的零值，不可更改不可寻址 func Zero(typ Type) Value Value 方法 Value 是一个定义的结构体，其有许多定义好的方法，根据其原始类型的不同，能使用的方法也不同。\ntype Value struct { typ *rtype // 反射出来此值的类型  ptr unsafe.Pointer // 数据形式的指针值  flag // 保存元数据 } 获取具体类型值 使用这些方法可以获取到 Value 对应类型的具体的值。\nfunc (v Value) String() string func (v Value) Int() int64 func (v Value) Uint() uint64 func (v Value) Float() float64 func (v Value) Bool() bool func (v Value) Slice(i, j int) Value func (v Value) Slice3(i, j, k int) Value // 用 v[i:j:k] 的方式获取切片 func (v Value) Bytes() []byte func (v Value) Complex() complex128 func (v Value) Interface() (i interface{}) func (v Value) Pointer() uintptr // 获取指针 func (v Value) UnsafeAddr() uintptr // 获取 unsafe 包中的指针 通用方法 这些通用方法基本上是所有类型都可以使用的方法。\n// 获取 Value 的 Type func (v Value) Type() Type // 获取 Value 的 Kind func (v Value) Kind() Kind // 转换 v 的类型，返回转换以后的值 func (v Value) Convert(t Type) Value // 判断 v 是否合法，如果返回 false，那么除了 String() 以外的其他方法调用都会 panic，事前检查是必要的 func (v Value) IsValid() bool // 判断 Value 是否为零值 func (v Value) IsZero() bool // 获取表示 v 的地址的指针值 func (v Value) Addr() Value // 判断 v 是否是可寻址的 func (v Value) CanAddr() bool // 判断 v 的值是否可以被更改 func (v Value) CanSet() bool // 这几个方法判断值是否超出了它的类型能表示的范围 func (v Value) OverflowInt(x int64) bool func (v Value) OverflowFloat(x float64) bool func (v Value) OverflowUint(x uint64) bool func (v Value) OverflowComplex(x complex128) bool 更改值 以下这些方法可以更改 Value 的值，但必须符合底层类型。\nfunc (v Value) Set(x Value) func (v Value) SetBool(x bool) func (v Value) SetBytes(x []byte) func (v Value) SetCap(n int) func (v Value) SetComplex(x complex128) func (v Value) SetFloat(x float64) func (v Value) SetInt(x int64) func (v Value) SetLen(n int) func (v Value) SetMapIndex(key, elem Value) func (v Value) SetPointer(x unsafe.Pointer) func (v Value) SetString(x string) func (v Value) SetUint(x uint64) Struct // 获取 struct 字段数量 func (v Value) NumField() int // 获取 struct 方法数量 func (v Value) NumMethod() int // 获取 sturct 第 i 个字段，主要用于遍历 func (v Value) Field(i int) Value // 获取 struct 名为 name 的字段 func (v Value) FieldByName(name string) Value // 获取 Struct 内嵌套的方法，[]int 为嵌套的路径 func (v Value) FieldByIndex(index []int) Value // 根据函数签名获取 struct 字段中的函数 func (v Value) FieldByNameFunc(match func(string) bool) Value // 获取 struct 第 i 个方法 func (v Value) Method(i int) Value // 获取 struct 名为 name 的方法 func (v Value) MethodByName(name string) Value 混合类型方法 这些混合类型方式是限定为一部分类型可用的。\n// 判断 v 是不是 nil，类型为：Chan, Func, Interface, Map, Pointer, Slice func (v Value) IsNil() bool // 获取 v 的 len 值，类型为：Array, Chan, Map, Slice, String. func (v Value) Len() int // 返回 v 的 cap 值，类型为：Array, Slice, Chan func (v Value) Cap() int // 返回 v 的第 i 个元素，类型为：Array, Slice, String func (v Value) Index(i int) Value Channel // Recv 和 Send 在没有完成操作时会阻塞 func (v Value) Recv() (x Value, ok bool) func (v Value) Send(x Value) // TryRecv 和 TrySend 不会阻塞，如果操作没有完成，会返回零值和 false func (v Value) TryRecv() (x Value, ok bool) func (v Value) TrySend(x Value) bool // 关闭通道 func (v Value) Close() 7. Map // 用 key 获取 map 的值 func (v Value) MapIndex(key Value) Value // 获取 map 所有的key func (v Value) MapKeys() []Value // 可以用来遍历 map 的方法 func (v Value) MapRange() *MapIter 遍历例子：\niter := reflect.ValueOf(m).MapRange() for iter.Next() { k := iter.Key() v := iter.Value() ... } Func // 调用函数 v，并将参数作为 Value 切片传入 func (v Value) Call(in []Value) []Value // 调用函数 v，并将参数作为 Value 切片传入，CallSlice 会将 in 中最后一个参数作为可变参数传入 func (v Value) CallSlice(in []Value) []Value Interface // 返回 v 的接口值或者指针 func (v Value) Elem() Value func (v Value) CanInterface() bool func (v Value) InterfaceData() [2]uintptr Kind Kind 表示的是对象的原生底层类型。有以下这些类型：\nconst ( Invalid Kind = iota Bool Int Int8 Int16 Int32 Int64 Uint Uint8 Uint16 Uint32 Uint64 Uintptr Float32 Float64 Complex64 Complex128 Array Chan Func Interface Map Ptr Slice String Struct UnsafePointer ) 还有一个 func (k Kind) String() string 方法可以返回 Kind 的名称。\nStructField 此结构体用来表示 Struct 的字段：\ntype StructField struct { Name string // 字段名  PkgPath string // PkgPath 是未导出字段的程序包路径，可导出字段此值为空  Type Type // 字段类型  Tag StructTag // 字段的 Tag  Offset uintptr // 在 struct 中的偏移量，单位 bytes  Index []int // 字段在 struct 中的数字索引  Anonymous bool // 是否是一个嵌入式字段 } StructTag 此类型用来表示 Struct 字段的 Tag 字符串，其有两个方法可以获取 Tag 中设定的值。\nfunc (tag StructTag) Get(key string) string func (tag StructTag) Lookup(key string) (value string, ok bool)   Get 在没有这个字段和字段为空字符时，都会返回空字符。\n  所以如果需要检查是否设置了这个 Tag，需要使用 Lookup。例子：\ntype S struct { F0 string `alias:\u0026#34;field_0\u0026#34;` F1 string `alias:\u0026#34;\u0026#34;` F2 string } s := S{} st := reflect.TypeOf(s) for i := 0; i \u0026lt; st.NumField(); i++ { field := st.Field(i) if alias, ok := field.Tag.Lookup(\u0026#34;alias\u0026#34;); ok { if alias == \u0026#34;\u0026#34; { fmt.Println(\u0026#34;(blank)\u0026#34;) } else { fmt.Println(alias) } } else { fmt.Println(\u0026#34;(not specified)\u0026#34;) } }  ","date":"2020-06-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%8F%8D%E5%B0%84-reflect/","title":"Go 反射 reflect"},{"content":"fmt 是 Go 用于日志打印的库：\n 模板模式: [name]f 根据模板格式化 例如: Printf 换行模式: [name]ln 输出后带换行 例如: Println  方法 Print 打印数据到控制台，返回字节数和异常。\nfunc Print(a ...interface{}) (n int, err error) func Printf(format string, a ...interface{}) (n int, err error) func Println(a ...interface{}) (n int, err error) Fprint 写入数据到一个 io.Writer 中，返回写入字节数和异常。\nfunc Fprint(w io.Writer, a ...interface{}) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) func Fprintln(w io.Writer, a ...interface{}) (n int, err error) Sprint 写入数据到一个字符串中并返回。\nfunc Sprint(a ...interface{}) string func Sprintf(format string, a ...interface{}) string func Sprintln(a ...interface{}) string Errorf 格式化字符串，并据此生成返回一个 error。\nfunc Errorf(format string, a ...interface{}) error 占位符  Go 没有 %u 点位符，若整数为无符号类型，默认就会被打印成无符号的。 宽度与精度的控制格式以 Unicode 码点为单位。宽度为该数值占用区域的最小宽度，精度为小数点之后的位数。 操作数的类型为 int 时，宽度与精度都可用字符 * 表示。 对于 %g/%G 而言，精度为所有数字的总数，例如：123.45，%.4g 会打印 123.5，（而 %6.2f 会打印123.45）。 %e 和 %f 的默认精度为 6。 对大多数的数值类型而言，宽度为输出的最小字符数，如果必要的话会为已格式化的形式填充空格。 而以字符串类型，精度为输出的最大字符数，如果必要的话会直接截断。  普通占位符    占位符 说明 举例 输出     %v 相应值的默认格式。 Printf(\u0026quot;%v\u0026quot;, people) {zhangsan}   %+v 打印结构体时，会添加字段名 Printf(\u0026quot;%+v\u0026quot;, people) {Name:zhangsan}   %#v 相应值的Go语法表示 Printf(\u0026quot;#v\u0026quot;, people) main.Human{Name:\u0026ldquo;zhangsan\u0026rdquo;}   %T 相应值的类型的Go语法表示 Printf(\u0026quot;%T\u0026quot;, people) main.Human   %% 字面上的百分号，并非值的占位符 Printf(\u0026quot;%%\u0026quot;) %    布尔占位符    占位符 说明 举例 输出     %t true 或 false。 Printf(\u0026quot;%t\u0026quot;, true) true    整数占位符    占位符 说明 举例 输出     %b 二进制表示 Printf(\u0026quot;%b\u0026quot;, 5) 101   %c 相应Unicode码点所表示的字符 Printf(\u0026quot;%c\u0026quot;, 0x4E2D) 中   %d 十进制表示 Printf(\u0026quot;%d\u0026quot;, 0x12) 18   %o 八进制表示 Printf(\u0026quot;%d\u0026quot;, 10) 12   %q 单引号围绕的字符字面值，由Go语法安全地转义 Printf(\u0026quot;%q\u0026quot;, 0x4E2D) \u0026lsquo;中\u0026rsquo;   %x 十六进制表示，字母形式为小写 a-f Printf(\u0026quot;%x\u0026quot;, 13) d   %X 十六进制表示，字母形式为大写 A-F Printf(\u0026quot;%x\u0026quot;, 13) D   %U Unicode格式：U+1234，等同于 \u0026ldquo;U+%04X\u0026rdquo; Printf(\u0026quot;%U\u0026quot;, 0x4E2D) U+4E2D    浮点数和复数    占位符 说明 举例 输出     %b 无小数部分的，指数为二的幂的科学计数法，与 strconv.FormatFloat 的 \u0026lsquo;b\u0026rsquo; 转换格式一致。例如 -123456p-78     %e 科学计数法，例如 -1234.456e+78 Printf(\u0026quot;%e\u0026quot;, 10.2) 1.020000e+01   %E 科学计数法，例如 -1234.456E+78 Printf(\u0026quot;%e\u0026quot;, 10.2) 1.020000E+01   %f 有小数点而无指数，例如 123.456 Printf(\u0026quot;%f\u0026quot;, 10.2) 10.200000   %g 根据情况选择 %e 或 %f 以产生更紧凑的（无末尾的0）输出 Printf(\u0026quot;%g\u0026quot;, 10.20) 10.2   %G 根据情况选择 %E 或 %f 以产生更紧凑的（无末尾的0）输出 Printf(\u0026quot;%G\u0026quot;, 10.20+2i) (10.2+2i)    字符串与字节切片    占位符 说明 举例 输出     %s 输出字符串表示（string类型或[]byte) Printf(\u0026quot;%s\u0026quot;, []byte(\u0026ldquo;Go语言\u0026rdquo;)) Go语言   %q 双引号围绕的字符串，由Go语法安全地转义 Printf(\u0026quot;%q\u0026quot;, \u0026ldquo;Go语言\u0026rdquo;) \u0026ldquo;Go语言\u0026rdquo;   %x 十六进制，小写字母，每字节两个字符 Printf(\u0026quot;%x\u0026quot;, \u0026ldquo;Go\u0026rdquo;) 676f6c616e67   %X 十六进制，大写字母，每字节两个字符 Printf(\u0026quot;%X\u0026quot;, \u0026ldquo;Go\u0026rdquo;) 676F6C616E67    指针    占位符 说明 举例 输出     %p 十六进制表示，前缀 0x Printf(\u0026quot;%p\u0026quot;, \u0026amp;people) 0x4f57f0    其它标记    占位符 说明 举例 输出     + 总打印数值的正负号；对于%q（%+q）保证只输出ASCII编码的字符。 Printf(\u0026quot;%+q\u0026quot;, \u0026ldquo;中文\u0026rdquo;) \u0026ldquo;\\u4e2d\\u6587\u0026rdquo;   - 在右侧而非左侧填充空格（左对齐该区域）     # 备用格式：为八进制添加前导 0（%#o） Printf(\u0026quot;%#U\u0026quot;, \u0026lsquo;中\u0026rsquo;) U+4E2D   ' ' (空格)为数值中省略的正负号留出空白（% d）；以十六进制（% x, % X）打印字符串或切片时，在字节之间用空格隔开     0 填充前导的0而非空格；对于数字，这会将填充移到正负号之后     ","date":"2020-06-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0-fmt/","title":"Go 日志打印 fmt"},{"content":"time 是 Go 用于处理时间的标准库，包括格式化、计算、修改、定时、超时等功能。\n格式 时间占位符 常用：2006-01-02 15:04:05\n 年份：06，2006 月份：01，Jan，January 星期：Monday，Mon 日期：02，2，_2 小时：15 小时（12时制）：3，03 分钟：04，4 秒钟：05，5 上下午标志：PM，pm 时区：MST 时区偏移：-700  常量 const ( ANSIC = \u0026#34;Mon Jan _2 15:04:05 2006\u0026#34; UnixDate = \u0026#34;Mon Jan _2 15:04:05 MST 2006\u0026#34; RubyDate = \u0026#34;Mon Jan 02 15:04:05 -0700 2006\u0026#34; RFC822 = \u0026#34;02 Jan 06 15:04 MST\u0026#34; RFC822Z = \u0026#34;02 Jan 06 15:04 -0700\u0026#34; // RFC822 with numeric zone  RFC850 = \u0026#34;Monday, 02-Jan-06 15:04:05 MST\u0026#34; RFC1123 = \u0026#34;Mon, 02 Jan 2006 15:04:05 MST\u0026#34; RFC1123Z = \u0026#34;Mon, 02 Jan 2006 15:04:05 -0700\u0026#34; // RFC1123 with numeric zone  RFC3339 = \u0026#34;2006-01-02T15:04:05Z07:00\u0026#34; RFC3339Nano = \u0026#34;2006-01-02T15:04:05.999999999Z07:00\u0026#34; Kitchen = \u0026#34;3:04PM\u0026#34; // Handy time stamps.  Stamp = \u0026#34;Jan _2 15:04:05\u0026#34; StampMilli = \u0026#34;Jan _2 15:04:05.000\u0026#34; StampMicro = \u0026#34;Jan _2 15:04:05.000000\u0026#34; StampNano = \u0026#34;Jan _2 15:04:05.000000000\u0026#34; ) Time 时间点 初始化 当前时间\nfunc Now() Time 解析时间\nfunc Parse(layout, value string) (Time, error) time.Parse(\u0026#34;2016-01-02 15:04:05\u0026#34;, \u0026#34;2018-04-23 12:24:51\u0026#34;) 解析指定时区时间\nfunc ParseInLocation(layout, value string, loc *Location) (Time, error) time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2017-05-11 14:06:06\u0026#34;, time.Local) 生成指定时间\nfunc Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time time.Date(2018, 1, 2, 15, 30, 10, 0, time.Local) 通过时间戳生成时间\nfunc Unix(sec int64, nsec int64) Time time.Unix(1571818205, 67868768768) Time 方法 休眠，暂停当前协程\nfunc Sleep(d Duration) 格式化时间点\nfunc (t Time) Format(layout string) string 返回时间点字符串格式\nfunc (t Time) String() string // \u0026#34;2006-01-02 15:04:05.999999999 -0700 MST\u0026#34; 获取时间戳\n// 获取10位长度时间戳 func (t Time) Unix() int64 // 获取纳秒单位时间戳 func (t Time) UnixNano() int64 具体时间数据 // 获取年份 func (t Time) Year() int // 获取月份 func (t Time) Month() Month // 获取星期 func (t Time) Weekday() Weekday // 获取日期 func (t Time) Day() int // 获取小时 func (t Time) Hour() int // 获取分钟 func (t Time) Minute() int // 获取秒钟 func (t Time) Second() int // 获取纳秒 func (t Time) Nanosecond() int // 获取时分秒 func (t Time) Clock() (hour, min, sec int) //获取年月日 func (t Time) Date() (year int, month Month, day int) // 获取时间点在一年中的天数 func (t Time) YearDay() int // 获取时间点年份和周数，周数范围为1-53 func (t Time) ISOWeek() (year, week int) 判断 // 判断时间是否在此之后 func (t Time) After(u Time) bool // 判断时间是否在此之前 func (t Time) Before(u Time) bool // 判断时间是否相等 func (t Time) Equal(u Time) bool // 判断是否为0 func (t Time) IsZero() bool Duartion 时间段 常量 type Duration int64 时分秒\nconst ( Nanosecond Duration = 1 Microsecond = 1000 * Nanosecond Millisecond = 1000 * Microsecond Second = 1000 * Millisecond Minute = 60 * Second Hour = 60 * Minute ) 月份\ntype Month int const ( January Month = 1 + iota February March April May June July August September October November December ) 星期\ntype Weekday int const ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday ) 方法 解析字符串生成时间段\nfunc ParseDuration(s string) (Duration, error) // 可用单位\u0026#34;ns\u0026#34;, \u0026#34;us\u0026#34; (or \u0026#34;µs\u0026#34;), \u0026#34;ms\u0026#34;, \u0026#34;s\u0026#34;, \u0026#34;m\u0026#34;, \u0026#34;h\u0026#34;. 获取特定单位的时间段\nfunc (d Duration) Hours() float64 func (d Duration) Minutes() float64 func (d Duration) Seconds() float64 func (d Duration) Milliseconds() int64 // 毫秒 func (d Duration) Microseconds() int64 // 微秒 func (d Duration) Nanoseconds() int64 // 纳秒 计算修改时间 修改时间 // 加上时间 func (t Time) Add(d Duration) Time // 加上日期 func (t Time) AddDate(years int, months int, days int) Time 计算时间 // 减去时间 func (t Time) Sub(u Time) Duration // 到当前时间过去了多久时间，等价 time.Now().Sub(t) func Since(t Time) Duration // 到指定时间还有多久，等价 t.Sub(time.Now()) func Until(t Time) Duration 时间点取整 func (t Time) Round(d Duration) Time func (t Time) Truncate(d Duration) Time 时区 // 获取时间点的时区 func (t Time) Location() *Location // 获取时区名和偏移量 func (t Time) Zone() (name string, offset int) // 获取时间点在当前时区的副本 func (t Time) Local() Time // 获取时间点在UTC时区的副本 func (t Time) UTC() Time // 获取时间点在指定时区的副本 func (t Time) In(loc *Location) Time 定时与超时 Timer 此函数等待指定时间后，然后在返回的通道中发送当前时间。\nfunc After(d Duration) \u0026lt;-chan Time 可以与 select 配合实现超时功能：\nvar c chan int func handle(int) {} func main() { select { case m := \u0026lt;-c: handle(m) case \u0026lt;-time.After(10 * time.Second): fmt.Println(\u0026#34;timed out\u0026#34;) } } Timer 方法：\n// 创建 Timer func NewTimer(d Duration) *Timer // 指定时间后调用 f 函数，可以使用返回的 Timer 取消 func AfterFunc(d Duration, f func()) *Timer // 重置计时时间 func (t *Timer) Reset(d Duration) bool // 停止 Timer func (t *Timer) Stop() bool Ticker 此函数是 Ticker 的简单封装，可以返回一个通道，此通道间隔指定时间发送当前时间，注意的是，由于无法关闭底层 Ticker，此通道是默认泄露的。\nfunc Tick(d Duration) \u0026lt;-chan Time 实现定时效果\nfunc statusUpdate() string { return \u0026#34;\u0026#34; } func main() { c := time.Tick(5 * time.Second) for now := range c { fmt.Printf(\u0026#34;%v %s\\n\u0026#34;, now, statusUpdate()) } } Ticker 方法\n// 创建 Ticker func NewTicker(d Duration) *Ticker // 停止 Ticker func (t *Ticker) Stop() ","date":"2020-06-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86%E5%BA%93-time/","title":"Go 时间处理库 time"},{"content":"errors 用于增强 Go 的错误处理能力。\nErrors error 类型为一个接口，其定义为：\ntype error interface { Error() string } Error Error() 函数返回一个字符串，用以表示这个 error 类型。\nfunc (e *error) Error() string ( return e.msg ) Wrap Go 1.13 中新增，可以将 error 嵌套起来，形成多层结构。\n简单的嵌套方法，用 Errorf() 和 %w：\ne := errors.New(\u0026#34;原始错误\u0026#34;) w := fmt.Errorf(\u0026#34;Wrap了一个错误%w\u0026#34;, e) 复杂的自定义类型需要拥有 Unwrap() 方法的 error 类型。\nUnwrap() 的定义举例：\ntype NewError struct { err error msg string } func (e *NewError) Error() string { return e.err.Error() + e.msg } func (e *NewError) Unwrap() error ( return e.err ) 用法：\ne := errors.New(\u0026#34;原始错误\u0026#34;) w := \u0026amp;NewError{err: e, msg: \u0026#34;wrap了一个错误\u0026#34;} Unwrap Go 1.13 新增，这个函数可以把嵌套在 error 中的 error 取出。\nfunc Unwrap(err error) error Is 用来判断 err 或者其嵌套链中，是否有 target 类型的异常，只能判断已经生成的特定类型 error，也就是所谓的哨兵异常。\nfunc Is(err error, target error) bool 用法：\nif errors.Is(err, os.ErrExist) As 用来判断 err 或者其嵌套链中，是否有 target 的异常，如果有，就将符合类型的 err 赋值给 target。\n这种方式只能判断指定的自定义异常类型，也就是 struct。\nfunc As(err error, target interface{}) bool 用法：\nvar tar *os.PathError if errors.As(err, \u0026amp;tar) { fmt.Println(perr.Path) } ","date":"2020-06-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86-errors/","title":"Go 错误处理 errors"},{"content":"os 库主要用于 Go 的文件、系统相关操作。\n文件操作 导入模块\nimport \u0026#34;os\u0026#34; 打开文件 函数：\nfunc Open(name string) (*File, error) // 只能用于读取 func OpenFile(name string, flag int, perm FileMode) (*File, error)  name - 文件路径 flag - 打开文件模式 perm - 权限控制  文件打开模式：\n// 此三项模式必须至少指定一个 O_RDONLY int = syscall.O_RDONLY // 只读模式 O_WRONLY int = syscall.O_WRONLY // 只写模式 O_RDWR int = syscall.O_RDWR // 读写模式 // 这些行为的选项是可选的 O_APPEND int = syscall.O_APPEND // 添加模式 O_CREATE int = syscall.O_CREAT // 如果文件不存在则创建新文件 O_EXCL int = syscall.O_EXCL // 与 O_CREATE 一起使用, 文件必须不存在 O_SYNC int = syscall.O_SYNC // 同步方式打开，即不使用缓存，直接写入硬盘 O_TRUNC int = syscall.O_TRUNC // 打开并清空文件 例子：\nfile, err := os.OpenFile(\u0026#34;example.txt\u0026#34;, os.O_RDWR|os.O_CREATE, 0664) if err != nil { ... } defer file.Close() File 对象 读取 // 读取数据到指定的 []byte 中 func (f *File) Read(b []byte) (n int, err error) // 从 off 开始读取数据到指定的 []byte 中 func (f *File) ReadAt(b []byte, off int64) (n int, err error) // 获取文件名 func (f *File) Name() string // 返回描述文件的 FileInfo 类型 func (f *File) Stat() (FileInfo, error) 写入 // 写入文件 func (f *File) Write(b []byte) (n int, err error) // 指定位置写入文件 func (f *File) WriteAt(b []byte, off int64) (n int, err error) // 写入字符串 func (f *File) WriteString(s string) (n int, err error) 操作 // 关闭文件 func (f *File) Close() error // 将文件裁剪到 size 大小，多余部分会被丢弃，size 为 0 则清空文件 func (f *File) Truncate(size int64) error // 将文件系统的最近写入的数据从内存中的拷贝刷新到硬盘中稳定保存 func (f *File) Sync() error // 更改文件操作的位置 func (f *File) Seek(offset int64, whence int) (ret int64, err error) // 更改文件权限 func (f *File) Chmod(mode FileMode) error // 更改文件所有者 func (f *File) Chown(uid, gid int) error // 获取目录的内容的 FileInfo 类型 func (f *File) Readdir(n int) ([]FileInfo, error) // 获取目录的内容的名称 func (f *File) Readdirnames(n int) (names []string, err error) // 设置读写文件超时 func (f *File) SetDeadline(t time.Time) error func (f *File) SetReadDeadline(t time.Time) error func (f *File) SetWriteDeadline(t time.Time) error FileInfo 对象 描述文件信息的接口对象\ntype FileInfo interface { Name() string // 文件名  Size() int64 // 文件大小  Mode() FileMode // 文件权限  ModTime() time.Time // 上次更改时间  IsDir() bool // 是否是目录  Sys() interface{} // 底层数据源 } 常用方法 文件操作 // 创建文件 func Create(name string) (*File, error) // 创建目录 func Mkdir(name string, perm FileMode) error // 创建路径中所有目录 func MkdirAll(path string, perm FileMode) error // 删除文件或目录 func Remove(name string) error // 删除目录及所有子目录内容 func RemoveAll(path string) error // 重命名或移动文件或目录 func Rename(oldpath, newpath string) error // 裁剪文件大小 func Truncate(name string, size int64) error // 获取文件或目录信息 func Stat(name string) (FileInfo, error) 环境变量 func Clearenv() // 清除所有环境变量 func Environ() []string // 返回所有环境变量 func Getenv(key string) string // 获取指定环境变量值 func Setenv(key, value string) error // 设置环境变量 func Unsetenv(key string) error // 取消某个环境变量 系统信息 func Getwd() (dir string, err error) // 获取当前路径的绝对路径 func Hostname() (name string, err error) // 获取当前主机名 func Getpid() int // 获取调用者进程 ID func Getppid() int // 获取调用者父进程 ID func Getgid() int // 获取调用者组 ID func Getegid() int // 获取调用者有效的组 ID func Getgroups() ([]int, error) // 获取调用者所属的所有组 func Getuid() int // 获取调用者用户 ID func Geteuid() int // 获取调用者有效的用户 ID 检查异常 func IsExist(err error) bool // 检查是否是文件存在异常 func IsNotExist(err error) bool // 检查是否是文件不存在异常 func IsPermission(err error) bool // 检查是否是权限异常 func IsTimeout(err error) bool // 检查是否是超时异常 ","date":"2020-05-05T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E7%B3%BB%E7%BB%9F%E5%BA%93-os/","title":"Go 系统库 os"},{"content":"Go 基础数据结构 array、slice、map 的声明与使用。\narray 数组是同一类型元素的集合。\n长度固定，不允许数组混合不同类型的元素。\n声明 var a [3]int  数组中的所有元素会被自动赋值为数据类型的零值。 数组的索引从 0 开始。 不同大小的数组视为不同类型。 Go 中的数组是值类型而不是引用类型，当数组赋值给一个新的变量时，该变量会得到一个原始数组的一个副本。  声明时赋值：\nvar a = [3]int{12, 78, 50} a := [3]int{12, 78, 50} a := [5]int{1:12, 3:78} a := [...]int{12, 78, 50} // 自动计算长度 多维数组 a := [3][2]string{ {\u0026#34;lion\u0026#34;, \u0026#34;tiger\u0026#34;}, {\u0026#34;cat\u0026#34;, \u0026#34;dog\u0026#34;}, {\u0026#34;pigeon\u0026#34;, \u0026#34;peacock\u0026#34;}, } slice 切片可以理解为一个可变长度的数组。\n切片本质上是对数组建立的方便、灵活且功能强大的封装（Wrapper）。\n切片本身不存储任何数据，数据存储在底层的数组中，切片只是对数组的引用。对切片所做的任何修改都会反映在底层数组中。\n声明 c := []int{6, 7, 8} 使用已有数组创建切片。\na := [5]int{76, 77, 78, 79, 80} var b []int = a[1:4] 使用 make 创建切片，三个参数是类型、长度、容量，容量是可选参数，默认值与长度相同。\n长度不为 0 时，将会自动填充相应数量的默认值。\nc := make([]int, 5, 5) 使用 make 创建空切片时，一般长度使用 0，但是最好指定容量信息，避免后续追加内容时容量不足，造成频繁的内存分配。\n空切片 切片还有 nil 切片和空切片，它们的长度和容量都是 0，但是它们指向底层数组的指针不一样\n  nil 切片意味着指向底层数组的指针为 nil，表示切片不存在\nvar nilSlice []int // nil 切片   而空切片对应的指针是个地址，一般用来表示这是一个空集合，没有内容\nslice := []int{} // 空切片   长度和容量  长度使用 len() 查看，是切片中元素的数量。访问超过长度的索引值会报错。 容量使用 cap() 查看，是指创建切片时，底层数组的元素数量。容量必须大于等于长度。  添加元素 使用append()方法\nvar a []int append(a, 10) append(a, 20, 30, 40) veggies := []string{\u0026#34;potatoes\u0026#34;, \u0026#34;tomatoes\u0026#34;, \u0026#34;brinjal\u0026#34;} fruits := []string{\u0026#34;oranges\u0026#34;, \u0026#34;apples\u0026#34;} food := append(veggies, fruits...) 使用 append() 方法时，如果添加元素后的数量超过了切片的容量，那么 Go 会自动创建一个容量翻倍的底层数组，并将原有数组的数据复制到新的数组中，这样就实现了切片的动态长度。\n注意：最好预先定好切片的大概长度，避免频繁的重新分配数组，浪费系统性能。\n拷贝 切片中保存的是对底层数组的引用，所以赋值给其他变量后，修改的依然是原数组。\n如果有对某个数组的切片存在，那么原数组就不会被垃圾回收。\n使用 copy() 函数可以生成一个与原切片无关的切片副本。\ncountries := []string{\u0026#34;USA\u0026#34;, \u0026#34;Singapore\u0026#34;, \u0026#34;Germany\u0026#34;, \u0026#34;India\u0026#34;, \u0026#34;Australia\u0026#34;} neededCountries := countries[:len(countries)-2] countriesCpy := make([]string, len(neededCountries)) copy(countriesCpy, neededCountries) map   Map 与切片相同，是引用类型\n  Map 之间不能使用 == 操作符进行判断，== 只能用来检查 Map 是否为 nil\n  声明 表示方式为 map[key type]value type，如 map[string]int\nm := map[string]int{} var m = map[string]int{\u0026#34;hunter\u0026#34;:12,\u0026#34;tony\u0026#34;:10} m := make(map[string]int) 与切片相同，使用 make 创建 map 时，最好指定容量信息，避免后续追加内容时容量不足，造成频繁的内存分配\nfiles, _ := ioutil.ReadDir(\u0026#34;./files\u0026#34;) m := make(map[string]os.FileInfo, len(files)) for _, f := range files { m[f.Name()] = f } 取值 取值方式为 map[key]，如果取一个不存在的值的话，那么会返回相应的数据类型的零值。\n如果我们希望知道 Map 中到底存不存在这个值，我们可以使用以下语法\nvalue, ok := map[key] 删除元素 删除 Map 中的元素可以使用 delete(map, key) 函数，此函数没有返回值。\ndelete(person, \u0026#34;steve\u0026#34;) New 和 Make 区别 Go 语言中 new 和 make 是内建的两个函数，主要用来创建分配类型内存。\n变量声明 通常的声明方式\nvar i int var s string  声明值类型变量时，默认值是他们的零值 声明引用类型时，类型的零值是 nil  而直接声明引用类型，会造成引用类型的内存空间没有分配，无法存储数据，例如以下代码会报错：\nvar i *int *i = 10 fmt.Println(*i) New new() 函数主要用于为变量分配内存，并初始化为零值。\n它只接受一个类型作为参数，分配好内存后，返回一个指向该类型内存地址的指针。同时把分配的内存值置为零，也就是类型的零值。\nvar i *int i = new(int) *i = 10 fmt.Println(*i) struct 可以用此方法将 struct 内部的字段初始化，例如下面这个 user 类型的 lock 字段，不需要额为的初始化了。\nnew() 也等价于 u := user{}\ntype user struct { lock sync.Mutex name string age int } u:=new(user) u.lock.Lock() u.name = \u0026#34;张三\u0026#34; u.lock.Unlock() Make make() 函数主要用于为特定类型分配内存：Slice、Map、Chan。\n  因为这三种类型就是引用类型，所以没有必要返回他们的指针。\n  由于是引用类型，所以必须得初始化，但不是置为零值，这是和 new 不一样的。\n  异同 相同：\n 二者都是内存的分配（堆上）  差异：\n make 只用于 slice、map、chan 的初始化（非零值） new 用于类型的内存分配，并且内存置为零值 ","date":"2019-11-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"Go 基础数据结构"},{"content":"Channel 实际上是类型化消息的队列，它有以下特性：\n 只能传输一种类型的数据。 所有的类型都可以用于通道，空接口 interface{} 也可以。 先进先出 FIFO 的结构。 引用类型，所以使用 make() 函数来给它分配内存。  用法 声明 声明一个无缓冲的 Channel：\nvar ch1 chan int ch2 := make(chan int) 有缓冲 Channel：\nch := make(chan int, 1) 发送数据 ch := make(chan int) defer close(ch) ch \u0026lt;- 5 阻塞：\n 向 nil 通道发送数据会被阻塞。 向无缓冲 channel 写数据，如果读协程没有准备好会阻塞。 向有缓冲 channel 写数据，如果缓冲已满会阻塞。  panic：\n 向已 closed 的 channel 写数据会 panic。  有缓冲的 channel，如果发送的时候，刚好有等待接收的协程，那么会直接交换数据。\n接收数据 v, ok := \u0026lt;- ch v := \u0026lt;-ch ok 可以用来判断 channel 是否已经关闭，如果关闭该值为 true ，此时 v 接收到的是 channel 类型的零值。\n\u0026lt;- ch 可以单独调用获取通道的（下一个）值，当前值会被丢弃，但是可以用来验证，所以以下代码是合法的：\nif \u0026lt;- ch != 1000{ ... } 阻塞：\n  从 nil 通道接收数据会被阻塞。\n  从无缓冲 channel 读数据，如果写协程没有准备好，会阻塞。\n  从有缓冲 channel 读数据，如果缓冲为空，会阻塞。\n  读取的 channel 如果被关闭，并不会影响正在读的数据，它会将所有数据读取完毕，并不会立即就失败或者返回零值。\n通道方向 通道在创建时都是双向的，但是我们可以声明单向的通道，在传递参数时用来限制使用者对通道的操作：\nfunc source(ch chan\u0026lt;- int){ // 单向入队列  for { ch \u0026lt;- 1 } } func sink(ch \u0026lt;-chan int) { // 单向出队列  for { \u0026lt;-ch } } 特性：\n 只接收的通道 \u0026lt;-chan T 是无法关闭的。  遍历读取 for-range 可以用来便利读取 channel 中的数据：\nch := make(chan int, 1) for val := range ch { fmt.Println(val) }   如果 channel 已经被关闭，它还是会继续执行，直到所有值被取完，然后退出执行。\n  如果通道没有关闭，但是 channel 没有可读取的数据，它则会阻塞在 range 这句位置，直到被唤醒。\n  如果 channel 是 nil，那么同样符合我们上面说的的原则，读取会被阻塞，也就是会一直阻塞在 range 位置。\n  select select case 语句可以方便的对通道进行操作，每次执行 select 语句，将会执行所有的 case 语句，判断是否有表达式能够执行。\n也就是说，select case 语句能同时监控多个通道，当有通道离开堵塞状态，就可以获知并执行相应的代码。\nch := make(chan int) q := make(chan int) for { select { case ch \u0026lt;- x: x, y = y, x+y break case \u0026lt;-q: fmt.Println(\u0026#34;quit\u0026#34;) return } }  select 只要有默认语句，就不会被阻塞，换句话说，如果没有 default，然后 case 又都不能读或者写，则会被阻塞。 nil 的 channel，不管读写都会被阻塞。 select 不能够像 for-range 一样发现 channel 被关闭而终止执行，所以需要结合 multi-valued assignment 来处理。 如果同时有多个 case 满足了条件，会使用伪随机选择一个 case 来执行。 select 语句如果不配合 for 语句使用，只会对 case 表达式求值一次。 每次 select 语句的执行，是会扫码完所有的 case 后才确定如何执行，而不是说遇到合适的 case 就直接执行了。  关闭通道 channel 在使用完毕以后需要关闭，一般的建议是谁写入，谁负责关闭。\n如果有多个写协程的 channel 需要关闭，可以使用额外的 channel 来标记，也可以使用 sync.Once 或者 sync.Mutex 来处理。\nch := make(chan int, 1) defer close(ch) 注：closed 的 channel，再次关闭会 panic。\n空 struct 有时我们需要将 channel 作为一个信号传输的管道，此时管道中的内容并不重要，只需要知道有信号传输过来即可。\n此时可以使用空 struct 作为传输的数据类型，因为空 struct 类型的内存占用大小为 0。即：\nvar c1 chan struct{} c1 \u0026lt;- struct{}{} ","date":"2019-11-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%B9%B6%E5%8F%91%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-channel/","title":"Go 并发消息队列 channel"},{"content":"Go 通过类型别名 alias types 和结构体的形式支持用户自定义类型。\n定义和声明 定义 type identifier struct { field1 type1 field2 type2 } type T struct {a, b int}  结构体的字段可以是任何类型，甚至是结构体本身，也可以是函数或者接口。  声明与赋值 var s T s.a = 5 s.b = 8 简短初始化方式\nintr := Interval{0, 3} // 需要按顺序赋值 intr := Interval{end:5, start:1} // 不需要按顺序 intr := Interval{end:5} // 甚至可以忽略某些字段  结构体未赋值的字段的值是它们所属类型的零值  new 声明 使用 new 函数给一个新的结构体变量分配内存，它会返回指向已分配内存的指针\nvar t *T = new(T) t := new(T) var t *T // 也可以分离定义和声明 t = new(T)   变量 t 是一个指向 T 的指针，此时结构体字段的值是它们所属类型的零值。\n  声明 var t T 也会给 t 分配内存，并零值化内存，但是这个时候 t 是类型 T。\n  初始化一个结构体实例更简短和惯用的方式如下：\nms := \u0026amp;struct1{10, 15.5, \u0026#34;Chris\u0026#34;} // 此时ms的类型是 *struct1 这是一种简写，底层仍然会调用 new ()，这里值的顺序必须按照字段顺序来写。表达式 new(Type) 和 \u0026amp;Type{} 是等价的。\n字段 structname.fieldname = value v := structname.fieldname 无论变量是一个结构体类型还是一个结构体类型指针，都使用同样的方式来使用结构体的字段：\ntype myStruct struct { i int } var v myStruct // v是结构体类型变量 var p *myStruct // p是指向一个结构体类型变量的指针 v.i p.i 也可以通过解引用的方式来设置值：(*pers2).lastName = \u0026quot;Woodward\u0026quot;\n类型转换 Go 中的类型转换遵循严格的规则。当为结构体定义了一个 alias 类型时，此结构体类型和它的 alias 类型都有相同的底层类型，它们可以互相转换。\n同时需要注意其中非法赋值或转换引起的编译错误。\ntype number struct { f float32 } type nr number // 别名  a := number{5.0} b := nr{5.0} var c = number(b) 嵌套 匿名字段 结构体可以包含一个或多个匿名字段，即这些字段没有显式的名字，只有字段的类型是必须的，此时类型就是字段的名字。\n 在一个结构体中对于每一种数据类型只能有一个匿名字段。  type outerS struct { b int c float32 int } outer := new(outerS) outer.b = 6 outer.c = 7.5 outer.int = 60 fmt.Printf(\u0026#34;outer.b is: %d\\n\u0026#34;, outer.b) fmt.Printf(\u0026#34;outer.c is: %f\\n\u0026#34;, outer.c) fmt.Printf(\u0026#34;outer.int is: %d\\n\u0026#34;, outer.int) 内嵌 struct 同样地，结构体也是一种数据类型，所以它也可以作为一个匿名字段来使用。\n当一个匿名类型被内嵌在结构体中时，匿名类型的可见方法也同样被内嵌，这在效果上等同于外层类型继承了这些方法：\n 将父类型放在子类型中来实现亚型。  这个机制提供了一种简单的方式来模拟经典面向对象语言中的子类和继承相关的效果，类似 Ruby 中的 mixin。\ntype A struct { ax, ay int } type B struct { A bx, by float32 } func main() { b := B{A{1, 2}, 3.0, 4.0} fmt.Println(b.ax, b.ay, b.bx, b.by) fmt.Println(b.A) }   内嵌将一个已存在类型的字段和方法注入到了另一个类型里，匿名字段上的方法晋升成为了外层类型的方法。\n  结构体内嵌和自己在同一个包中的结构体时，可以彼此访问对方所有的字段和方法。\n  字段名冲突 当 struct 嵌套时有字段名冲突，按以下规则：\n  外层字段名会覆盖内层字段名，但是两者的内存空间都保留，这提供了一种重载字段或方法的方式。\n  如果相同的名字在同一级别出现了两次，如果这个名字被程序使用了，将会引发一个异常，不使用则没关系。\n没有办法来解决这种问题引起的二义性，必须由程序员自己修正。\n  例子：\ntype A struct {a int} type B struct {a, b int} type C struct {A; B} var c C 在字段名冲突时，如果依然需要使用被覆盖的字段，则可以使用 c.b.a 这种方式。\nmethod Go 的方法是作用在接收者 receiver 上的一个函数，接收者是某种类型的变量。因此方法是一种特殊类型的函数。\n接收者类型可以是几乎任何类型，不仅仅是结构体类型，任何类型都可以有方法，甚至可以是函数类型，可以是 int、bool、string 或数组的别名类型。\n  接收者不能是一个接口类型，因为接口是一个抽象定义，但是方法却是具体实现。\n  接收者不能是一个原始的指针类型，但是它可以是任何其他允许类型的指针。\n  定义 func (recv recv_type) method(param_list) (return_list) { ... } 如果 recv 是一个指针，Go 会自动解引用。\ntype TwoInts struct { a int b int } func (tn *TwoInts) AddToParam(param int) int { return tn.a + tn.b + param } 接收者 由于性能的原因，recv 最常见的值是一个指向 recv_type 的指针，特别是在 recv 类型是结构体时。\n 当接收者是值类型时，方法无法修改接收者本身的数据，因为是值传递。 当接收者是指针类型时，方法内可以修改接收者本身的数据。  无论是值还是指针，通过接收者调用方法时，Go 为我们做了探测工作，方法都支持运行。\n给包外 struct 定义方法 类型和作用在它上面定义的方法必须在同一个包里定义，这就是为什么不能在 int、float 或类似这些的类型上定义方法。试图在 int 类型上定义方法会编译失败。\n但是有一个间接的方式：可以先定义该类型的别名类型，然后再为别名类型定义方法。\n或者将它作为匿名类型嵌入在一个新的结构体中。当然方法只在这个别名类型上有效。\nTag 底层原理 内存布局 Go 语言中，结构体和它所包含的数据在内存中是以连续块的形式存在的，即使结构体中嵌套有其他的结构体，这在性能上带来了很大的优势。\n下面的例子清晰地说明了这些情况：\ntype Rect1 struct {Min, Max Point } type Rect2 struct {Min, Max *Point } ","date":"2019-11-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E7%BB%93%E6%9E%84%E4%BD%93-struct/","title":"Go 结构体 struct"},{"content":"interface 的一些特性：\n 类型不需要显式声明它实现了某个接口：接口被隐式地实现。 多个类型可以实现同一个接口。 实现某个接口的类型，除了实现接口方法外，可以有其他的方法。 一个类型可以实现多个接口。 接口是动态类型，可以包含一个实例的引用，该实例的类型实现了此接口。 即使接口在类型之后才定义，二者处于不同的包中，被单独编译，只要类型实现了接口中的方法，它就实现了此接口。 接口只能访问接口内声明的方法。  定义 type Namer interface { Method1(param_list) return_type Method2(param_list) return_type }   按照约定，只包含一个方法的接口的名字由方法名加 [e]r 后缀组成，例如 Printer、Reader、Writer、Logger、Converter 等等。\n  当后缀 er 不合适时，比如 Recoverable，此时接口名以 able 结尾，或者以 I 开头。\n  Go 语言中的接口都很简短，通常它们会包含 0 个、最多 3 个方法。\n  空接口 空接口 interface{} 不包含任何方法，它对实现不做任何要求：\ntype Any interface{}   空接口类型的变量可以赋任何类型的值。\n  任何其他类型都实现了空接口，any 或 Any 是空接口一个很好的别名或缩写。\n  每个 interface {} 变量在内存中占据两个字长：一个用来存储它包含的类型，另一个用来存储它包含的数据或者指向数据的指针。\n  嵌套接口 一个接口可以包含一个或多个其他的接口，这相当于直接将这些内嵌接口的方法列举在外层接口中一样。\n比如接口 File 包含了 ReadWrite 和 Lock 的所有方法，它还额外有一个 Close() 方法。\ntype ReadWrite interface { Read(b Buffer) bool Write(b Buffer) bool } type Lock interface { Lock() Unlock() } type File interface { ReadWrite Lock Close() } 接口继承 当一个 Struct 包含另一个 Struct（实现了一个或多个接口）的指针时，这个 Struct 就可以使用另一个 Struct 所有的接口方法。例如：\ntype Task struct { Command string *log.Logger } 这个 Struct 的工厂方法像这样：\nfunc NewTask(command string, logger *log.Logger) *Task { return \u0026amp;Task{command, logger} } 当 log.Logger 实现了 Log() 方法后，Task 的实例 task 就可以调用该方法：\ntask.Log() Struct 可以通过继承多个接口来提供像 多重继承 一样的特性：\ntype ReaderWriter struct { *io.Reader *io.Writer } 实现 当一个类型实现了某一个接口所包含的所有方法时，则认为这个类型实现了这个接口。\ntype Handler interface { Do(k, v interface{}) } type HandlerFunc func(k, v interface{}) func (f HandlerFunc) Do(k, v interface{}) { f(k, v) } 类型可以是函数，也可以是 Struct。\n接收者问题 对于一个 Struct，作用于变量上的方法不区分变量到底是指针还是值。\n但当碰到接口类型值时，由于接口变量中存储的具体值是不可寻址的，所以有一定区别。\ntype List []int func (l List) Len() int { return len(l) } func (l *List) Append(val int) { *l = append(*l, val) } type Appender interface { Append(int) } type Lener interface { Len() int }  由于 Appender 接口的方法 Append 实现时使用的是 Struct 的指针，此时使用 var lst List 方式声明的值类型，将不被认为是实现了 Appender 接口。 此时必须使用 plst := new(List) 方式，得到的指针类型，才会被认定为实现了 Appender 接口。 而无论哪种类型，都会被认定为实现了 Lener 接口，因为如果是指针类型，会自动解引用。  总结：\n 指针方法可以通过指针调用。 值方法可以通过值调用。 接收者是值的方法可以通过指针调用，因为指针会首先被解引用。 接收者是指针的方法不可以通过值调用，因为存储在接口中的值没有地址。  断言 一个接口类型的变量 varI 中可以包含任何类型的值，必须有一种方式来检测它的动态类型，即运行时在变量中存储的值的实际类型。\n在执行过程中动态类型可能会有所不同，但是它总是可以分配给接口变量本身的类型。通常我们可以使用类型断言来测试在某个时刻 varI 是否包含类型 T 的值。\nv := varI.(T)  varI 必须是一个接口变量，否则编译器会报错。  类型断言失败后会导致异常退出，如果不希望退出，可以使用以下方法。\nif v, ok := varI.(T); ok { Process(v) return }  如果类型符合，varI 是类型 T 的值，ok 会是 true。 否则 v 是类型 T 的零值，ok 是 false，没有运行时错误发生。  此方法也可以检测变量是否实现了某个接口\ntype Stringer interface { String() string } if sv, ok := v.(Stringer); ok { fmt.Printf(\u0026#34;v implements String(): %s\\n\u0026#34;, sv.String()) } ","date":"2019-10-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-interface-%E6%8E%A5%E5%8F%A3/","title":"Go interface 接口"},{"content":"Go 使用包结构 package 来定义模块、组织代码。\n可见性 在 Go 语言中，包中的标识符（函数、变量、常量、struct 等），都遵守一个 Go 强制的命名规则：\n  小写开头的变量不可以被导入到包外使用，为包内私有变量。\n  大写开头的变量可以被导入到包外使用，为共有变量。\n  Go 通过这种语言层面上的命名方式来决定外部能访问包内的哪些内容。\n而在同一个包内，在使用 import 导入包之后定义或声明的变量、常量、类型，这些对象的作用域在本包范围内都是全局的。\nimport path import \u0026#34;fmt\u0026#34; import \u0026#34;os\u0026#34; import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; )  如果包名不是以 . 或 / 开头，如 \u0026quot;fmt\u0026quot; 或者 \u0026quot;container/list\u0026quot;，则 Go 会在全局文件进行查找。 如果包名以 / 开头（在 Windows 下也可以这样使用），则会在系统的绝对路径中查找。 在 modules 模式下，导入包的路径不再支持相对路径，只支持项目名开头的绝对路径。  别名 import io \u0026#34;fmt\u0026#34; import ( io \u0026#34;fmt\u0026#34; ) 导入而不使用 在 Go 语言中，导入了一个包之后，必须要使用它，不然就会在编译的时候报错，但我们有时候又需要这么做，那么我们可以在导入时使用空白标识符。\n这样的话，这个包就只会执行初始化 init 的内容。\nimport ( _ \u0026#34;geometry/rectangle\u0026#34; ) 编译 go run go run 会编译相应的有 main 执行入口的文件，并且执行编译之后的可执行文件。\ngo run 只能执行一个或多个文件，不能执行包。\ngo build 此命令用来编译我们的指定代码源文件或者包，以及它们的依赖包。\n  build 只编译有 main 包执行入口的包和文件，才会生成相应执行文件。\n  如果只使用一个go build，那么它会默认编译当前目录所对应的包。\n  参数：\n   参数 参数描述     -o 指定输出文件的名称   -i 安装那些编译目标依赖的且还未被安装的代码包   -a 强行对所有涉及到的代码包（包含标准库中的代码包）重新构建，即使它们已经是最新的了。   -n 打印编译期间所用到的其它命令，但是并不真正执行它们。   -p n 指定编译过程中执行各任务的并行数量（确切地说应该是并发数量）。在默认情况下，该数量等于CPU的逻辑核数。但是在 darwin/arm 平台（即iPhone和iPad所用的平台）下，该数量默认是 1。   -race 开启竞态条件的检测。不过此标记目前仅在 linux/amd64、freebsd/amd64、darwin/amd64 和 windows/amd64 平台下受到支持。   -v 打印出那些被编译的代码包的名字。   -work 打印出编译时生成的临时工作目录的路径，并在编译结束时保留它。在默认情况下，编译结束时会删除该目录。   -x 打印编译期间所用到的其它命令。注意它与-n 标记的区别。    go install go install 与 go build 命令大致相同，与 build 主要有两点区别：\n 生成的可执行文件会自动放到工作空间的 bin 目录下。 编译那些没有 main 包执行入口的包时，会生成相应的 .a 文件，并放到工作空间的 pkg 目录下。没有可执行 main 包的文件，也被称为库源码文件。  go build 能用的标签，go install 基本都能用。\ngo get go get 命令可以接受所有可用于 go build 命令和 go install 命令的标记。这是因为 go get 命令的内部步骤中完全包含了编译和安装这两个动作。\n另外，go get 命令还有一些特有的参数，如下表所示：\n   参数名称 参数描述     -d 让命令程序只执行下载动作，而不执行安装动作。   -f 仅在使用 -u 标记时才有效。该标记会让命令程序忽略掉对已下载代码包的导入路径的检查。如果下载并安装的代码包所属的项目是你从别人那里Fork过来的，那么这样做就尤为重要了。   -fix 让命令程序在下载代码包后先执行修正动作，而后再进行编译和安装。   -insecure 允许命令程序使用非安全的 scheme（如HTTP）去下载指定的代码包。如果你用的代码仓库（如公司内部的Gitlab）没有 HTTPS 支持，可以添加此标记。请在确定安全的情况下使用它。   -t 让命令程序同时下载并安装指定的代码包中的测试源码文件中依赖的代码包。   -u 让命令利用网络来更新已有代码包及其依赖包。默认情况下，该命令只会从网络上下载本地不存在的代码包，而不会更新已有的代码包。    Go Mod 用法 初始化包管理，生成 go.mod 文件：\ngo mod init yourProjectName 在 modules 模式下，导入包的路径不再支持相对路径，只支持项目名开头的绝对路径。\n命令 go mod 命令下有以下子命令\n   命令 说明     go mod download 下载modules依赖的包   go mod edit 编辑go.mod文件   go mod graph 打印模块的依赖图   go mod init 在当前目录下初始化modules   go mod tidy 整理modules的依赖项，下载缺少的，删除不需要的   go mod verify 验证依赖是否正确   go mod why 解释为什么需要依赖   go mod vendor 将依赖项复制到vender目录下    可以使用命令 go list -m -u all 来检查可以升级的package。\n使用go get -u need-upgrade-package 升级后会将新的依赖版本更新到 go.mod。\n也可以使用 go get -u 升级所有依赖。\nGOPROXY 国内用于下载包的代理：\n http://goproxy.io http://goproxy.cn ","date":"2019-08-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%8C%85%E7%AE%A1%E7%90%86-package/","title":"Go 包管理 Package"},{"content":"Go 的流程控制语句，包括 if、switch、for。\nif if condition1 { ... } else if condition2 { ... } else { ... } 取反，用 ! 来判断值的相反结果，如：if !bool1 或者 if !(condition)\n初始化语句 if 可以包含一个初始化语句，如 := 给一个变量赋值，这种写法具有固定的格式：\nif initialization; condition {} if val := 10; val \u0026gt; max {} if value := process(data); value \u0026gt; max {} if err := file.Chmod(0664); err != nil {} if value, ok := readData(); ok {}  使用 := 声明的变量的作用域只存在于 if 结构中，如果使用 if-else 则在 else 代码块中变量也会存在。 如果变量在 if 结构之前就已经存在，那么在 if 结构中，该变量原来的值会被隐藏。  switch switch 的 case 从上到下逐一进行判断，一旦满足条件，立即执行对应的分支并返回。其余分支不再做判断。\nswitch var1 { case val1: ... case val2, val3: ... default: ... } fallthrough 在 case 分支执行完毕后继续执行顺序为下一个的分支：\nswitch i { case 0: fallthrough case 1: f() // 当 i == 0 时函数也会被调用 } 条件判断 switch { case condition1: ... case condition2: ... default: ... } 初始化语句 switch initialization { case val1: ... case val2: ... default: ... } type switch 用于判断一个接口变量的类型。\nswitch t := areaIntf.(type) { case *Square: fmt.Printf(\u0026#34;Type Square %T with value %v\\n\u0026#34;, t, t) case *Circle: fmt.Printf(\u0026#34;Type Circle %T with value %v\\n\u0026#34;, t, t) case nil: fmt.Printf(\u0026#34;nil value: nothing to check?\\n\u0026#34;) default: fmt.Printf(\u0026#34;Unexpected type %T\\n\u0026#34;, t) }   变量 t 得到了 areaIntf 的值和类型， 所有 case 语句中列举的类型（nil 除外）都必须实现对应的接口（在上例中即 Shaper）。\n  可以用 type-switch 进行运行时类型分析，但是在 type-switch 不允许有 fallthrough 。\n  如果仅仅是测试变量的类型，不需要它的值，那么就可以不需要赋值语句，比如：\nswitch areaIntf.(type) { case *Square: ... case *Circle: ... default: ... } for 计数器循环 // for 初始化语句; 条件语句; 修饰语句 {} for i := 0; i \u0026lt; 5; i++ { fmt.Printf(\u0026#34;This is the %d iteration\\n\u0026#34;, i) }  注意，不要在循环体内修改计数器  在循环中可以同时使用多个计数器，这得益于 Go 语言具有的平行赋值的特性。\nfor i, j := 0, N; i \u0026lt; j; i, j = i+1, j-1 {} 条件判断循环 // for 条件语句 {} var i int = 5 for i \u0026gt;= 0 { i = i - 1 fmt.Printf(\u0026#34;The variable i is now: %d\\n\u0026#34;, i) } 无限循环 for { ... } 迭代循环 for ix, val := range coll { ... }  如果 coll 为数组，则 ix 为索引位置，val 为值。 如果 coll 为字典，则 ix 为 key，val 为 value。  注意：\n val 始终为集合中对应索引的值拷贝，因此它一般只具有只读性质，对它所做的任何修改都不会影响到集合中原有的值。 如果 val 为指针，则会产生指针的拷贝，依旧可以修改集合中的原值。  break 与 continue break 退出当前整个循环层。\nfor i:=0; i\u0026lt;3; i++ { for j:=0; j\u0026lt;10; j++ { if j\u0026gt;5 { break } } } continue 推出本次循环，直接进入下一次循环，continue 只能被用于 for 循环中。\nfor i := 0; i \u0026lt; 10; i++ { if i == 5 { continue } } ","date":"2019-02-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5/","title":"Go 流程控制语句"},{"content":"Go 中的net包封装了大部分网络相关的功能，我们基本不需要借助其他库就能实现我们的爬虫需求。\n简单请求 其中最为常用的是 http 和 url，使用前可以根据我们的需要进行导入：\nimport ( \u0026#34;net/http\u0026#34; \u0026#34;net/url\u0026#34; ) http提供了一些非常方便的接口，可以实现最简单的请求，例如Get、Post、Head：\nresp, err := http.Get(\u0026#34;http://example.com/\u0026#34;) ... resp, err := http.Post(\u0026#34;http://example.com/upload\u0026#34;, \u0026#34;image/jpeg\u0026#34;, \u0026amp;buf) ... resp, err := http.PostForm(\u0026#34;http://example.com/form\u0026#34;, url.Values{\u0026#34;key\u0026#34;: {\u0026#34;Value\u0026#34;}, \u0026#34;id\u0026#34;: {\u0026#34;123\u0026#34;}}) 可以看到，我们非常简单的就发起了请求并获得了响应，这里需要注意一点的是，获得的响应body需要我们手动关闭：\nresp, err := http.Get(\u0026#34;http://example.com/\u0026#34;) if err != nil { // 处理异常 } defer resp.Body.Close() // 函数结束时关闭Body body, err := ioutil.ReadAll(resp.Body) // 读取Body // ... 这样的请求方式是非常方便的，但是当我们需要定制我们请求的其他参数时，就必须要使用其他组件了。\nClient Client是http包内部发起请求的组件，使用它，我们才可以去控制请求的超时、重定向和其他的设置。以下是Client的定义：\ntype Client struct { Transport RoundTripper CheckRedirect func(req *Request, via []*Request) error Jar CookieJar Timeout time.Duration // Go 1.3 } 首先是生成Client对象：\nclient := \u0026amp;http.Client{} Client也有一些简便的请求方法，如：\nresp, err := client.Get(\u0026#34;http://example.com\u0026#34;) 但这种方法与直接使用http.Get没多大差别，我们需要使用另一个方法来定制请求的Header、请求体、证书验证等参数，这就是Request和Do。\n设置超时 这是一张说明Client超时的控制范围的图：\n img \n这其中，设置起来最方便的是http.Client.Timeout，可以在创建Client时通过字段设置，其计算的范围包括连接(Dial)到读完response body为止。\nhttp.Client会自动跟随重定向，重定向时间也会记入http.Client.Timeout，这点一定要注意。\nclient := \u0026amp;http.Client{ Timeout: 15 * time.Second } 还有一些更细粒度的超时控制：\n net.Dialer.Timeout 限制建立TCP连接的时间 http.Transport.TLSHandshakeTimeout 限制 TLS握手的时间 http.Transport.ResponseHeaderTimeout 限制读取response header的时间 http.Transport.ExpectContinueTimeout 限制client在发送包含 Expect: 100-continue的header到收到继续发送body的response之间的时间等待。  如果需要使用这些超时，需要到Transport中去设置，方法如下所示：\nc := \u0026amp;http.Client{ Transport: \u0026amp;http.Transport{ DialContext: (\u0026amp;net.Dialer{ Timeout: 30 * time.Second, KeepAlive: 30 * time.Second, }).DialContext, TLSHandshakeTimeout: 10 * time.Second, ResponseHeaderTimeout: 10 * time.Second, ExpectContinueTimeout: 1 * time.Second, }, } 可以看到这其中没有单独控制Do方法超时时间的设置，如果需要的话可以使用context自行实现。\n控制重定向 在Client的字段中，有一个CheckRedirect，此字段就是用来控制重定向的函数，如果没有定义此字段的话，将会使用默认的defaultCheckRedirect方法。\n默认的转发策略是最多转发10次。\n在转发的过程中，某一些包含安全信息的Header，比如Authorization、WWW-Authenticate、Cookie等，如果转发是跨域的，那么这些Header不会复制到新的请求中。\nhttp的重定向判断会默认处理以下状态码的请求：\n 301 (Moved Permanently) 302 (Found) 303 (See Other) 307 (Temporary Redirect) 308 (Permanent Redirect)  301、302和303请求将会改用Get访问新的请求，而307和308会使用原有的请求方式。\n那么，我们如何去控制重定向的次数，甚至是禁止重定向呢？这里其实就需要我们自己去实现一个CheckRedirect函数了，首先我们来看看默认的defaultCheckRedirect方法：\nfunc defaultCheckRedirect(req *Request, via []*Request) error { if len(via) \u0026gt;= 10 { return errors.New(\u0026#34;stopped after 10 redirects\u0026#34;) } return nil } 第一个参数req是即将转发的request，第二个参数 via是已经请求过的requests。可以看到其中的逻辑是判断请求过的request数量，大于等于10的时候返回一个error，这也说明默认的最大重定向次数为10次，当此函数返回error时，即是重定向结束的时候。\n所以如果需要设置重定向次数，那么复制一份这个函数，修改函数名字和其中if判断的数字，然后在生成Client时设定到Client即可：\nclient := \u0026amp;http.Client{ CheckRedirect: yourCheckRedirect, } 或者：\nclient := \u0026amp;http.Client{} client.CheckRedirect = yourCheckRedirect 禁止重定向则可以把判断数字修改为0。最好相应地修改errors中提示的信息。\nCookieJar管理 可以看到Client结构体中还有一个Jar字段，类型为CookieJar，这是Client用来管理Cookie的对象。\n如果在生成Client时，没有给这个字段赋值，使其为nil的话，那么之后Client发起的请求将只会带上Request对象中指定的Cookie，请求响应中由服务器返回的Cookie也不会被保存。所以如果需要自动管理Cookie的话，我们还需要生成并设定一个CookieJar对象：\noptions := cookiejar.Options{ PublicSuffixList: publicsuffix.List } jar, err := cookiejar.New(\u0026amp;options) client := \u0026amp;http.Client{ Jar: jar, } 这里的publicsuffix.List是一个域的公共后缀列表，是一个可选的选项，设置为nil代表不启用。但是不启用的情况下会使Cookie变得不安全：意味着foo.com的HTTP服务器可以为bar.com设置cookie。所以一般来说最好启用。\n如果嫌麻烦不想启用PublicSuffixList，可以将其设置为nil，如下即可：\njar, err := cookiejar.New(nil) client := \u0026amp;http.Client{ Jar: jar, } 而publicsuffix.List的实现位于golang.org/x/net/publicsuffix，需要额外下载，使用的时候也需要导入：\nimport \u0026#34;golang.org/x/net/publicsuffix\u0026#34; Request 这是Go源码中Request定义的字段，可以看到非常的多，有兴趣的可以去源码或者官方文档看有注释的版本，本文只介绍一些比较重要的字段。\ntype Request struct { Method string URL *url.URL Proto string // \u0026#34;HTTP/1.0\u0026#34; \tProtoMajor int // 1 \tProtoMinor int // 0 \tHeader Header Body io.ReadCloser GetBody func() (io.ReadCloser, error) ContentLength int64 TransferEncoding []string Close bool Host string Form url.Values PostForm url.Values MultipartForm *multipart.Form Trailer Header RemoteAddr string RequestURI string TLS *tls.ConnectionState Cancel \u0026lt;-chan struct{} Response *Response } 在这里不推荐直接生成Request，而应该使用http提供的NewRequest方法来生成Request，此方法中做了一些生成Request的默认设置，以下是NewRequest的函数签名：\nfunc NewRequest(method, url string, body io.Reader) (*Request, error) 参数中method和url两个是必备参数，而body参数，在使用没有body的请求方法时，传入nil即可。\n配置好Request之后，使用Client对象的Do方法，就可以将Request发送出去，以下是示例：\nreq, err := NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;https://www.baidu.com\u0026#34;, nil) resp, err := client.Do(req) Method 请求方法，必备的参数，如果为空字符则表示Get请求。\n注：Go的HTTP客户端不支持CONNECT请求方法。\nURL 一个被解析过的url结构体。\nProto HTTP协议版本。\n在Go中，HTTP请求会默认使用HTTP1.1，而HTTPS请求会默认首先使用HTTP2.0，如果目标服务器不支持，握手失败后才会改用HTTP1.1。\n如果希望强制使用HTTP2.0的协议，那么需要使用golang.org/x/net/http2这个包所提供的功能。\n发起Post请求 如果要使用Request发起Post请求，提交表单的话，可以用到它的PostForm字段，这是一个类型为url.Values的字段，以下为示例：\nreq, err := NewRequest(\u0026#34;Post\u0026#34;, \u0026#34;https://www.baidu.com\u0026#34;, nil) req.PostForm.Add(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) 如果你Post提交的不是表单数据，那么你需要将其封装成io.Reader类型，并在NewRequest函数中传递进去。\n设置Header Header的类型是http.Header，其中包含着之前请求中返回的header和client发送的header。\n可以使用这种方式设置Header：\nreq, err := NewRequest(\u0026#34;Get\u0026#34;, \u0026#34;https://www.baidu.com\u0026#34;, nil) req.Header.Add(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) Header还有一些Set、Del等方法可以使用。\n添加Cookie 前文我们已经介绍了如何在Client中启用一直使用的CookieJar，使用它可以自动管理获得的Cookie。\n但很多时候我们也需要给特定的请求手动设置Cookie，这个时候就可以使用Request对象的AddCookie方法，这是其函数签名：\nfunc (r *Request) AddCookie(c *Cookie) 要注意的是，其传入的参数是Cookie类型，，以下是此类型包含的属性：\ntype Cookie struct { Name string Value string Path string Domain string Expires time.Time RawExpires string MaxAge int Secure bool HttpOnly bool Raw string Unparsed []string } 其中只有Name和Value是必须的，所以以下是添加Cookie的示例：\nc := \u0026amp;http.Cookie{ Name: \u0026#34;key\u0026#34;, Value: \u0026#34;value\u0026#34;, } req.AddCookie(c) Transport Transport是Client中的一个类型，用于控制传输过程，是Client实际发起请求的底层实现。如果没有给这个字段初始化相应的值，那么将会使用默认的DefaultTransport。\nTransport承担起了Client中连接池的功能，它会将建立的连接缓存下来，这可能会在访问大量不同网站时，留下太多打开的连接，这可以使用Transport中的方法进行关闭。\n首先来看一下Transport的定义：\ntype Transport struct { Proxy func(*Request) (*url.URL, error) DialContext func(ctx context.Context, network, addr string) (net.Conn, error) // Go 1.7 \tDial func(network, addr string) (net.Conn, error) DialTLS func(network, addr string) (net.Conn, error) // Go 1.4 \tTLSClientConfig *tls.Config TLSHandshakeTimeout time.Duration // Go 1.3 \tDisableKeepAlives bool DisableCompression bool MaxIdleConns int // Go 1.7 \tMaxIdleConnsPerHost int MaxConnsPerHost int // Go 1.11 \tIdleConnTimeout time.Duration // Go 1.7 \tResponseHeaderTimeout time.Duration // Go 1.1 \tExpectContinueTimeout time.Duration // Go 1.6 \tTLSNextProto map[string]func(authority string, c *tls.Conn) RoundTripper // Go 1.6 \tProxyConnectHeader Header // Go 1.8 \tMaxResponseHeaderBytes int64 // Go 1.7 } 由于Transport是Client内部请求的实际发起者，所以内容会比较多，1.6之后的版本也添加了许多新的字段，这里我们来讲解常见的一些字段。\n拨号 由于Client中设置的Timeout范围比较宽，而在生产环境中我们可能需要更为精细的超时控制，在Dial拨号中可以设置几个超时时间。\n在较新的版本中，Dial这个字段已经不再被推荐使用，取而代之的是DialContext，设置这个字段，需要借助于net.Dialer，以下是其定义：\ntype Dialer struct { Timeout time.Duration Deadline time.Time LocalAddr Addr DualStack bool FallbackDelay time.Duration KeepAlive time.Duration Resolver *Resolver Cancel \u0026lt;-chan struct{} Control func(network, address string, c syscall.RawConn) error } 这其中需要我们设置的并不多，主要是Timeout和KeepAlive。Timeout是Dial这个过程的超时时间，而KeepAlive是连接池中连接的超时时间，如下所示：\ntrans := \u0026amp;http.Transport{ DialContext: (\u0026amp;net.Dialer{ Timeout: 30 * time.Second, KeepAlive: 30 * time.Second, }).DialContext, } 设置代理 Transport第一个Proxy字段是用来设置代理，支持HTTP、HTTPS、SOCKS5三种代理方式，首先我们来看看如何设置HTTP和HTTPS代理：\npackage main import ( \u0026#34;net/url\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { proxyURL, _ := url.Parse(\u0026#34;https://127.0.0.1:1080\u0026#34;) trans := \u0026amp;http.Transport{ Proxy: http.ProxyURL(proxyURL), } client := \u0026amp;http.Client{ Transport: trans, } client.Get(\u0026#34;https://www.google.com\u0026#34;) } 设置SOCKS5代理则需要借助golang.org/x/net/proxy：\npackage main import ( \u0026#34;net/url\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;golang.org/x/net/proxy\u0026#34; ) func main() { dialer, err := proxy.SOCKS5(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;, \u0026amp;proxy.Auth{User:\u0026#34;username\u0026#34;, Password:\u0026#34;password\u0026#34;}, \u0026amp;net.Dialer { Timeout: 30 * time.Second, KeepAlive: 30 * time.Second, }, ) trans := \u0026amp;http.Transport{ DialContext: dialer.DialContext } client := \u0026amp;http.Client{ Transport: trans, } client.Get(\u0026#34;https://www.google.com\u0026#34;) } 这里的proxy.SOCKS5函数将会返回一个Dialer对象，其传入的参数分别为协议、IP端口、账号密码、Dialer，如果代理不需要账号密码验证的话，第三个字段可以设置为nil。\n连接控制 众所周知，HTTP1.0协议使用的是短连接，而HTTP1.1默认使用的是长连接，使用长连接则可以复用连接，减少建立连接的开销。\nTransport中实现了连接池的功能，可以将连接保存下来以便下次访问此域名，其中也对连接的数量做出了一定的限制。\nDisableKeepAlives这个字段可以用来关闭长连接，默认值为false，如果有特殊的需求，需要使用短连接，可以设置此字段为true：\ntrans := \u0026amp;http.Transport{ ... DisableKeepAlives: true, } 除此之外，还可以控制连接的数量和保持时间：\n  MaxConnsPerHost int - 每个域名下最大连接数量，包括正在拨号的、活跃的、空闲的的连接。\n值为0表示不限制数量。\n  MaxIdleConns int - 空闲连接的最大数量。\nDefaultTransport中的默认值为100，在需要发起大量连接时偏小，可以根据需求自行设定。\n值为0表示不限制数量。\n  MaxIdleConnsPerHost int - 每个域名下空闲连接的最大数量。\n值为0则会使用默认的数量，每个域名下只能有两个空闲连接。在对单个网站发起大量连接时，两个连接可能会不够，可以酌情增加此数值。\n  IdleConnTimeout time.Duration - 空闲连接的超时时间，从每一次空闲开始算。DefaultTransport中的默认值为90秒。\n值为0表示不限制。\n  由于Transport负担起了连接池的功能，所以在并发使用时，最好将Transport与Client一起复用，不然可能会造成发起过量的长连接，浪费系统资源。\n其他 设置url参数 在Go的请求方式中，没有给我们提供可以直接设置url参数的方法，所以需要我们自己在url地址中进行拼接。\nurl包中提供了一个url.Values类型，其本质的类型为：map[string][]string，可以让我们拼接参数更加简单，如下所示：\nURL := \u0026#34;http://httpbin.org/get\u0026#34; params := url.Values{ \u0026#34;key1\u0026#34;: {\u0026#34;value\u0026#34;}, \u0026#34;key2\u0026#34;: {\u0026#34;value2\u0026#34;, \u0026#34;value3\u0026#34;}, } URL = URL + \u0026#34;\u0026amp;\u0026#34; + params.Encode() fmt.Println(URL) // 输出为：http://httpbin.org/get\u0026amp;key1=value\u0026amp;key2=value2\u0026amp;key2=value3 示例 以下是发起Get请求的一个例子：\n// 生成client客户端 client := \u0026amp;http.Client{} // 生成Request对象 req, err := http.NewRequest(\u0026#34;Get\u0026#34;, \u0026#34;http://httpbin.org/get\u0026#34;, nil) if err != nil { fmt.Println(err) } // 添加Header req.Header.Add(\u0026#34;User-Agent\u0026#34;, \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.108 Safari/537.36\u0026#34;) // 发起请求 resp, err := client.Do(req) if err != nil { fmt.Println(err) } // 设定关闭响应体 defer resp.Body.Close() // 读取响应体 body, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(err) } fmt.Println(string(body))\u0026lt;https://colobu.com/2016/07/01/the-complete-guide-to-golang-net-http-timeouts/\u0026gt;) ","date":"2019-01-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-net/http-client-%E5%AE%A2%E6%88%B7%E7%AB%AF/","title":"Go net/http client 客户端"},{"content":"除了 main()、init() 函数外，其它所有类型的函数都可以有参数与返回值。\n函数参数、返回值以及它们的类型被统称为函数签名。\n参数 多个参数 func find(num1 int, num2 int) {} func find(num1, num2 int) {} 可变参数 使用 ... 声明可变参数。\n 可变参数只能放在参数列表的最末尾:  func find(num int, nums ...int){ ... } 声明后，可以在调用函数时传入任意数量的参数\nfind(89, 89, 90, 95) find(45, 56, 67, 45, 90, 109) find(87) 在函数中接收的nums被接收为一个切片。\n如果希望将一个切片作为可变参数传入函数，则需要在传参的时候加上 ...：\nnums := []int{89, 90, 95} find(89, nums...) 返回值 命名返回值 在声明函数时可以为其返回值命名。\n命名了返回值后，可以认为这些值在函数第一行就已被声明为变量。\nfunc rectProps(length, width float64)(area, perimeter float64) { area = length * width perimeter = (length + width) * 2 return // 不需要明确指定返回值，默认返回 area, perimeter 的值 } 在函数中，perimeter 不需要再次声明了。而且在 return 返回时，不再需要指定返回哪些变量，函数将自动把命名的返回值返回。\n匿名函数 例如：\nfunc(x, y int) int { return x + y } 这样的函数不能够独立存在，编译器会返回错误：non-declaration statement outside function body）\n但可以被赋值于某个变量，即保存函数的地址到变量中:\nfplus := func(x, y int) int { return x + y } fplus(3,4) 或者也可以直接对匿名函数进行调用:\nfunc(x, y int) int { return x + y } (3, 4) ","date":"2019-01-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E5%87%BD%E6%95%B0/","title":"Go 函数"},{"content":"Go 语言规范指导性原则：\n 简单性 可读性 生产力  命名    概括性词汇 精确清晰的词汇     send deliver, dispatch, announce, distribute, route   find search, extract, locate, recover   start launch, create, begin, open   make create, set up, build, generate, compose, add, new    项目名   项目名(仓库名）的命名可以使用字母、数字。\n  多个单词建议采用中划线分隔，目前github中大多数项目都是使用用中划线。\n  不建议采用驼峰式分隔，不要使用下划线( kubernetes 中的组件名称不允许使用下划线)\n  正确:\n user、user-api、user-service,product、product-search、redis-go,druid、zeus、kubernetes.\n 错误:\n user_api、Product\n 包与导入路径  包名应和目录名一致 包路径应该尽可能简洁 避免在包路径中使用任何大写字母  常量   全大写，使用 _ 分隔\n  如果是枚举类型的常量，需要先创建相应类型。\ntype Scheme string const ( HTTP Scheme = \u0026#34;http\u0026#34; HTTPS Scheme = \u0026#34;https\u0026#34; )   变量 指导原则：\n 勿在变量名称中包含类型名称。 常量应该描述它们持有的值，而不是该如何使用。 循环和分支使用单字母变量，参数和返回值使用单个词，函数和包级别声明使用多个单词。 方法、接口和包使用单个词。 包的名称是调用者用来引用名称的一部分，要好好利用这一点。  声明样式 使用一致的声明样式：\n 声明变量但没有初始化时，使用 var。 在声明和初始化时，使用 :=。  长度  The greater the distance between a name’s declaration and its uses, the longer the name should be.\n名字的声明与其使用之间的距离越大，名字应该越长。\n​ — Andrew Gerrand\n   声明和使用的距离越短，变量命名可以越短。如 i 代替 index。\n  长变量名称需要证明自己的合理性。\n  参数 参数默认具有文档的功能。\n  当参数类型具有描述性的时候，参数名就应该尽可能短小：\nfunc AfterFunc(d Duration, f func()) *Timer func Escape(w io.Writer, s []byte)   当参数类型比较模糊的时候，参数名就应当具有文档的功能：\nfunc Unix(sec, nsec int64) Time func HasPrefix(s, prefix []byte) bool   返回值   在外部可见的函数中，返回值的名称应当可以作为文档参考。\nfunc Copy(dst Writer, src Reader) (written int64, err error) func ScanBytes(data []byte, atEOF bool) (advance int, token []byte, err error)   Receiver   方法接收者的名字在同一类型的不同方法中应该保持统一。\n  由于方法接收者在函数内部经常出现，因此它经常采用一两个字母来标识方法接收者的类型。\nfunc (b *Buffer) Read(p []byte) (n int, err error) func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) func (r Rectangle) Size() Point   接口类型   只含有一个方法的接口类型通常以函数名加上er后缀作为名字\ntype Reader interface { Read(p []byte) (n int, err error) }   有时候可能导致蹩脚的英文，但别管他，能看懂就好\ntype Execer interface { Exec(p []byte) (n int, err error) }   有时候可以适当调整一下英文单词的顺序，增加可读性：\ntype ByteReader interface { ReadByte(p []byte) (n int, err error) }   当接口含有多个方法的时候，还是要选取一个能够精准描述接口目的的名字，譬如net.Conn、http/ResponseWriter。\n  Error   Error 类型写成 FooError 形式\ntype ExitError struct {}   Error 变量写成 ErrFoo 形式\nvar ErrFormat = errors.New(\u0026#34;unknown format\u0026#34;)   注释 注释应该做至少三件事中的一件：\n 注释应该解释其作用。 注释应该解释其如何做的。 注释应该解释其原因。  包级别注释   包级别的注释就是对包的介绍，只需在同个包的任一源文件中说明即可有效。\n  对于 main 包，一般只有一行简短的注释用以说明包的用途，且以项目名称开头：\n// Gogs (Go Git Service) is a painless self-hosted Git Service.  package main   对于一个复杂项目的子包，一般情况下不需要包级别注释，除非是代表某个特定功能的模块。\n  对于简单的非 main 包，可用一行注释概括。\n  对于相对功能复杂的非 main 包，一般都会增加一些使用示例或基本说明，且以 Package \u0026lt;name\u0026gt; 开头：\n/* Package regexp implements a simple library for regular expressions. The syntax of the regular expressions accepted is: regexp: concatenation { \u0026#39;|\u0026#39; concatenation } concatenation: { closure } closure: term [ \u0026#39;*\u0026#39; | \u0026#39;+\u0026#39; | \u0026#39;?\u0026#39; ] term: \u0026#39;^\u0026#39; \u0026#39;$\u0026#39; \u0026#39;.\u0026#39; character \u0026#39;[\u0026#39; [ \u0026#39;^\u0026#39; ] character-ranges \u0026#39;]\u0026#39; \u0026#39;(\u0026#39; regexp \u0026#39;)\u0026#39; */ package regexp   特别复杂的包说明，可单独创建 doc.go 文件来加以说明。\n  特别声明  TODO:当某个部分等待完成时，使用此开头的注释来提醒维护人员。 FIXME:当某个部分存在已知问题进行需要修复或改进时，使用此开头的注释来提醒维护人员。 NOTE:当需要特别说明某个问题时，使用此开头的注释。  版权声明 作为开源项目，必须有相应的开源许可证才能算是真正的开源。在选择了一个开源许可证之后，需要在源文件中进行相应的版权声明才能生效。\nApache License Version 2.0 该许可证要求在所有的源文件中的头部放置以下内容才能算协议对该文件有效。\n// Copyright [yyyy] [name of copyright owner] // // Licensed under the Apache License, Version 2.0 (the \u0026quot;License\u0026quot;): you may // not use this file except in compliance with the License. You may obtain // a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT // WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the // License for the specific language governing permissions and limitations // under the License. [yyyy] 表示该源文件创建的年份。\n[name of copyright owner]，即版权所有者。如果为个人项目，就写个人名称。若为团队项目，则宜写团队名称。\nMIT License 使用 MIT 授权的项目，需在源文件头部增加以下内容。\n// Copyright [yyyy] [name of copyright owner]. All rights reserved. // Use of this source code is governed by a MIT-style // license that can be found in the LICENSE file. 年份和版权所有者的名称填写规则与 Apache License Version 2.0 的一样。\n","date":"2019-01-01T00:00:00Z","permalink":"https://wnanbei.github.io/post/go-%E8%AF%AD%E8%A8%80%E8%A7%84%E8%8C%83/","title":"Go 语言规范"},{"content":"HTTP（HyperText Transfer Protocol），意为超文本传输协议，是目前互联网上应用最为广泛的一种网络协议。目前使用最普遍的一个版本是HTTP 1.1。\nHTTP协议是用于从WWW服务器传输超文本到本地浏览器的传送协议。它可以使浏览器更加高效，使网络传输减少。它不仅保证计算机正确快速地传输超文本文档，还确定传输文档中的哪一部分，以及哪部分内容首先显示(如文本先于图形)等。\nHTTP是一个应用层协议，由请求和响应构成，是一个标准的客户端服务器模型。\n一次HTTP请求的基本流程一般是，在建立TCP连接后，由客户端向服务端发起一次请求 request ，而服务器在接收到以后返回给客户端一个响应 response 。所以我们看到的HTTP请求内容一般就分为请求和响应两部分。\nHTTP协议通常承载于TCP协议之上，有时也承载于TLS或SSL协议层之上，这个时候，就成了我们常说的HTTPS。默认HTTP的端口号为80。\n无状态协议 HTTP协议是无状态的，也就是说每一次HTTP请求之间都是相互独立的，没有联系的，服务端不知道客户端具体的状态。\n比如客户端访问一次网页之后关闭浏览器，然后再一次启动浏览器，再访问该网站，服务器是不知道客户关闭了一次浏览器的。\n这样设计的原因是因为Web服务器一般需要面对很多浏览器的并发访问，为了提高Web服务器对并发访问的处理能力，在设计HTTP协议时规定Web服务器发送HTTP应答报文和文档时，不保存发出请求的Web浏览器进程的任何状态信息。\nRequest 每一个HTTP请求都由三部分组成，分别是：请求行、请求报头、请求正文。\n请求行 请求行一般由请求方法、url路径、协议版本组成。\n请求报头 请求行下方的是则是请求报头，HTTP消息报头包括普通报头、请求报头、响应报头、实体报头。每个报头的形式如下：\n 名字 + : + 空格 + 值\n   Host\n指定的请求资源的域名（主机和端口号）。HTTP请求必须包含HOST，否则系统会以400状态码返回。\n  User-Agant\n简称UA，内容包含发出请求的用户信息，通常UA包含浏览者的信息，主要是浏览器的名称版本和所用的操作系统。这个UA头不仅仅是使用浏览器才存在，只要使用了基于HTTP协议的客户端软件都会发送，无论是手机端还是PDA等，这个UA头是辨别客户端所用设备的重要依据。\n  Accept\n告诉服务器可以接受的文件格式。通常这个值在各种浏览器中都差不多，不过WAP浏览器所能接受的格式要少一些，这也是用来区分WAP和计算机浏览器的主要依据之一，随着WAP浏览器的升级，其已经和计算机浏览器越来越接近，因此这个判断所起的作用也越来越弱。\n  Cookie\nCookie信息。\n  Cache-Control\n指定请求和响应遵循的缓存机制。在请求消息或响应消息中设置Cache-Control并不会修改另一个消息消息处理过程中的缓存处理过程。请求时的缓存指令包括no-cache、no-store、man-age、max-stake、min-fresh、only-if-cached；响应消息中的指令包括 public、privete、no-cache、no-store、no-transform、must-revalidate、proxy-revalidate、max-age。\n  Referer\n页面跳转处，表明产生请求的网页来自于哪个URL，用户是从该 Referer页面访问到当前请求的页面。这个属性可以用来跟踪Web请求来自哪个页面，是从什么网站来的。\n  Content-Length\n内容长度。\n  Content-Range\n响应的资源范围。可以在每次请求中标记请求的资源范围，在连接断开重连时，客户端只请求该资源未下载的部分，而不是重新请求整个资源，实现断点续传。迅雷就是基于这个原，使用多线程分段读取网络上的资源，最后再合并。\n  Accept-Encoding\n指定所能接收的编码方式，通常服务器会对页面进行GZIP压缩后再输出以减少流量，一般浏览器均支持对这种压缩后的数据进行处理，但对于我们来说，如果不想接收到这些看似乱码的数据，可以指定不接收任何服务器端压缩处理，要求其原样返回。\n  Accept-Language\n指浏览器可以接受的语言种类 en、en-us指英语 zh、zh-cn指中文。\n  Connection\n客户端与服务器链接类型，keep-alive:保持链接，close:关闭链接。\n  请求正文 请求正文通常是使用POST方法进行发送的数据，GET方法是没有请求正文的。\n请求正文跟上面的消息报头一般由一个空行隔开。\nResponse HTTP响应同样也是由状态行、响应报头、报文主体三部分组成。\n状态行 状态行由HTTP协议版本号， 状态码， 状态消息三部分组成。\n响应报头   Allow\n服务器支持哪些请求方法（如GET、POST等）。\n  Date\n表示消息发送的时间，时间的描述格式由rfc822定义。例如，Date:Mon,31Dec200104:25:57GMT。Date描述的时间表示世界标准时，换算成本地时间，需要知道用户所在的时区。\n  Set-Cookie\n非常重要的header, 用于把cookie发送到客户端浏览器，每一个写入cookie都会生成一个Set-Cookie。\n  Expires\n指明应该在什么时候认为文档已经过期，从而不再缓存它，重新从服务器获取，会更新缓存。过期之前使用本地缓存。\n  Content-Type\nWEB服务器告诉客户端自己响应的对象的类型和字符集。\n  Content-Encoding\n文档的编码（Encode）方法。只有在解码之后才可以得到Content-Type头指定的内容类型。利用gzip压缩文档能够显著地减少HTML文档的下载时间。\n  Content-Length\n指明实体正文的长度，以字节方式存储的十进制数字来表示。\n  Location\n用于重定向一个新的位置，包含新的URL地址。表示客户应当到哪里去提取文档。\n  Refresh\n表示浏览器应该在多少时间之后刷新文档，以秒计。\n  响应正文 服务器返回的数据。\nURL URL（Uniform Resource Locator），中文叫统一资源定位符。是用来标识某一处资源的地址。以下面这个URL为例，介绍下普通URL的各部分组成：\n  协议部分：该URL的协议部分为“http：”，这代表网页使用的是HTTP协议。在\u0026quot;HTTP\u0026quot;后面的“//”为分隔符。\n  域名部分：该URL的域名部分为www.aspxfans.com。一个URL中，也可以使用IP地址作为域名使用。\n  端口部分：跟在域名后面的是端口，域名和端口之间使用 : 作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口。\n  路径部分：从域名后的第一个“/”开始到最后一个“？”为止，是路径部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是路径部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是路径部分。\n本例中的文件名是“index.asp”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名。\n  参数部分：从“？”开始到“#”为止之间的部分为参数部分。本例中的参数部分为“boardID=5\u0026amp;ID=24618\u0026amp;page=1”。参数可以允许有多个参数，参数与参数之间用“\u0026amp;”作为分隔符。\n  锚部分：从“#”开始到最后，都是锚部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分。\n锚部分是用来定位到页面中某个元素的。\n  HTTP请求方法 HTTP协议中定义的请求方法有以下几种：\n   序号 方法 描述     1 GET 请求指定的页面信息，并返回实体主体。   2 HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头   3 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。   4 PUT 从客户端向服务器传送的数据取代指定的文档的内容。   5 DELETE 请求服务器删除指定的页面。   6 CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。   7 OPTIONS 允许客户端查看服务器的性能。   8 TRACE 回显服务器收到的请求，主要用于测试或诊断。    虽然HTTP请求中定义的方法有这么多种，但是我们平常使用的基本只有GET和POST两种方法，而且大部分网站都是禁用掉了除GET和POST外其他的方法。\n因为其他几种方法通过GET或者POST都能实现，而且对于网站来说更加的安全和可控。\n  GET\n其实简单来说，GET方法一般用来负责获取数据，或者将一些简短的数据放到URL参数中传递到服务器。比POST更加高效和方便。\n  POST\n由于GET方法最多在url中携带1024字节数据，且将数据放到URL中传递太不安全，数据量大时URL也会变得冗长。所以传递数据量大或者安全性要求高的数据的时候，最好使用POST方法来传递数据。\n  状态码 当客户端向服务端发起一次请求后，服务端在返回的响应头中会包含一个HTTP状态码，以表明这一次请求的状态。下面是一些常见的状态码：\n  200 - 请求成功\n  301 - 资源（网页等）被永久转移到其它URL\n  404 - 请求的资源（网页等）不存在\n  500 - 内部服务器错误\n  HTTP的状态码是由三位数字来表示的，由第一位数字来表示状态码的类型，一般来说有五种类型：\n   分类 分类描述     1** 信息，服务器收到请求，需要请求者继续执行操作   2** 成功，操作被成功接收并处理   3** 重定向，需要进一步的操作以完成请求   4** 客户端错误，请求包含语法错误或无法完成请求   5** 服务器错误，服务器在处理请求的过程中发生了错误    以下是详细的状态码列表：\n   状态码 状态码英文名称 中文描述     100 Continue 继续。客户端应继续其请求   101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议        200 OK 请求成功。一般用于GET与POST请求   201 Created 已创建。成功请求并创建了新的资源   202 Accepted 已接受。已经接受请求，但未处理完成   203 Non-Authoritative Information 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本   204 No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档   205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域   206 Partial Content 部分内容。服务器成功处理了部分GET请求        300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择   301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替   302 Found 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI   303 See Other 查看其它地址。与301类似。使用GET和POST请求查看   304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源   305 Use Proxy 使用代理。所请求的资源必须通过代理访问   306 Unused 已经被废弃的HTTP状态码   307 Temporary Redirect 临时重定向。与302类似。使用GET请求重定向        400 Bad Request 客户端请求的语法错误，服务器无法理解   401 Unauthorized 请求要求用户的身份认证   402 Payment Required 保留，将来使用   403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求   404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置\u0026quot;您所请求的资源无法找到\u0026quot;的个性页面   405 Method Not Allowed 客户端请求中的方法被禁止   406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求   407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权   408 Request Time-out 服务器等待客户端发送的请求时间过长，超时   409 Conflict 服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突   410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置   411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息   412 Precondition Failed 客户端请求信息的先决条件错误   413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息   414 Request-URI Too Large 请求的URI过长（URI通常为网址），服务器无法处理   415 Unsupported Media Type 服务器无法处理请求附带的媒体格式   416 Requested range not satisfiable 客户端请求的范围无效   417 Expectation Failed 服务器无法满足Expect的请求头信息        500 Internal Server Error 服务器内部错误，无法完成请求   501 Not Implemented 服务器不支持请求的功能，无法完成请求   502 Bad Gateway 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求   503 Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中   504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求   505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理    Cookie Cookie有时也用其复数形式 Cookies，英文是饼干的意思。指某些网站为了辨别用户身份、进行 session 跟踪而储存在用户本地终端上的数据（通常经过加密）。最新的规范是 RFC6265 。\nCookie其实就是由服务器发给客户端的特殊信息，而这些信息以文本文件的方式存放在客户端，然后客户端每次向服务器发送请求的时候都会带上这些特殊的信息。 服务器在接收到Cookie以后，会验证Cookie的信息，以此来辨别用户的身份。\nCookie可以理解为一个临时通行证。\n作用 Cookie其实是HTTP请求头的扩展部分，由于HTTP协议是无状态的协议，所以为了在网页上实现登陆之类的需求，所以扩展了Cookie这样的功能。\n每一次HTTP请求在数据交换完毕之后就会关闭连接，所以下一次HTTP请求就无法让服务端得知你和上一次请求的关系。而使用了Cookie之后，你在第一次登陆之类的请求成功之后，服务器会在Response的头信息中给你返回Cookie信息，你下一次访问的时候带上这个Cookie信息，则服务器就能识别你为上一次成功登陆的用户。\n内容 Cookie一般保存的格式为json格式，由一些属性组成。\n name：Cookie的名称 value：Cookie的值 domain：可以使用此Cookie的域名 path：可以使用此Cookie的页面路径 expires/Max-Age：此Cookie的超时时间 secure：设置是否只能通过https来传递此条Cookie  domain属性 域名一般来说分为顶级域名，二级域名，三级域名等等。\n例如baidu.com是一个顶级域名，而www.baidu.com和map.baidu.com就是二级域名，依次类推。\n而在我们的Cookie来说，都有一个domain属性，这个属性限制了访问哪些域名时可以使用这一条Cookie。因为每个网站基本上都会分发Cookie，所以domain属性就可以让我们在访问新浪时不会带上百度分发给我们的Cookie。\n而在同一系的域名中，顶级域名是无法使用其二级域名的Cookie的，也就是说访问baidu.com的时候是不会带上map.baidu.com分发的Cookie的，二级域名之间的Cookie也不可以共享。但访问二级域名时是可以使用顶级域名的Cookie的。\npath属性 path属性为可以访问此cookie的页面路径。 比如domain是abc.com，path是/test，那么只有/test路径下的页面可以读取此cookie。\nexpires/Max-Age属性 字段为此cookie超时时间。若设置其值为一个时间，那么当到达此时间后，此cookie失效。不设置的话默认值是Session，意思是cookie会和session一起失效。当浏览器关闭(不是浏览器标签页，而是整个浏览器) 后，此cookie失效。\nSession Session，中文经常翻译为会话，其本来的含义是指有始有终的一系列动作/消息，比如打电话时从拿起电话拨号到挂断电话这中间的一系列过程可以称之为一个session。这个词在各个领域都有在使用。\n而我们web领域，一般使用的是其本义，一个浏览器窗口从打开到关闭这个期间。\nSession的目的则是，在一个客户从打开浏览器到关闭浏览器这个期间内，发起的所有请求都可以被识别为同一个用户。而实现的方式则是，在一个客户打开浏览器开始访问网站的时候，会生成一个SessionID，这个ID每次的访问都会带上，而服务器会识别这个SessionID并且将与这个SessionID有关的数据保存在服务器上。由此来实现客户端的状态识别。\nSession与Cookie相反，Session是存储在服务器上的数据，只由客户端传上来的SessionId来进行判定，所以相对于Cookie，Session的安全性更高。\n一般SessionID会在浏览器被关闭时丢弃，或者服务器会验证Session的活跃程度，例如30分钟某一个SessionID都没有活跃，那么也会被识别为失效。\n","date":"2018-01-06T16:17:25Z","permalink":"https://wnanbei.github.io/post/http%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/","title":"HTTP网络协议"},{"content":"其实网络协议，就是为了所有的计算机能够在同一个网络中互相传递数据，而制定的数据传输规则。 就好像我们只有说同一种语言才能互相交流一个道理，那么想要在互联网中传递数据，就得遵守标准的网络协议。\nOSI参考模型 既然说到网络协议就像一种语言，同语言间才能够互相交流，那么自然网络协议也像语言一样，是多种多样的。\n在这种情况下国际标准化组织(ISO)提出的一个试图使各种计算机在世界范围内互连为网络的标准框架，简称OSI，OSI模型，即开放式通信系统互联参考模型(Open System Interconnection,OSI/RM,Open Systems Interconnection Reference Model)。\n这个模型的目的是：提供给开发者一个必须的、通用的概念以便开发完善、可以用来解释连接不同系统的框架。也就是说希望规范网络协议。\nOSI模型定义了网络互联的七层框架，也就是将网络协议从软件到硬件，从上到下的分成了七层，每层都为更高一层提供服务。\n虽然说OSI模型算是网络协议的框架标准，但是在实际的使用中，TCP/IP的五层协议使用的更加广泛。\nTCP/IP TCP/IP指的其实不只是TCP和IP这两个协议，而是一个协议簇，其中包括了IP、ICMP、TCP、http、ftp、pop3 等等的一系列协议。 TCP/IP（Transmission Control Protocol/Internet Protocol）是传输控制协议和网络协议的简称，它定义了电子设备如何连入因特网，以及数据如何在它们之间传输的标准。\nTCP/IP是Internet互联网上所有主机间的共同协议。\n结构 而TCP/IP协议采用五层结构，其与OSI模型的各层对应关系为\n网络分层 物理层和数据链路层 物理层是定义物理介质的各种特性：\n 机械特性 电子特性 功能特性 规程特性  数据链路层是负责接收IP数据包并通过网络发送，或者从网络上接收物理帧，抽出IP数据包，交给IP层。\n ARP是正向地址解析协议，通过已知的IP，寻找对应主机的MAC地址。 RARP是反向地址解析协议，通过MAC地址确定IP地址。比如无盘工作站还有DHCP服务。  常见的接口层协议有：\nEthernet 802.3、Token Ring 802.5、X.25、Frame relay、HDLC、PPP ATM等。\n网络层 负责相邻计算机之间的通信。其功能包括三方面。\n 处理来自传输层的分组发送请求，收到请求后，将分组装入IP数据报，填充报头，选择去往信宿机的路径，然后将数据报发往适当的网络接口。 处理输入数据报：首先检查其合法性，然后进行寻径\u0026ndash;假如该数据报已到达信宿机，则去掉报头，将剩下部分交给适当的传输协议；假如该数据报尚未到达信宿，则转发该数据报。 处理路径、流控、拥塞等问题。  网络层包括：IP(Internet Protocol）协议、ICMP(Internet Control Message Protocol)\n控制报文协议、ARP(Address Resolution Protocol）地址转换协议、RARP(Reverse ARP)反向地址转换协议。\n IP是网络层的核心，通过路由选择将下一条IP封装后交给接口层。IP数据报是无连接服务。 ICMP是网络层的补充，可以回送报文。用来检测网络是否通畅。Ping命令就是发送ICMP的echo包，通过回送的echo relay进行网络测试。  传输层 提供应用程序间的通信。其功能包括：一、格式化信息流；二、提供可靠传输。为实现后者，传输层协议规定接收端必须发回确认，并且假如分组丢失，必须重新发送，即耳熟能详的“三次握手”过程，从而提供可靠的数据传输。\n传输层协议主要是：传输控制协议TCP(Transmission Control Protocol）和用户数据报协议UDP(User Datagram protocol）。\n应用层 向用户提供一组常用的应用程序，比如电子邮件、文件传输访问、远程登录等。远程登录TELNET使用TELNET协议提供在网络其它主机上注册的接口。TELNET会话提供了基于字符的虚拟终端。文件传输访问FTP使用FTP协议来提供网络内机器间的文件拷贝功能。\n应用层协议主要包括如下几个：FTP、TELNET、DNS、SMTP、NFS、HTTP。\n FTP(File Transfer Protocol）是文件传输协议，一般上传下载用FTP服务，数据端口是20H，控制端口是21H。 Telnet服务是用户远程登录服务，使用23H端口，使用明码传送，保密性差、简单方便。 DNS(Domain Name Service）是域名解析服务，提供域名到IP地址之间的转换，使用端口53。 SMTP(Simple Mail Transfer Protocol）是简单邮件传输协议，用来控制信件的发送、中转，使用端口25。 NFS（Network File System）是网络文件系统，用于网络中不同主机间的文件共享。 HTTP(Hypertext Transfer Protocol）是超文本传输协议，用于实现互联网中的WWW服务，使用端口80。  TCP TCP（Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议，由IETF的RFC 793定义。\n在TCP/IP协议簇中，TCP处于传输层中。\n应用层向TCP层发送用于网间传输的、用8位字节表示的数据流，然后TCP把数据流分区成适当长度的报文段。之后TCP把结果包传给IP层，由它来通过网络将包传送给接收端实体的TCP层。\nTCP为了保证不发生丢包，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的包发回一个相应的确认（ACK），如果发送端实体在合理的往返时延（RTT）内未收到确认，那么对应的数据包就被假设为已丢失将会被进行重传。TCP用一个校验和函数来检验数据是否有错误，在发送和接收时都要计算校验和。\nTCP报文头 TCP传输的数据分为头部和数据部分。\n各个段位说明:\n 源端口和目的端口: 各占 2 字节.端口是传输层与应用层的服务接口.传输层的复用和分用功能都要通过端口才能实现 序号: 占 4 字节.TCP 连接中传送的数据流中的每一个字节都编上一个序号.序号字段的值则指的是本报文段所发送的数据的第一个字节的序号 确认号: 占 4 字节,是期望收到对方的下一个报文段的数据的第一个字节的序号 数据偏移/首部长度: 占 4 位,它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远.“数据偏移”的单位是 32 位字(以 4 字节为计算单位) 保留: 占 6 位,保留为今后使用,但目前应置为 0 紧急URG: 当 URG=1 时,表明紧急指针字段有效.它告诉系统此报文段中有紧急数据,应尽快传送(相当于高优先级的数据) 确认ACK: 只有当 ACK=1 时确认号字段才有效.当 ACK=0 时,确认号无效 PSH(PuSH): 接收 TCP 收到 PSH = 1 的报文段,就尽快地交付接收应用进程,而不再等到整个缓存都填满了后再向上交付 RST (ReSeT): 当 RST=1 时,表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因）,必须释放连接,然后再重新建立运输连接 同步 SYN: 同步 SYN = 1 表示这是一个连接请求或连接接受报文 终止 FIN: 用来释放一个连接.FIN=1 表明此报文段的发送端的数据已发送完毕,并要求释放运输连接 检验和: 占 2 字节.检验和字段检验的范围包括首部和数据这两部分.在计算检验和时,要在 TCP 报文段的前面加上 12 字节的伪首部 紧急指针: 占 16 位,指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面） 选项: 长度可变.TCP 最初只规定了一种选项,即最大报文段长度 MSS.MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节.” [MSS(Maximum Segment Size)是 TCP 报文段中的数据字段的最大长度.数据字段加上 TCP 首部才等于整个的 TCP 报文段] 填充: 这是为了使整个首部长度是 4 字节的整数倍 其他选项:  窗口扩大: 占 3 字节,其中有一个字节表示移位值 S.新的窗口值等于TCP 首部中的窗口位数增大到(16 + S),相当于把窗口值向左移动 S 位后获得实际的窗口大小 时间戳: 占10 字节,其中最主要的字段时间戳值字段(4字节)和时间戳回送回答字段(4字节) 选择确认: 接收方收到了和前面的字节流不连续的两2字节.如果这些字节的序号都在接收窗口之内,那么接收方就先收下这些数据,但要把这些信息准确地告诉发送方,使发送方不要再重复发送这些已收到的数据    三次握手四次挥手 既然说到TCP，不能不提到广为人知的三次握手和四次挥手，TCP协议为了保证信息传输的连接和可靠性，使用了这样的方式来保证连接的可靠性。\n三次握手 所谓三次握手，其实指的是TCP建立连接的过程，整个建立连接的过程需要发送三个包，来确认建立连接，具体流程如下：\n 第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。  四次挥手 四次挥手指的则是断开连接的过程：\n  第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。\n  第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。\n  第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。\n  第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。\n ","date":"2018-01-06T16:17:25Z","permalink":"https://wnanbei.github.io/post/tcp/ip%E4%BC%A0%E8%BE%93%E5%B1%82%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/","title":"TCP/IP传输层网络协议"}]